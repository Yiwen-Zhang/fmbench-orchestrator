Directory structure:
└── awslabs-fmbench-orchestrator/
    ├── constants.py
    ├── byo_dataset/
    │   ├── synthetic_data_large_prompts.jsonl
    │   ├── custom.jsonl
    │   └── prompt_template_llama3_summarization.txt
    ├── analytics/
    │   ├── sagemaker_metrics_plot.py
    │   ├── scratchpad.ipynb
    │   ├── pricing.yml
    │   ├── sagemaker_cost_rpm_plot.py
    │   └── analytics.py
    ├── startup_scripts/
    │   ├── ubuntu_arm_startup.txt
    │   ├── neuron_al2_startup_triton.txt
    │   ├── cpu_al2023_startup.txt
    │   └── ubuntu_startup.txt
    ├── globals.py
    ├── post_startup_scripts/
    │   └── fmbench.txt
    ├── main.py
    ├── requirements.txt
    ├── docs/
    │   ├── img/
    │   ├── iam.md
    │   └── config_guide.md
    ├── configs/
    │   ├── infra.yml
    │   ├── ec2_llama3.2-1b-cpu-byodataset.yml
    │   ├── llama3.1/
    │   │   ├── 8b/
    │   │   │   ├── llama3.1-8b-g5.yml
    │   │   │   └── llama3.1-8b-g6e-p5-djl.yml
    │   │   └── 70b/
    │   │       ├── llama3.1-70b-p4de-summariztion.yml
    │   │       └── llama3.1-70b-g5-g6-g6e-trn-inf-p4de.yml
    │   ├── llama3.2/
    │   │   └── llama3.2-1b-cpu-intel-amd.yml
    │   ├── ec2_custom_dataset.yml
    │   ├── ec2_byo_instance.yml
    │   ├── ami_mapping.yml
    │   ├── llama3/
    │   │   └── 8b/
    │   │       ├── llama3-8b-triton-g6e.yml
    │   │       ├── llam3-8b-cpu-intel.yml
    │   │       ├── llama3-8b-cpu-amd.yml
    │   │       └── llama3-8b-djl-g6e.yml
    │   ├── bedrock/
    │   │   ├── llama3.2-bedrock.yml
    │   │   └── llama3.1-bedrock.yml
    │   ├── sagemaker.yml
    │   ├── ec2.yml
    │   ├── bedrock.yml
    │   └── fmbench/
    │       └── .gitkeep
    ├── utils.py
    └── README.md

================================================
File: /constants.py
================================================
import os
from enum import Enum
from typing import Optional, List, Dict

# Define constants
FMBENCH_PACKAGE_NAME: str = "fmbench"
remote_script_path: str = "/home/{username}/run_fmbench.sh"
YAML_FILE_PATH: str = "config.yml"
DEFAULT_EC2_USERNAME: str = "ec2-user"
BYO_DATASET_FILE_PATH: str = "/tmp/fmbench-read/source_data/"
POST_STARTUP_LOCAL_MODE_VAR: str = "yes"
POST_STARTUP_WRITE_BUCKET_VAR: str = "placeholder"
AWS_CHIPS_PREFIX_LIST: List[str] = ["inf2", "trn1"]
IS_NEURON_INSTANCE = lambda instance_type: any([instance_type.startswith(p) for p in AWS_CHIPS_PREFIX_LIST])

class AMI_TYPE(str, Enum):
    NEURON = 'neuron'
    GPU = "gpu"

# Define a dictionary for common AMIs and their corresponding usernames
AMI_USERNAME_MAP: Dict = {
    "ami-": "ec2-user",  # Amazon Linux AMIs start with 'ami-'
    "ubuntu": "ubuntu",  # Ubuntu AMIs contain 'ubuntu' in their name
}

# Default constants for ec2 instance creation
DEFAULT_DEVICE_NAME: str = '/dev/sda/1'
EBS_IOPS: int = 16000
EBS_VOLUME_SIZE: int = 250
EBS_VOLUME_TYPE: str = "gp3"
CAPACITY_RESERVATION_PREFERENCE: str = "none"
MIN_INSTANCE_COUNT: int = 1
MAX_INSTANCE_COUNT: int = 1

# all region specific AMI mapping information for gpu/neuron based instances
# are given in this "ami_mapping.yml" file. This file currently contains information
# on us-east-1, us-east-2, us-west-1, us-west-2 for gpu and neuron instances. To add
# or change the ami mapping for other regions, modify this file. This model benchmarking
# configuration file will utilize the region (determined by the region metadata) or if the
# user provides it in the model config to get the AMI mapping and launch the specific
# instance accordingly.
AMI_MAPPING_FNAME: str = 'ami_mapping.yml'
INFRA_YML_FPATH: str = os.path.join("configs", "infra.yml")
# FMBench results file path
FMBENCH_RESULTS_FOLDER_PATTERN: str = "$HOME/results-*"

# flag related variables
STARTUP_COMPLETE_FLAG_FPATH: str = "/tmp/startup_complete.flag"
FMBENCH_TEST_COMPLETE_FLAG_FPATH: str = "/tmp/fmbench_completed.flag"
MAX_WAIT_TIME_FOR_STARTUP_SCRIPT_IN_SECONDS: int = 1500
SCRIPT_CHECK_INTERVAL_IN_SECONDS: int = 60
FMBENCH_LOG_PATH: str = "~/fmbench.log"
FMBENCH_LOG_REMOTE_PATH: str = "/home/{username}/fmbench.log"
CLOUD_INITLOG_PATH: str = "/var/log/cloud-init-output.log"

# misc directory paths
RESULTS_DIR: str = "results"
DOWNLOAD_DIR_FOR_CFG_FILES: str = "downloaded_configs"

# if the config file path starts with this then we know
# we need to download it from fmbench github repo
FMBENCH_CFG_PREFIX: str = "fmbench:"
FMBENCH_CFG_GH_PREFIX: str = "https://raw.githubusercontent.com/aws-samples/foundation-model-benchmarking-tool/refs/heads/main/src/fmbench/configs/"



================================================
File: /byo_dataset/synthetic_data_large_prompts.jsonl
================================================
{"input": "Lorem ipsum odor amet, consectetuer adipiscing elit. Lectus accumsan varius ultricies sagittis eget facilisis dapibus nec. Bibendum et porttitor posuere dapibus tempor class vulputate dis nisi. Metus natoque id suscipit accumsan senectus dolor netus. Vulputate habitasse ornare hendrerit; phasellus cubilia potenti viverra. Himenaeos fusce placerat orci quam pulvinar vestibulum. Nec blandit tincidunt commodo libero mollis. Fusce inceptos eleifend tincidunt, ligula volutpat a quis. Tincidunt accumsan dis lorem at orci velit arcu. Sociosqu congue cubilia faucibus metus mi phasellus. Tortor varius massa nascetur parturient efficitur nulla conubia montes feugiat. Odio ullamcorper venenatis odio habitant rhoncus vehicula non velit. Ut egestas duis molestie malesuada quam odio ac maecenas euismod. Erat felis et; diam neque nam donec quam cursus. Aliquam aenean dictum at ut nunc ut. Suscipit erat finibus rhoncus amet ultricies mi nulla libero ullamcorper. Facilisi porttitor egestas praesent eu maximus vel bibendum. Scelerisque convallis hendrerit tempor dictumst eros vitae auctor tempus. Varius sociosqu magna malesuada nibh turpis litora urna. Diam suscipit rutrum hac rutrum phasellus tellus semper posuere? Pulvinar lacinia nulla ac mauris proin, fermentum ridiculus pharetra. Montes dignissim senectus bibendum habitasse faucibus litora justo eget? igula congue facilisi vel lobortis maecenas nostra molestie lobortis integer. Fames turpis porta mus cursus auctor. Sed diam natoque justo amet tortor lacus lobortis taciti. Venenatis litora morbi ridiculus velit magnis nostra nec. Cubilia gravida vestibulum hac venenatis neque? Ornare id amet varius ex, quam massa. Class volutpat vel enim sem curabitur. Lacus vulputate interdum integer cursus eget. Aliquam litora netus morbi ipsum netus eu. Litora ligula dignissim vehicula feugiat odio fringilla. Mi integer auctor proin venenatis viverra montes. Sagittis accumsan molestie non ultricies euismod quis orci. Non scelerisque euismod lectus praesent erat montes taciti quisque. Penatibus inceptos cursus dictum ultrices vel consectetur scelerisque. Dignissim viverra penatibus turpis leo integer euismod himenaeos. Eu sodales nullam ultricies tempus massa interdum dui cursus nisl. Hac habitant morbi ipsum velit natoque tincidunt penatibus senectus. Ad nibh suscipit bibendum; vehicula ultricies tempor accumsan."}
{"input": "Lorem ipsum odor amet, consectetuer adipiscing elit. Lectus accumsan varius ultricies sagittis eget facilisis dapibus nec. Bibendum et porttitor posuere dapibus tempor class vulputate dis nisi. Metus natoque id suscipit accumsan senectus dolor netus. Vulputate habitasse ornare hendrerit; phasellus cubilia potenti viverra. Himenaeos fusce placerat orci quam pulvinar vestibulum. Nec blandit tincidunt commodo libero mollis. Fusce inceptos eleifend tincidunt, ligula volutpat a quis. Tincidunt accumsan dis lorem at orci velit arcu. Sociosqu congue cubilia faucibus metus mi phasellus. Tortor varius massa nascetur parturient efficitur nulla conubia montes feugiat. Odio ullamcorper venenatis odio habitant rhoncus vehicula non velit. Ut egestas duis molestie malesuada quam odio ac maecenas euismod. Erat felis et; diam neque nam donec quam cursus. Aliquam aenean dictum at ut nunc ut. Suscipit erat finibus rhoncus amet ultricies mi nulla libero ullamcorper. Facilisi porttitor egestas praesent eu maximus vel bibendum. Scelerisque convallis hendrerit tempor dictumst eros vitae auctor tempus. Varius sociosqu magna malesuada nibh turpis litora urna. Diam suscipit rutrum hac rutrum phasellus tellus semper posuere? Pulvinar lacinia nulla ac mauris proin, fermentum ridiculus pharetra. Montes dignissim senectus bibendum habitasse faucibus litora justo eget? igula congue facilisi vel lobortis maecenas nostra molestie lobortis integer. Fames turpis porta mus cursus auctor. Sed diam natoque justo amet tortor lacus lobortis taciti. Venenatis litora morbi ridiculus velit magnis nostra nec. Cubilia gravida vestibulum hac venenatis neque? Ornare id amet varius ex, quam massa. Class volutpat vel enim sem curabitur. Lacus vulputate interdum integer cursus eget. Aliquam litora netus morbi ipsum netus eu. Litora ligula dignissim vehicula feugiat odio fringilla. Mi integer auctor proin venenatis viverra montes. Sagittis accumsan molestie non ultricies euismod quis orci. Non scelerisque euismod lectus praesent erat montes taciti quisque. Penatibus inceptos cursus dictum ultrices vel consectetur scelerisque. Dignissim viverra penatibus turpis leo integer euismod himenaeos. Eu sodales nullam ultricies tempus massa interdum dui cursus nisl. Hac habitant morbi ipsum velit natoque tincidunt penatibus senectus. Ad nibh suscipit bibendum; vehicula ultricies tempor accumsan.Lorem ipsum odor amet, consectetuer adipiscing elit. Lectus accumsan varius ultricies sagittis eget facilisis dapibus nec. Bibendum et porttitor posuere dapibus tempor class vulputate dis nisi. Metus natoque id suscipit accumsan senectus dolor netus. Vulputate habitasse ornare hendrerit; phasellus cubilia potenti viverra. Himenaeos fusce placerat orci quam pulvinar vestibulum. Nec blandit tincidunt commodo libero mollis. Fusce inceptos eleifend tincidunt, ligula volutpat a quis. Tincidunt accumsan dis lorem at orci velit arcu. Sociosqu congue cubilia faucibus metus mi phasellus. Tortor varius massa nascetur parturient efficitur nulla conubia montes feugiat. Odio ullamcorper venenatis odio habitant rhoncus vehicula non velit. Ut egestas duis molestie malesuada quam odio ac maecenas euismod. Erat felis et; diam neque nam donec quam cursus. Aliquam aenean dictum at ut nunc ut. Suscipit erat finibus rhoncus amet ultricies mi nulla libero ullamcorper. Facilisi porttitor egestas praesent eu maximus vel bibendum. Scelerisque convallis hendrerit tempor dictumst eros vitae auctor tempus. Varius sociosqu magna malesuada nibh turpis litora urna. Diam suscipit rutrum hac rutrum phasellus tellus semper posuere? Pulvinar lacinia nulla ac mauris proin, fermentum ridiculus pharetra. Montes dignissim senectus bibendum habitasse faucibus litora justo eget? igula congue facilisi vel lobortis maecenas nostra molestie lobortis integer. Fames turpis porta mus cursus auctor. Sed diam natoque justo amet tortor lacus lobortis taciti. Venenatis litora morbi ridiculus velit magnis nostra nec. Cubilia gravida vestibulum hac venenatis neque? Ornare id amet varius ex, quam massa. Class volutpat vel enim sem curabitur. Lacus vulputate interdum integer cursus eget. Aliquam litora netus morbi ipsum netus eu. Litora ligula dignissim vehicula feugiat odio fringilla. Mi integer auctor proin venenatis viverra montes. Sagittis accumsan molestie non ultricies euismod quis orci. Non scelerisque euismod lectus praesent erat montes taciti quisque. Penatibus inceptos cursus dictum ultrices vel consectetur scelerisque. Dignissim viverra penatibus turpis leo integer euismod himenaeos. Eu sodales nullam ultricies tempus massa interdum dui cursus nisl. Hac habitant morbi ipsum velit natoque tincidunt penatibus senectus. Ad nibh suscipit bibendum; vehicula ultricies tempor accumsan."}
{"input": "Lorem ipsum odor amet, consectetuer adipiscing elit. Lectus accumsan varius ultricies sagittis eget facilisis dapibus nec. Bibendum et porttitor posuere dapibus tempor class vulputate dis nisi. Metus natoque id suscipit accumsan senectus dolor netus. Vulputate habitasse ornare hendrerit; phasellus cubilia potenti viverra. Himenaeos fusce placerat orci quam pulvinar vestibulum. Nec blandit tincidunt commodo libero mollis. Fusce inceptos eleifend tincidunt, ligula volutpat a quis. Tincidunt accumsan dis lorem at orci velit arcu. Sociosqu congue cubilia faucibus metus mi phasellus. Tortor varius massa nascetur parturient efficitur nulla conubia montes feugiat. Odio ullamcorper venenatis odio habitant rhoncus vehicula non velit. Ut egestas duis molestie malesuada quam odio ac maecenas euismod. Erat felis et; diam neque nam donec quam cursus. Aliquam aenean dictum at ut nunc ut. Suscipit erat finibus rhoncus amet ultricies mi nulla libero ullamcorper. Facilisi porttitor egestas praesent eu maximus vel bibendum. Scelerisque convallis hendrerit tempor dictumst eros vitae auctor tempus. Varius sociosqu magna malesuada nibh turpis litora urna. Diam suscipit rutrum hac rutrum phasellus tellus semper posuere? Pulvinar lacinia nulla ac mauris proin, fermentum ridiculus pharetra. Montes dignissim senectus bibendum habitasse faucibus litora justo eget? igula congue facilisi vel lobortis maecenas nostra molestie lobortis integer. Fames turpis porta mus cursus auctor. Sed diam natoque justo amet tortor lacus lobortis taciti. Venenatis litora morbi ridiculus velit magnis nostra nec. Cubilia gravida vestibulum hac venenatis neque? Ornare id amet varius ex, quam massa. Class volutpat vel enim sem curabitur. Lacus vulputate interdum integer cursus eget. Aliquam litora netus morbi ipsum netus eu. Litora ligula dignissim vehicula feugiat odio fringilla. Mi integer auctor proin venenatis viverra montes. Sagittis accumsan molestie non ultricies euismod quis orci. Non scelerisque euismod lectus praesent erat montes taciti quisque. Penatibus inceptos cursus dictum ultrices vel consectetur scelerisque. Dignissim viverra penatibus turpis leo integer euismod himenaeos. Eu sodales nullam ultricies tempus massa interdum dui cursus nisl. Hac habitant morbi ipsum velit natoque tincidunt penatibus senectus. Ad nibh suscipit bibendum; vehicula ultricies tempor accumsan.Lorem ipsum odor amet, consectetuer adipiscing elit. Lectus accumsan varius ultricies sagittis eget facilisis dapibus nec. Bibendum et porttitor posuere dapibus tempor class vulputate dis nisi. Metus natoque id suscipit accumsan senectus dolor netus. Vulputate habitasse ornare hendrerit; phasellus cubilia potenti viverra. Himenaeos fusce placerat orci quam pulvinar vestibulum. Nec blandit tincidunt commodo libero mollis. Fusce inceptos eleifend tincidunt, ligula volutpat a quis. Tincidunt accumsan dis lorem at orci velit arcu. Sociosqu congue cubilia faucibus metus mi phasellus. Tortor varius massa nascetur parturient efficitur nulla conubia montes feugiat. Odio ullamcorper venenatis odio habitant rhoncus vehicula non velit. Ut egestas duis molestie malesuada quam odio ac maecenas euismod. Erat felis et; diam neque nam donec quam cursus. Aliquam aenean dictum at ut nunc ut. Suscipit erat finibus rhoncus amet ultricies mi nulla libero ullamcorper. Facilisi porttitor egestas praesent eu maximus vel bibendum. Scelerisque convallis hendrerit tempor dictumst eros vitae auctor tempus. Varius sociosqu magna malesuada nibh turpis litora urna. Diam suscipit rutrum hac rutrum phasellus tellus semper posuere? Pulvinar lacinia nulla ac mauris proin, fermentum ridiculus pharetra. Montes dignissim senectus bibendum habitasse faucibus litora justo eget? igula congue facilisi vel lobortis maecenas nostra molestie lobortis integer. Fames turpis porta mus cursus auctor. Sed diam natoque justo amet tortor lacus lobortis taciti. Venenatis litora morbi ridiculus velit magnis nostra nec. Cubilia gravida vestibulum hac venenatis neque? Ornare id amet varius ex, quam massa. Class volutpat vel enim sem curabitur. Lacus vulputate interdum integer cursus eget. Aliquam litora netus morbi ipsum netus eu. Litora ligula dignissim vehicula feugiat odio fringilla. Mi integer auctor proin venenatis viverra montes. Sagittis accumsan molestie non ultricies euismod quis orci. Non scelerisque euismod lectus praesent erat montes taciti quisque. Penatibus inceptos cursus dictum ultrices vel consectetur scelerisque. Dignissim viverra penatibus turpis leo integer euismod himenaeos. Eu sodales nullam ultricies tempus massa interdum dui cursus nisl. Hac habitant morbi ipsum velit natoque tincidunt penatibus senectus. Ad nibh suscipit bibendum; vehicula ultricies tempor accumsan.Lorem ipsum odor amet, consectetuer adipiscing elit. Lectus accumsan varius ultricies sagittis eget facilisis dapibus nec. Bibendum et porttitor posuere dapibus tempor class vulputate dis nisi. Metus natoque id suscipit accumsan senectus dolor netus. Vulputate habitasse ornare hendrerit; phasellus cubilia potenti viverra. Himenaeos fusce placerat orci quam pulvinar vestibulum. Nec blandit tincidunt commodo libero mollis. Fusce inceptos eleifend tincidunt, ligula volutpat a quis. Tincidunt accumsan dis lorem at orci velit arcu. Sociosqu congue cubilia faucibus metus mi phasellus. Tortor varius massa nascetur parturient efficitur nulla conubia montes feugiat. Odio ullamcorper venenatis odio habitant rhoncus vehicula non velit. Ut egestas duis molestie malesuada quam odio ac maecenas euismod. Erat felis et; diam neque nam donec quam cursus. Aliquam aenean dictum at ut nunc ut. Suscipit erat finibus rhoncus amet ultricies mi nulla libero ullamcorper. Facilisi porttitor egestas praesent eu maximus vel bibendum. Scelerisque convallis hendrerit tempor dictumst eros vitae auctor tempus. Varius sociosqu magna malesuada nibh turpis litora urna. Diam suscipit rutrum hac rutrum phasellus tellus semper posuere? Pulvinar lacinia nulla ac mauris proin, fermentum ridiculus pharetra. Montes dignissim senectus bibendum habitasse faucibus litora justo eget? igula congue facilisi vel lobortis maecenas nostra molestie lobortis integer. Fames turpis porta mus cursus auctor. Sed diam natoque justo amet tortor lacus lobortis taciti. Venenatis litora morbi ridiculus velit magnis nostra nec. Cubilia gravida vestibulum hac venenatis neque? Ornare id amet varius ex, quam massa. Class volutpat vel enim sem curabitur. Lacus vulputate interdum integer cursus eget. Aliquam litora netus morbi ipsum netus eu. Litora ligula dignissim vehicula feugiat odio fringilla. Mi integer auctor proin venenatis viverra montes. Sagittis accumsan molestie non ultricies euismod quis orci. Non scelerisque euismod lectus praesent erat montes taciti quisque. Penatibus inceptos cursus dictum ultrices vel consectetur scelerisque. Dignissim viverra penatibus turpis leo integer euismod himenaeos. Eu sodales nullam ultricies tempus massa interdum dui cursus nisl. Hac habitant morbi ipsum velit natoque tincidunt penatibus senectus. Ad nibh suscipit bibendum; vehicula ultricies tempor accumsan."}
{"input": "Lorem ipsum odor amet, consectetuer adipiscing elit. Lectus accumsan varius ultricies sagittis eget facilisis dapibus nec. Bibendum et porttitor posuere dapibus tempor class vulputate dis nisi. Metus natoque id suscipit accumsan senectus dolor netus. Vulputate habitasse ornare hendrerit; phasellus cubilia potenti viverra. Himenaeos fusce placerat orci quam pulvinar vestibulum. Nec blandit tincidunt commodo libero mollis. Fusce inceptos eleifend tincidunt, ligula volutpat a quis. Tincidunt accumsan dis lorem at orci velit arcu. Sociosqu congue cubilia faucibus metus mi phasellus. Tortor varius massa nascetur parturient efficitur nulla conubia montes feugiat. Odio ullamcorper venenatis odio habitant rhoncus vehicula non velit. Ut egestas duis molestie malesuada quam odio ac maecenas euismod. Erat felis et; diam neque nam donec quam cursus. Aliquam aenean dictum at ut nunc ut. Suscipit erat finibus rhoncus amet ultricies mi nulla libero ullamcorper. Facilisi porttitor egestas praesent eu maximus vel bibendum. Scelerisque convallis hendrerit tempor dictumst eros vitae auctor tempus. Varius sociosqu magna malesuada nibh turpis litora urna. Diam suscipit rutrum hac rutrum phasellus tellus semper posuere? Pulvinar lacinia nulla ac mauris proin, fermentum ridiculus pharetra. Montes dignissim senectus bibendum habitasse faucibus litora justo eget? igula congue facilisi vel lobortis maecenas nostra molestie lobortis integer. Fames turpis porta mus cursus auctor. Sed diam natoque justo amet tortor lacus lobortis taciti. Venenatis litora morbi ridiculus velit magnis nostra nec. Cubilia gravida vestibulum hac venenatis neque? Ornare id amet varius ex, quam massa. Class volutpat vel enim sem curabitur. Lacus vulputate interdum integer cursus eget. Aliquam litora netus morbi ipsum netus eu. Litora ligula dignissim vehicula feugiat odio fringilla. Mi integer auctor proin venenatis viverra montes. Sagittis accumsan molestie non ultricies euismod quis orci. Non scelerisque euismod lectus praesent erat montes taciti quisque. Penatibus inceptos cursus dictum ultrices vel consectetur scelerisque. Dignissim viverra penatibus turpis leo integer euismod himenaeos. Eu sodales nullam ultricies tempus massa interdum dui cursus nisl. Hac habitant morbi ipsum velit natoque tincidunt penatibus senectus. Ad nibh suscipit bibendum; vehicula ultricies tempor accumsan.Lorem ipsum odor amet, consectetuer adipiscing elit. Lectus accumsan varius ultricies sagittis eget facilisis dapibus nec. Bibendum et porttitor posuere dapibus tempor class vulputate dis nisi. Metus natoque id suscipit accumsan senectus dolor netus. Vulputate habitasse ornare hendrerit; phasellus cubilia potenti viverra. Himenaeos fusce placerat orci quam pulvinar vestibulum. Nec blandit tincidunt commodo libero mollis. Fusce inceptos eleifend tincidunt, ligula volutpat a quis. Tincidunt accumsan dis lorem at orci velit arcu. Sociosqu congue cubilia faucibus metus mi phasellus. Tortor varius massa nascetur parturient efficitur nulla conubia montes feugiat. Odio ullamcorper venenatis odio habitant rhoncus vehicula non velit. Ut egestas duis molestie malesuada quam odio ac maecenas euismod. Erat felis et; diam neque nam donec quam cursus. Aliquam aenean dictum at ut nunc ut. Suscipit erat finibus rhoncus amet ultricies mi nulla libero ullamcorper. Facilisi porttitor egestas praesent eu maximus vel bibendum. Scelerisque convallis hendrerit tempor dictumst eros vitae auctor tempus. Varius sociosqu magna malesuada nibh turpis litora urna. Diam suscipit rutrum hac rutrum phasellus tellus semper posuere? Pulvinar lacinia nulla ac mauris proin, fermentum ridiculus pharetra. Montes dignissim senectus bibendum habitasse faucibus litora justo eget? igula congue facilisi vel lobortis maecenas nostra molestie lobortis integer. Fames turpis porta mus cursus auctor. Sed diam natoque justo amet tortor lacus lobortis taciti. Venenatis litora morbi ridiculus velit magnis nostra nec. Cubilia gravida vestibulum hac venenatis neque? Ornare id amet varius ex, quam massa. Class volutpat vel enim sem curabitur. Lacus vulputate interdum integer cursus eget. Aliquam litora netus morbi ipsum netus eu. Litora ligula dignissim vehicula feugiat odio fringilla. Mi integer auctor proin venenatis viverra montes. Sagittis accumsan molestie non ultricies euismod quis orci. Non scelerisque euismod lectus praesent erat montes taciti quisque. Penatibus inceptos cursus dictum ultrices vel consectetur scelerisque. Dignissim viverra penatibus turpis leo integer euismod himenaeos. Eu sodales nullam ultricies tempus massa interdum dui cursus nisl. Hac habitant morbi ipsum velit natoque tincidunt penatibus senectus. Ad nibh suscipit bibendum; vehicula ultricies tempor accumsan.Lorem ipsum odor amet, consectetuer adipiscing elit. Lectus accumsan varius ultricies sagittis eget facilisis dapibus nec. Bibendum et porttitor posuere dapibus tempor class vulputate dis nisi. Metus natoque id suscipit accumsan senectus dolor netus. Vulputate habitasse ornare hendrerit; phasellus cubilia potenti viverra. Himenaeos fusce placerat orci quam pulvinar vestibulum. Nec blandit tincidunt commodo libero mollis. Fusce inceptos eleifend tincidunt, ligula volutpat a quis. Tincidunt accumsan dis lorem at orci velit arcu. Sociosqu congue cubilia faucibus metus mi phasellus. Tortor varius massa nascetur parturient efficitur nulla conubia montes feugiat. Odio ullamcorper venenatis odio habitant rhoncus vehicula non velit. Ut egestas duis molestie malesuada quam odio ac maecenas euismod. Erat felis et; diam neque nam donec quam cursus. Aliquam aenean dictum at ut nunc ut. Suscipit erat finibus rhoncus amet ultricies mi nulla libero ullamcorper. Facilisi porttitor egestas praesent eu maximus vel bibendum. Scelerisque convallis hendrerit tempor dictumst eros vitae auctor tempus. Varius sociosqu magna malesuada nibh turpis litora urna. Diam suscipit rutrum hac rutrum phasellus tellus semper posuere? Pulvinar lacinia nulla ac mauris proin, fermentum ridiculus pharetra. Montes dignissim senectus bibendum habitasse faucibus litora justo eget? igula congue facilisi vel lobortis maecenas nostra molestie lobortis integer. Fames turpis porta mus cursus auctor. Sed diam natoque justo amet tortor lacus lobortis taciti. Venenatis litora morbi ridiculus velit magnis nostra nec. Cubilia gravida vestibulum hac venenatis neque? Ornare id amet varius ex, quam massa. Class volutpat vel enim sem curabitur. Lacus vulputate interdum integer cursus eget. Aliquam litora netus morbi ipsum netus eu. Litora ligula dignissim vehicula feugiat odio fringilla. Mi integer auctor proin venenatis viverra montes. Sagittis accumsan molestie non ultricies euismod quis orci. Non scelerisque euismod lectus praesent erat montes taciti quisque. Penatibus inceptos cursus dictum ultrices vel consectetur scelerisque. Dignissim viverra penatibus turpis leo integer euismod himenaeos. Eu sodales nullam ultricies tempus massa interdum dui cursus nisl. Hac habitant morbi ipsum velit natoque tincidunt penatibus senectus. Ad nibh suscipit bibendum; vehicula ultricies tempor accumsan.Lorem ipsum odor amet, consectetuer adipiscing elit. Lectus accumsan varius ultricies sagittis eget facilisis dapibus nec. Bibendum et porttitor posuere dapibus tempor class vulputate dis nisi. Metus natoque id suscipit accumsan senectus dolor netus. Vulputate habitasse ornare hendrerit; phasellus cubilia potenti viverra. Himenaeos fusce placerat orci quam pulvinar vestibulum. Nec blandit tincidunt commodo libero mollis. Fusce inceptos eleifend tincidunt, ligula volutpat a quis. Tincidunt accumsan dis lorem at orci velit arcu. Sociosqu congue cubilia faucibus metus mi phasellus. Tortor varius massa nascetur parturient efficitur nulla conubia montes feugiat. Odio ullamcorper venenatis odio habitant rhoncus vehicula non velit. Ut egestas duis molestie malesuada quam odio ac maecenas euismod. Erat felis et; diam neque nam donec quam cursus. Aliquam aenean dictum at ut nunc ut. Suscipit erat finibus rhoncus amet ultricies mi nulla libero ullamcorper. Facilisi porttitor egestas praesent eu maximus vel bibendum. Scelerisque convallis hendrerit tempor dictumst eros vitae auctor tempus. Varius sociosqu magna malesuada nibh turpis litora urna. Diam suscipit rutrum hac rutrum phasellus tellus semper posuere? Pulvinar lacinia nulla ac mauris proin, fermentum ridiculus pharetra. Montes dignissim senectus bibendum habitasse faucibus litora justo eget? igula congue facilisi vel lobortis maecenas nostra molestie lobortis integer. Fames turpis porta mus cursus auctor. Sed diam natoque justo amet tortor lacus lobortis taciti. Venenatis litora morbi ridiculus velit magnis nostra nec. Cubilia gravida vestibulum hac venenatis neque? Ornare id amet varius ex, quam massa. Class volutpat vel enim sem curabitur. Lacus vulputate interdum integer cursus eget. Aliquam litora netus morbi ipsum netus eu. Litora ligula dignissim vehicula feugiat odio fringilla. Mi integer auctor proin venenatis viverra montes. Sagittis accumsan molestie non ultricies euismod quis orci. Non scelerisque euismod lectus praesent erat montes taciti quisque. Penatibus inceptos cursus dictum ultrices vel consectetur scelerisque. Dignissim viverra penatibus turpis leo integer euismod himenaeos. Eu sodales nullam ultricies tempus massa interdum dui cursus nisl. Hac habitant morbi ipsum velit natoque tincidunt penatibus senectus. Ad nibh suscipit bibendum; vehicula ultricies tempor accumsan."}
{"input": "Lorem ipsum odor amet, consectetuer adipiscing elit. Lectus accumsan varius ultricies sagittis eget facilisis dapibus nec. Bibendum et porttitor posuere dapibus tempor class vulputate dis nisi. Metus natoque id suscipit accumsan senectus dolor netus. Vulputate habitasse ornare hendrerit; phasellus cubilia potenti viverra. Himenaeos fusce placerat orci quam pulvinar vestibulum. Nec blandit tincidunt commodo libero mollis. Fusce inceptos eleifend tincidunt, ligula volutpat a quis. Tincidunt accumsan dis lorem at orci velit arcu. Sociosqu congue cubilia faucibus metus mi phasellus. Tortor varius massa nascetur parturient efficitur nulla conubia montes feugiat. Odio ullamcorper venenatis odio habitant rhoncus vehicula non velit. Ut egestas duis molestie malesuada quam odio ac maecenas euismod. Erat felis et; diam neque nam donec quam cursus. Aliquam aenean dictum at ut nunc ut. Suscipit erat finibus rhoncus amet ultricies mi nulla libero ullamcorper. Facilisi porttitor egestas praesent eu maximus vel bibendum. Scelerisque convallis hendrerit tempor dictumst eros vitae auctor tempus. Varius sociosqu magna malesuada nibh turpis litora urna. Diam suscipit rutrum hac rutrum phasellus tellus semper posuere? Pulvinar lacinia nulla ac mauris proin, fermentum ridiculus pharetra. Montes dignissim senectus bibendum habitasse faucibus litora justo eget? igula congue facilisi vel lobortis maecenas nostra molestie lobortis integer. Fames turpis porta mus cursus auctor. Sed diam natoque justo amet tortor lacus lobortis taciti. Venenatis litora morbi ridiculus velit magnis nostra nec. Cubilia gravida vestibulum hac venenatis neque? Ornare id amet varius ex, quam massa. Class volutpat vel enim sem curabitur. Lacus vulputate interdum integer cursus eget. Aliquam litora netus morbi ipsum netus eu. Litora ligula dignissim vehicula feugiat odio fringilla. Mi integer auctor proin venenatis viverra montes. Sagittis accumsan molestie non ultricies euismod quis orci. Non scelerisque euismod lectus praesent erat montes taciti quisque. Penatibus inceptos cursus dictum ultrices vel consectetur scelerisque. Dignissim viverra penatibus turpis leo integer euismod himenaeos. Eu sodales nullam ultricies tempus massa interdum dui cursus nisl. Hac habitant morbi ipsum velit natoque tincidunt penatibus senectus. Ad nibh suscipit bibendum; vehicula ultricies tempor accumsan.Lorem ipsum odor amet, consectetuer adipiscing elit. Lectus accumsan varius ultricies sagittis eget facilisis dapibus nec. Bibendum et porttitor posuere dapibus tempor class vulputate dis nisi. Metus natoque id suscipit accumsan senectus dolor netus. Vulputate habitasse ornare hendrerit; phasellus cubilia potenti viverra. Himenaeos fusce placerat orci quam pulvinar vestibulum. Nec blandit tincidunt commodo libero mollis. Fusce inceptos eleifend tincidunt, ligula volutpat a quis. Tincidunt accumsan dis lorem at orci velit arcu. Sociosqu congue cubilia faucibus metus mi phasellus. Tortor varius massa nascetur parturient efficitur nulla conubia montes feugiat. Odio ullamcorper venenatis odio habitant rhoncus vehicula non velit. Ut egestas duis molestie malesuada quam odio ac maecenas euismod. Erat felis et; diam neque nam donec quam cursus. Aliquam aenean dictum at ut nunc ut. Suscipit erat finibus rhoncus amet ultricies mi nulla libero ullamcorper. Facilisi porttitor egestas praesent eu maximus vel bibendum. Scelerisque convallis hendrerit tempor dictumst eros vitae auctor tempus. Varius sociosqu magna malesuada nibh turpis litora urna. Diam suscipit rutrum hac rutrum phasellus tellus semper posuere? Pulvinar lacinia nulla ac mauris proin, fermentum ridiculus pharetra. Montes dignissim senectus bibendum habitasse faucibus litora justo eget? igula congue facilisi vel lobortis maecenas nostra molestie lobortis integer. Fames turpis porta mus cursus auctor. Sed diam natoque justo amet tortor lacus lobortis taciti. Venenatis litora morbi ridiculus velit magnis nostra nec. Cubilia gravida vestibulum hac venenatis neque? Ornare id amet varius ex, quam massa. Class volutpat vel enim sem curabitur. Lacus vulputate interdum integer cursus eget. Aliquam litora netus morbi ipsum netus eu. Litora ligula dignissim vehicula feugiat odio fringilla. Mi integer auctor proin venenatis viverra montes. Sagittis accumsan molestie non ultricies euismod quis orci. Non scelerisque euismod lectus praesent erat montes taciti quisque. Penatibus inceptos cursus dictum ultrices vel consectetur scelerisque. Dignissim viverra penatibus turpis leo integer euismod himenaeos. Eu sodales nullam ultricies tempus massa interdum dui cursus nisl. Hac habitant morbi ipsum velit natoque tincidunt penatibus senectus. Ad nibh suscipit bibendum; vehicula ultricies tempor accumsan.Lorem ipsum odor amet, consectetuer adipiscing elit. Lectus accumsan varius ultricies sagittis eget facilisis dapibus nec. Bibendum et porttitor posuere dapibus tempor class vulputate dis nisi. Metus natoque id suscipit accumsan senectus dolor netus. Vulputate habitasse ornare hendrerit; phasellus cubilia potenti viverra. Himenaeos fusce placerat orci quam pulvinar vestibulum. Nec blandit tincidunt commodo libero mollis. Fusce inceptos eleifend tincidunt, ligula volutpat a quis. Tincidunt accumsan dis lorem at orci velit arcu. Sociosqu congue cubilia faucibus metus mi phasellus. Tortor varius massa nascetur parturient efficitur nulla conubia montes feugiat. Odio ullamcorper venenatis odio habitant rhoncus vehicula non velit. Ut egestas duis molestie malesuada quam odio ac maecenas euismod. Erat felis et; diam neque nam donec quam cursus. Aliquam aenean dictum at ut nunc ut. Suscipit erat finibus rhoncus amet ultricies mi nulla libero ullamcorper. Facilisi porttitor egestas praesent eu maximus vel bibendum. Scelerisque convallis hendrerit tempor dictumst eros vitae auctor tempus. Varius sociosqu magna malesuada nibh turpis litora urna. Diam suscipit rutrum hac rutrum phasellus tellus semper posuere? Pulvinar lacinia nulla ac mauris proin, fermentum ridiculus pharetra. Montes dignissim senectus bibendum habitasse faucibus litora justo eget? igula congue facilisi vel lobortis maecenas nostra molestie lobortis integer. Fames turpis porta mus cursus auctor. Sed diam natoque justo amet tortor lacus lobortis taciti. Venenatis litora morbi ridiculus velit magnis nostra nec. Cubilia gravida vestibulum hac venenatis neque? Ornare id amet varius ex, quam massa. Class volutpat vel enim sem curabitur. Lacus vulputate interdum integer cursus eget. Aliquam litora netus morbi ipsum netus eu. Litora ligula dignissim vehicula feugiat odio fringilla. Mi integer auctor proin venenatis viverra montes. Sagittis accumsan molestie non ultricies euismod quis orci. Non scelerisque euismod lectus praesent erat montes taciti quisque. Penatibus inceptos cursus dictum ultrices vel consectetur scelerisque. Dignissim viverra penatibus turpis leo integer euismod himenaeos. Eu sodales nullam ultricies tempus massa interdum dui cursus nisl. Hac habitant morbi ipsum velit natoque tincidunt penatibus senectus. Ad nibh suscipit bibendum; vehicula ultricies tempor accumsan.Lorem ipsum odor amet, consectetuer adipiscing elit. Lectus accumsan varius ultricies sagittis eget facilisis dapibus nec. Bibendum et porttitor posuere dapibus tempor class vulputate dis nisi. Metus natoque id suscipit accumsan senectus dolor netus. Vulputate habitasse ornare hendrerit; phasellus cubilia potenti viverra. Himenaeos fusce placerat orci quam pulvinar vestibulum. Nec blandit tincidunt commodo libero mollis. Fusce inceptos eleifend tincidunt, ligula volutpat a quis. Tincidunt accumsan dis lorem at orci velit arcu. Sociosqu congue cubilia faucibus metus mi phasellus. Tortor varius massa nascetur parturient efficitur nulla conubia montes feugiat. Odio ullamcorper venenatis odio habitant rhoncus vehicula non velit. Ut egestas duis molestie malesuada quam odio ac maecenas euismod. Erat felis et; diam neque nam donec quam cursus. Aliquam aenean dictum at ut nunc ut. Suscipit erat finibus rhoncus amet ultricies mi nulla libero ullamcorper. Facilisi porttitor egestas praesent eu maximus vel bibendum. Scelerisque convallis hendrerit tempor dictumst eros vitae auctor tempus. Varius sociosqu magna malesuada nibh turpis litora urna. Diam suscipit rutrum hac rutrum phasellus tellus semper posuere? Pulvinar lacinia nulla ac mauris proin, fermentum ridiculus pharetra. Montes dignissim senectus bibendum habitasse faucibus litora justo eget? igula congue facilisi vel lobortis maecenas nostra molestie lobortis integer. Fames turpis porta mus cursus auctor. Sed diam natoque justo amet tortor lacus lobortis taciti. Venenatis litora morbi ridiculus velit magnis nostra nec. Cubilia gravida vestibulum hac venenatis neque? Ornare id amet varius ex, quam massa. Class volutpat vel enim sem curabitur. Lacus vulputate interdum integer cursus eget. Aliquam litora netus morbi ipsum netus eu. Litora ligula dignissim vehicula feugiat odio fringilla. Mi integer auctor proin venenatis viverra montes. Sagittis accumsan molestie non ultricies euismod quis orci. Non scelerisque euismod lectus praesent erat montes taciti quisque. Penatibus inceptos cursus dictum ultrices vel consectetur scelerisque. Dignissim viverra penatibus turpis leo integer euismod himenaeos. Eu sodales nullam ultricies tempus massa interdum dui cursus nisl. Hac habitant morbi ipsum velit natoque tincidunt penatibus senectus. Ad nibh suscipit bibendum; vehicula ultricies tempor accumsan.Lorem ipsum odor amet, consectetuer adipiscing elit. Lectus accumsan varius ultricies sagittis eget facilisis dapibus nec. Bibendum et porttitor posuere dapibus tempor class vulputate dis nisi. Metus natoque id suscipit accumsan senectus dolor netus. Vulputate habitasse ornare hendrerit; phasellus cubilia potenti viverra. Himenaeos fusce placerat orci quam pulvinar vestibulum. Nec blandit tincidunt commodo libero mollis. Fusce inceptos eleifend tincidunt, ligula volutpat a quis. Tincidunt accumsan dis lorem at orci velit arcu. Sociosqu congue cubilia faucibus metus mi phasellus. Tortor varius massa nascetur parturient efficitur nulla conubia montes feugiat. Odio ullamcorper venenatis odio habitant rhoncus vehicula non velit. Ut egestas duis molestie malesuada quam odio ac maecenas euismod. Erat felis et; diam neque nam donec quam cursus. Aliquam aenean dictum at ut nunc ut. Suscipit erat finibus rhoncus amet ultricies mi nulla libero ullamcorper. Facilisi porttitor egestas praesent eu maximus vel bibendum. Scelerisque convallis hendrerit tempor dictumst eros vitae auctor tempus. Varius sociosqu magna malesuada nibh turpis litora urna. Diam suscipit rutrum hac rutrum phasellus tellus semper posuere? Pulvinar lacinia nulla ac mauris proin, fermentum ridiculus pharetra. Montes dignissim senectus bibendum habitasse faucibus litora justo eget? igula congue facilisi vel lobortis maecenas nostra molestie lobortis integer. Fames turpis porta mus cursus auctor. Sed diam natoque justo amet tortor lacus lobortis taciti. Venenatis litora morbi ridiculus velit magnis nostra nec. Cubilia gravida vestibulum hac venenatis neque? Ornare id amet varius ex, quam massa. Class volutpat vel enim sem curabitur. Lacus vulputate interdum integer cursus eget. Aliquam litora netus morbi ipsum netus eu. Litora ligula dignissim vehicula feugiat odio fringilla. Mi integer auctor proin venenatis viverra montes. Sagittis accumsan molestie non ultricies euismod quis orci. Non scelerisque euismod lectus praesent erat montes taciti quisque. Penatibus inceptos cursus dictum ultrices vel consectetur scelerisque. Dignissim viverra penatibus turpis leo integer euismod himenaeos. Eu sodales nullam ultricies tempus massa interdum dui cursus nisl. Hac habitant morbi ipsum velit natoque tincidunt penatibus senectus. Ad nibh suscipit bibendum; vehicula ultricies tempor accumsan."}
{"input":"Lorem ipsum odor amet, consectetuer adipiscing elit. Lectus accumsan varius ultricies sagittis eget facilisis dapibus nec. Bibendum et porttitor posuere dapibus tempor class vulputate dis nisi. Metus natoque id suscipit accumsan senectus dolor netus. Vulputate habitasse ornare hendrerit; phasellus cubilia potenti viverra. Himenaeos fusce placerat orci quam pulvinar vestibulum. Nec blandit tincidunt commodo libero mollis. Fusce inceptos eleifend tincidunt, ligula volutpat a quis. Tincidunt accumsan dis lorem at orci velit arcu. Sociosqu congue cubilia faucibus metus mi phasellus. Tortor varius massa nascetur parturient efficitur nulla conubia montes feugiat. Odio ullamcorper venenatis odio habitant rhoncus vehicula non velit. Ut egestas duis molestie malesuada quam odio ac maecenas euismod. Erat felis et; diam neque nam donec quam cursus. Aliquam aenean dictum at ut nunc ut. Suscipit erat finibus rhoncus amet ultricies mi nulla libero ullamcorper. Facilisi porttitor egestas praesent eu maximus vel bibendum. Scelerisque convallis hendrerit tempor dictumst eros vitae auctor tempus. Varius sociosqu magna malesuada nibh turpis litora urna. Diam suscipit rutrum hac rutrum phasellus tellus semper posuere? Pulvinar lacinia nulla ac mauris proin, fermentum ridiculus pharetra. Montes dignissim senectus bibendum habitasse faucibus litora justo eget? igula congue facilisi vel lobortis maecenas nostra molestie lobortis integer. Fames turpis porta mus cursus auctor. Sed diam natoque justo amet tortor lacus lobortis taciti. Venenatis litora morbi ridiculus velit magnis nostra nec. Cubilia gravida vestibulum hac venenatis neque? Ornare id amet varius ex, quam massa. Class volutpat vel enim sem curabitur. Lacus vulputate interdum integer cursus eget. Aliquam litora netus morbi ipsum netus eu. Litora ligula dignissim vehicula feugiat odio fringilla. Mi integer auctor proin venenatis viverra montes. Sagittis accumsan molestie non ultricies euismod quis orci. Non scelerisque euismod lectus praesent erat montes taciti quisque. Penatibus inceptos cursus dictum ultrices vel consectetur scelerisque. Dignissim viverra penatibus turpis leo integer euismod himenaeos. Eu sodales nullam ultricies tempus massa interdum dui cursus nisl. Hac habitant morbi ipsum velit natoque tincidunt penatibus senectus. Ad nibh suscipit bibendum; vehicula ultricies tempor accumsan.Lorem ipsum odor amet, consectetuer adipiscing elit. Lectus accumsan varius ultricies sagittis eget facilisis dapibus nec. Bibendum et porttitor posuere dapibus tempor class vulputate dis nisi. Metus natoque id suscipit accumsan senectus dolor netus. Vulputate habitasse ornare hendrerit; phasellus cubilia potenti viverra. Himenaeos fusce placerat orci quam pulvinar vestibulum. Nec blandit tincidunt commodo libero mollis. Fusce inceptos eleifend tincidunt, ligula volutpat a quis. Tincidunt accumsan dis lorem at orci velit arcu. Sociosqu congue cubilia faucibus metus mi phasellus. Tortor varius massa nascetur parturient efficitur nulla conubia montes feugiat. Odio ullamcorper venenatis odio habitant rhoncus vehicula non velit. Ut egestas duis molestie malesuada quam odio ac maecenas euismod. Erat felis et; diam neque nam donec quam cursus. Aliquam aenean dictum at ut nunc ut. Suscipit erat finibus rhoncus amet ultricies mi nulla libero ullamcorper. Facilisi porttitor egestas praesent eu maximus vel bibendum. Scelerisque convallis hendrerit tempor dictumst eros vitae auctor tempus. Varius sociosqu magna malesuada nibh turpis litora urna. Diam suscipit rutrum hac rutrum phasellus tellus semper posuere? Pulvinar lacinia nulla ac mauris proin, fermentum ridiculus pharetra. Montes dignissim senectus bibendum habitasse faucibus litora justo eget? igula congue facilisi vel lobortis maecenas nostra molestie lobortis integer. Fames turpis porta mus cursus auctor. Sed diam natoque justo amet tortor lacus lobortis taciti. Venenatis litora morbi ridiculus velit magnis nostra nec. Cubilia gravida vestibulum hac venenatis neque? Ornare id amet varius ex, quam massa. Class volutpat vel enim sem curabitur. Lacus vulputate interdum integer cursus eget. Aliquam litora netus morbi ipsum netus eu. Litora ligula dignissim vehicula feugiat odio fringilla. Mi integer auctor proin venenatis viverra montes. Sagittis accumsan molestie non ultricies euismod quis orci. Non scelerisque euismod lectus praesent erat montes taciti quisque. Penatibus inceptos cursus dictum ultrices vel consectetur scelerisque. Dignissim viverra penatibus turpis leo integer euismod himenaeos. Eu sodales nullam ultricies tempus massa interdum dui cursus nisl. Hac habitant morbi ipsum velit natoque tincidunt penatibus senectus. Ad nibh suscipit bibendum; vehicula ultricies tempor accumsan.Lorem ipsum odor amet, consectetuer adipiscing elit. Lectus accumsan varius ultricies sagittis eget facilisis dapibus nec. Bibendum et porttitor posuere dapibus tempor class vulputate dis nisi. Metus natoque id suscipit accumsan senectus dolor netus. Vulputate habitasse ornare hendrerit; phasellus cubilia potenti viverra. Himenaeos fusce placerat orci quam pulvinar vestibulum. Nec blandit tincidunt commodo libero mollis. Fusce inceptos eleifend tincidunt, ligula volutpat a quis. Tincidunt accumsan dis lorem at orci velit arcu. Sociosqu congue cubilia faucibus metus mi phasellus. Tortor varius massa nascetur parturient efficitur nulla conubia montes feugiat. Odio ullamcorper venenatis odio habitant rhoncus vehicula non velit. Ut egestas duis molestie malesuada quam odio ac maecenas euismod. Erat felis et; diam neque nam donec quam cursus. Aliquam aenean dictum at ut nunc ut. Suscipit erat finibus rhoncus amet ultricies mi nulla libero ullamcorper. Facilisi porttitor egestas praesent eu maximus vel bibendum. Scelerisque convallis hendrerit tempor dictumst eros vitae auctor tempus. Varius sociosqu magna malesuada nibh turpis litora urna. Diam suscipit rutrum hac rutrum phasellus tellus semper posuere? Pulvinar lacinia nulla ac mauris proin, fermentum ridiculus pharetra. Montes dignissim senectus bibendum habitasse faucibus litora justo eget? igula congue facilisi vel lobortis maecenas nostra molestie lobortis integer. Fames turpis porta mus cursus auctor. Sed diam natoque justo amet tortor lacus lobortis taciti. Venenatis litora morbi ridiculus velit magnis nostra nec. Cubilia gravida vestibulum hac venenatis neque? Ornare id amet varius ex, quam massa. Class volutpat vel enim sem curabitur. Lacus vulputate interdum integer cursus eget. Aliquam litora netus morbi ipsum netus eu. Litora ligula dignissim vehicula feugiat odio fringilla. Mi integer auctor proin venenatis viverra montes. Sagittis accumsan molestie non ultricies euismod quis orci. Non scelerisque euismod lectus praesent erat montes taciti quisque. Penatibus inceptos cursus dictum ultrices vel consectetur scelerisque. Dignissim viverra penatibus turpis leo integer euismod himenaeos. Eu sodales nullam ultricies tempus massa interdum dui cursus nisl. Hac habitant morbi ipsum velit natoque tincidunt penatibus senectus. Ad nibh suscipit bibendum; vehicula ultricies tempor accumsan.Lorem ipsum odor amet, consectetuer adipiscing elit. Lectus accumsan varius ultricies sagittis eget facilisis dapibus nec. Bibendum et porttitor posuere dapibus tempor class vulputate dis nisi. Metus natoque id suscipit accumsan senectus dolor netus. Vulputate habitasse ornare hendrerit; phasellus cubilia potenti viverra. Himenaeos fusce placerat orci quam pulvinar vestibulum. Nec blandit tincidunt commodo libero mollis. Fusce inceptos eleifend tincidunt, ligula volutpat a quis. Tincidunt accumsan dis lorem at orci velit arcu. Sociosqu congue cubilia faucibus metus mi phasellus. Tortor varius massa nascetur parturient efficitur nulla conubia montes feugiat. Odio ullamcorper venenatis odio habitant rhoncus vehicula non velit. Ut egestas duis molestie malesuada quam odio ac maecenas euismod. Erat felis et; diam neque nam donec quam cursus. Aliquam aenean dictum at ut nunc ut. Suscipit erat finibus rhoncus amet ultricies mi nulla libero ullamcorper. Facilisi porttitor egestas praesent eu maximus vel bibendum. Scelerisque convallis hendrerit tempor dictumst eros vitae auctor tempus. Varius sociosqu magna malesuada nibh turpis litora urna. Diam suscipit rutrum hac rutrum phasellus tellus semper posuere? Pulvinar lacinia nulla ac mauris proin, fermentum ridiculus pharetra. Montes dignissim senectus bibendum habitasse faucibus litora justo eget? igula congue facilisi vel lobortis maecenas nostra molestie lobortis integer. Fames turpis porta mus cursus auctor. Sed diam natoque justo amet tortor lacus lobortis taciti. Venenatis litora morbi ridiculus velit magnis nostra nec. Cubilia gravida vestibulum hac venenatis neque? Ornare id amet varius ex, quam massa. Class volutpat vel enim sem curabitur. Lacus vulputate interdum integer cursus eget. Aliquam litora netus morbi ipsum netus eu. Litora ligula dignissim vehicula feugiat odio fringilla. Mi integer auctor proin venenatis viverra montes. Sagittis accumsan molestie non ultricies euismod quis orci. Non scelerisque euismod lectus praesent erat montes taciti quisque. Penatibus inceptos cursus dictum ultrices vel consectetur scelerisque. Dignissim viverra penatibus turpis leo integer euismod himenaeos. Eu sodales nullam ultricies tempus massa interdum dui cursus nisl. Hac habitant morbi ipsum velit natoque tincidunt penatibus senectus. Ad nibh suscipit bibendum; vehicula ultricies tempor accumsan.Lorem ipsum odor amet, consectetuer adipiscing elit. Lectus accumsan varius ultricies sagittis eget facilisis dapibus nec. Bibendum et porttitor posuere dapibus tempor class vulputate dis nisi. Metus natoque id suscipit accumsan senectus dolor netus. Vulputate habitasse ornare hendrerit; phasellus cubilia potenti viverra. Himenaeos fusce placerat orci quam pulvinar vestibulum. Nec blandit tincidunt commodo libero mollis. Fusce inceptos eleifend tincidunt, ligula volutpat a quis. Tincidunt accumsan dis lorem at orci velit arcu. Sociosqu congue cubilia faucibus metus mi phasellus. Tortor varius massa nascetur parturient efficitur nulla conubia montes feugiat. Odio ullamcorper venenatis odio habitant rhoncus vehicula non velit. Ut egestas duis molestie malesuada quam odio ac maecenas euismod. Erat felis et; diam neque nam donec quam cursus. Aliquam aenean dictum at ut nunc ut. Suscipit erat finibus rhoncus amet ultricies mi nulla libero ullamcorper. Facilisi porttitor egestas praesent eu maximus vel bibendum. Scelerisque convallis hendrerit tempor dictumst eros vitae auctor tempus. Varius sociosqu magna malesuada nibh turpis litora urna. Diam suscipit rutrum hac rutrum phasellus tellus semper posuere? Pulvinar lacinia nulla ac mauris proin, fermentum ridiculus pharetra. Montes dignissim senectus bibendum habitasse faucibus litora justo eget? igula congue facilisi vel lobortis maecenas nostra molestie lobortis integer. Fames turpis porta mus cursus auctor. Sed diam natoque justo amet tortor lacus lobortis taciti. Venenatis litora morbi ridiculus velit magnis nostra nec. Cubilia gravida vestibulum hac venenatis neque? Ornare id amet varius ex, quam massa. Class volutpat vel enim sem curabitur. Lacus vulputate interdum integer cursus eget. Aliquam litora netus morbi ipsum netus eu. Litora ligula dignissim vehicula feugiat odio fringilla. Mi integer auctor proin venenatis viverra montes. Sagittis accumsan molestie non ultricies euismod quis orci. Non scelerisque euismod lectus praesent erat montes taciti quisque. Penatibus inceptos cursus dictum ultrices vel consectetur scelerisque. Dignissim viverra penatibus turpis leo integer euismod himenaeos. Eu sodales nullam ultricies tempus massa interdum dui cursus nisl. Hac habitant morbi ipsum velit natoque tincidunt penatibus senectus. Ad nibh suscipit bibendum; vehicula ultricies tempor accumsan.Lorem ipsum odor amet, consectetuer adipiscing elit. Lectus accumsan varius ultricies sagittis eget facilisis dapibus nec. Bibendum et porttitor posuere dapibus tempor class vulputate dis nisi. Metus natoque id suscipit accumsan senectus dolor netus. Vulputate habitasse ornare hendrerit; phasellus cubilia potenti viverra. Himenaeos fusce placerat orci quam pulvinar vestibulum. Nec blandit tincidunt commodo libero mollis. Fusce inceptos eleifend tincidunt, ligula volutpat a quis. Tincidunt accumsan dis lorem at orci velit arcu. Sociosqu congue cubilia faucibus metus mi phasellus. Tortor varius massa nascetur parturient efficitur nulla conubia montes feugiat. Odio ullamcorper venenatis odio habitant rhoncus vehicula non velit. Ut egestas duis molestie malesuada quam odio ac maecenas euismod. Erat felis et; diam neque nam donec quam cursus. Aliquam aenean dictum at ut nunc ut. Suscipit erat finibus rhoncus amet ultricies mi nulla libero ullamcorper. Facilisi porttitor egestas praesent eu maximus vel bibendum. Scelerisque convallis hendrerit tempor dictumst eros vitae auctor tempus. Varius sociosqu magna malesuada nibh turpis litora urna. Diam suscipit rutrum hac rutrum phasellus tellus semper posuere? Pulvinar lacinia nulla ac mauris proin, fermentum ridiculus pharetra. Montes dignissim senectus bibendum habitasse faucibus litora justo eget? igula congue facilisi vel lobortis maecenas nostra molestie lobortis integer. Fames turpis porta mus cursus auctor. Sed diam natoque justo amet tortor lacus lobortis taciti. Venenatis litora morbi ridiculus velit magnis nostra nec. Cubilia gravida vestibulum hac venenatis neque? Ornare id amet varius ex, quam massa. Class volutpat vel enim sem curabitur. Lacus vulputate interdum integer cursus eget. Aliquam litora netus morbi ipsum netus eu. Litora ligula dignissim vehicula feugiat odio fringilla. Mi integer auctor proin venenatis viverra montes. Sagittis accumsan molestie non ultricies euismod quis orci. Non scelerisque euismod lectus praesent erat montes taciti quisque. Penatibus inceptos cursus dictum ultrices vel consectetur scelerisque. Dignissim viverra penatibus turpis leo integer euismod himenaeos. Eu sodales nullam ultricies tempus massa interdum dui cursus nisl. Hac habitant morbi ipsum velit natoque tincidunt penatibus senectus. Ad nibh suscipit bibendum; vehicula ultricies tempor accumsan."}


================================================
File: /byo_dataset/custom.jsonl
================================================
{"input": "Passage:\nVisit Grand Coulee Dam| Bureau of Reclamation\nVisit Grand Coulee Dam| Bureau of Reclamation\nContact Us\nVisit the Dam\nExplore the dam, take part in the D3 Geocache Challenge, view the Laser Light Show, and come inside the Visitor Center to experience the hands-on exhibits!\nThe visitor center is open daily (except Thanksgiving Day, December 25, and January 1) from 9:00 a.m. to 5:00 p.m, with extended hours between Memorial Day and September 30. During the summer season the visitor center is open until the laser light show, One River, Many Voices, ends. Show times vary, learn more >>\nQuestion:\nIn which country is the Grand Coulee Dam\nAnswer:\n", "context": "Passage:\nAdam's apple\nThe laryngeal prominence (commonly referred to as Adam's apple), a feature of the human neck, is the lump or protrusion that is formed by the angle of the thyroid cartilage surrounding the larynx.\n\nStructure\n\nThe structure of the laryngeal prominence forms a bump under the skin. It is larger in adult men, in whom it is usually clearly visible and palpable. In women, the bump is much less visible and is hardly perceived on the upper edge of the thyroid cartilage. \n\nThe meeting point of the two portions of the cartilage generally forms an acute angle (of about 90°) in men, while in women it forms an open arc (of about 120°).\n\nSex difference\n\nAlthough both sexes have it, the Adam's apple is considered to be a characteristic feature of adult men, because its size tends to increase considerably during puberty. \n\nIts development is considered a secondary sexual characteristic of males that appears as a result of hormonal activity. Its level of development varies among individuals and the widening of that area in the larynx can occur very suddenly and quickly.\n\nThe laryngeal prominence is more prominent in adult males than in females because of the difference in the size of the angle: 90° in males and 120° in females.\n\nFunction \n\nThe Adam's apple, in conjunction with the thyroid cartilage which forms it, helps to protect the walls and the frontal part of the larynx, including the vocal cords (which are located directly behind it). It is found in both women and men.\n\nAnother function of the laryngeal prominence is related to the deepening of the voice. During adolescence, the thyroid cartilage grows together with the larynx. Consequently, the laryngeal prominence grows in size mainly in men. Together, a larger soundboard is made up in phonation apparatus and, as a result, the man gets a deeper voice note.  \n\nSociety and culture\n\nCosmetic surgery to reduce the size of laryngeal prominence is called chondrolaryngoplasty (thyroid chondroplasty).  The surgery is effective, such that complications tend to be few and, if present, transient. \n\nHistory\n\nEtymology\n\nThere are two main theories as to the origin of the term \"Adam's apple\". \nThe \"Brewer's Dictionary of Phrase and Fable\" and the 1913 edition of Webster's Dictionary point at an ancient belief that a piece of forbidden fruit was embedded in Adam's throat (the first man, according to Abrahamic religions).  However, neither the Bible nor other Judeo-Christian Islamic writings mention such a story. In fact, the biblical story does not even specify the type of fruit that Adam ate. \n\nLinguist Alexander Gode claimed that the Latin phrase to designate the laryngeal prominence was very probably translated incorrectly from the beginning. The phrase in Latin was \"pomum Adami\" (literally: 'Adam's apple'). This, in turn, came from the Hebrew \"tappuach ha adam\" meaning \"apple of man\". The confusion lies in the fact that in Hebrew language the proper name \"Adam\" (אדם) literally means \"man\", while the late Hebrew word used to refer  \"bump\" is very similar to the word used to refer \"apple\".   Proponents of this version contend that the subsequent phrases in Latin and other Romance languages represent a mistranslation from the start. \n\nThe medical term \"prominentia laryngea\" was introduced by the Basle Nomina Anatomica in 1895. \n\nIn the American South, goozle is used colloquially to describe the Adam's apple, likely derived from guzzle.    \n\nAdditional images\n\nFile:Slide9lll.JPG|Laryngeal prominence\nFile:Slide5mmm.JPG|Laryngeal prominence\nFile:Slide7ooo.JPG|Laryngeal prominence\nQuestion:\nWhat is the common name for the laryngeal prominence in the body?\nAnswer:\nAdams Apple\nPassage:\nUranophobia\nFear of heaven, also known by its Greek-derived name uranophobia or ouranophobia, is a phobia that makes its sufferer fear heaven or the sky. \n\nThe origin of the word urano is Greek, meaning heaven, while phobia is Greek for fear.\n\nCauses\n\nThe causes of Uranophobia, as with other phobias, can be linked to a combination of external events and internal susceptibility - of brain chemistry and life experiences.\n\nFear of heaven may more specifically be related to the dread of punishment in the afterlife.  Psychoanalysis would see this as an animistic projection of the threatening and punitive powers of the parents  - heaven or the sky being a relatively late stage in the detachment of the superego from the actual parents. \n\nJewish tradition\n\nJewish tradition highly valorised the fear of heaven, seeing it as a positive force linked both to wisdom and to personal humility. \n\nLiterary examples\n\nW. B. Yeats in his poem 'The Cold Heaven' asked rhetorically whether after death the ghost is:\n\n\"stricken By the injustice of the skies for punishment?”\nQuestion:\nUranophobia is the irrational fear of which place or state of bliss?\nAnswer:\nHeaven\nPassage:\nThe Three-Cornered Hat\nEl sombrero de tres picos (The Three-Cornered Hat or Le tricorne) is a ballet choreographed by Léonide Massine to music by Manuel de Falla, commissioned by Sergei Diaghilev and premiered complete in 1919. It is not only a ballet with Spanish setting but one that also employs the techniques of Spanish dance (adapted and somewhat simplified) instead of classical ballet.   \n\nThe story – a magistrate infatuated with a miller's faithful wife attempts to seduce her – derives from the novella by Pedro Antonio de Alarcón (born in Granada) and has been traced in film several times, usually in Spanish. The music has these sections:\n\nAct I\n*Introducción — Introduction\n*Atardecer - Sunset\n*Danza de la molinera (Farruca) — Dance of the Miller's Wife \n*Las uvas — The Grapes\nAct II\n*Danza de los vecinos (Seguidillas) — Dance of the Neighbors\n*Danza del molinero (Farruca) — Dance of the Miller\n*Danza del corregidor — Dance of the Magistrate\n*Danza final (Jota)\n\nComposition History \n\nAs El corregidor y la molinera\n\nDuring World War I Manuel de Falla wrote a pantomime ballet in two scenes and called it The Magistrate and the Miller's Wife (El corregidor y la molinera). The work was scored for a small chamber orchestra and was performed in 1917.\n\nAs El sombrero de tres picos\n\nSergei Diaghilev of the Ballets Russes, saw the premiere of El corregidor y la molinera and commissioned Falla to rewrite it. The outcome was a two-act ballet scored for large orchestra called The Three-Cornered Hat (El sombrero de tres picos). This was first performed in London at the Alhambra Theatre on 22 July 1919. Sets and costumes were created by Pablo Picasso. Choreography was by Léonide Massine. Diaghilev asked Falla to conduct the premiere but the composer felt he was not experienced enough to conduct a work so complex and he handed the baton to Ernest Ansermet after one rehearsal. \nSynopsis \n\nAct One \n\nAfter a short fanfare the curtain rises revealing a mill in Andalusia. The miller is trying to teach a pet blackbird to tell the time. He tells the bird to chirp twice, but instead it chirps three times. Annoyed, the miller scolds the bird and tells it to try again. The  bird now chirps four times. The miller gets angry at the bird again and his wife offers it a grape. The bird takes the grape and chirps twice. The miller and his wife laugh over this and continue their work. \n\nSoon the magistrate, his wife, and their bodyguard pass by, taking their daily walk. The procession goes by and the couple returns to their work. The dandified, but lecherous, magistrate is heard coming back. The miller tells his wife that he will hide and that they will play a trick on the magistrate. \n\nThe miller hides and the magistrate sees the miller's wife dancing. After her dance she offers him some grapes. When the magistrate gets the grapes the miller's wife runs away with the magistrate following her. Finally he catches her, and the miller jumps out of a bush with a stick. The miller chases the magistrate away and the miller and his wife continue working.\n\nAct Two \n\nThat night, guests are at the miller's house. The miller dances to entertain them. His dance is interrupted by the magistrate's bodyguard, who has come to arrest him on trumped-up charges. After the miller is taken away, the guests leave one by one. The miller's wife goes to sleep and soon the magistrate comes to the mill. On his way to the door the magistrate trips and falls in the river. The miller's wife wakes up and runs away. \n\nThe magistrate undresses and hangs his clothes on a tree and goes to sleep in the miller's bed. The miller has escaped from prison and sees the magistrate in his bed. The miller thinks that the magistrate is sleeping with his wife and plans to switch clothes with the magistrate and avenge himself by seducing the magistrate's wife. The miller leaves, dressed as the magistrate, and the magistrate soon wakes up. He goes outside and sees that his clothes are gone, so he dresses in the miller's clothes. The bodyguard comes and sees the magistrate dressed as the miller and goes to arrest him. The miller's wife sees the bodyguard fighting with what looks like her husband and joins in the fight. The miller comes back and sees his wife in the fight and joins it to protect her. The magistrate explains the entire story and the ballet ends with the miller's guests tossing the magistrate up and down in a blanket.\n\nThe Music \n\nThroughout the ballet Falla uses traditional Andalusian folk music. The two songs sung by the mezzo-soprano are examples of cante jondo singing; this typically accompanies flamenco music and tells a sad story. At one point he quotes the opening of Beethoven's 5th Symphony. \n\nRecordings \n\nThere are many recordings of the complete ballet, as well as of the suites extracted from it. In the early 1960s Ernest Ansermet, the original conductor of the work, recorded it in stereo for London Records (aka Decca). The music was played by the Orchestre de la Suisse Romande and the cante-jondo soloist was Teresa Berganza. It has also been recorded by such conductors as Rafael Fruhbeck de Burgos and Jesús López-Cobos, and Leonard Bernstein has recorded the two suites from the ballet with the New York Philharmonic.\n\nThe original pantomime El corregidor y la molinera has been recorded by Josep Pons and Orquestra del Teatro Lliure for Harmonia Mundi.\n\nFilm versions \n\nThe Paris Opera Ballet has recently issued a performance of the complete ballet on a DVD entitled Picasso and Dance. The performance uses not only Massine's original choreography, but actual reproductions of Picasso's sets and costumes. It is, so far, the only performance of the ballet issued on video.\nQuestion:\nWho wrote the music for the ballet 'The Three-Cornered Hat'?\nAnswer:\nManuel de Fallas\nPassage:\nArctic Circle\nThe Arctic Circle is the most northerly of the five major circles of latitude that mark maps of the Earth. The region north of this circle is known as the Arctic, and the zone just to the south is called the Northern Temperate Zone. North of the Arctic Circle, the sun is above the horizon for twenty-four continuous hours at least once per year (and therefore visible at midnight) and below the horizon for twenty-four continuous hours at least once per year (and therefore not visible at noon); this is also true within the equivalent polar circle in the Southern Hemisphere, the Antarctic Circle.\n\nThe position of the Arctic Circle is not fixed; as of , it runs  north of the Equator.  Its latitude depends on the Earth's axial tilt, which fluctuates within a margin of 2° over a 40,000-year period, due to tidal forces resulting from the orbit of the Moon.  Consequently, the Arctic Circle is currently drifting northwards at a speed of about 15 m per year.\n\nEtymology \n\nThe word \"arctic\" comes from the Greek word ἀρκτικός (arktikos: \"near the Bear, northern\")  and that from the word ἄρκτος (arktos: \"bear\").  The name refers either to the constellation Ursa Major, the \"Great Bear\", which is prominent in the northern portion of the celestial sphere, or to the constellation Ursa Minor, the \"Little Bear\", which contains Polaris, the Pole star, also known as the North Star. \n\nMidnight sun and polar night\n\nThe Arctic Circle is the southernmost latitude in the Northern Hemisphere at which the sun can remain continuously above or below the horizon for twenty-four hours; as a result, at least once each year at any location within the Arctic Circle the sun is visible at local midnight, and at least once it is not visible at local noon.  \n\nDirectly on the Arctic Circle these events occur, in principle, exactly once per year: at the June and December solstices, respectively. However, because of atmospheric refraction and mirages, and because the sun appears as a disk and not a point, part of the midnight sun may be seen on the night of the northern summer solstice up to about 50 minutes (′) (90 km) south of the Arctic Circle; similarly, on the day of the northern winter solstice, part of the sun may be seen up to about 50′ north of the Arctic Circle. That is true at sea level; those limits increase with elevation above sea level, although in mountainous regions there is often no direct view of the true horizon.\n\nHuman habitation\n\nRelatively few people live north of the Arctic Circle due to the severe climate; nonetheless, some areas have been settled for thousands of years by indigenous peoples. Tens of thousands of years ago, waves of people migrated from eastern Siberia across the Bering Strait into North America and gradually eastward to settle. Much later, in the historic period, there has been migration into some Arctic areas by Europeans and other immigrants.\n\nThe largest communities north of the Arctic Circle are situated in Russia and Norway: Murmansk (population 307,257), Norilsk (175,365), Tromsø (71,295) and Vorkuta (70,548). Rovaniemi (61,329) in Finland is the largest settlement in the immediate vicinity of the Arctic Circle lying slightly south of the line.\n\nIn contrast, the largest North American community north of the Arctic Circle, Sisimiut (Greenland), has approximately 5,000 inhabitants. Of the Canadian and United States Arctic communities, Barrow, Alaska is the largest settlement with about 4,000 inhabitants.\n\nGeography\n\nThe Arctic Circle is roughly  long.  (A different source says . ) The area north of the Circle is about  and covers roughly 4% of Earth's surface. \n\nThe Arctic Circle passes through the Arctic Ocean, the Scandinavian Peninsula, North Asia, Northern America and Greenland. The land within the Arctic Circle is divided among eight countries: Norway, Sweden, Finland, Russia, the United States (Alaska), Canada, Denmark (Greenland), and Iceland (where it passes through the small offshore island of Grímsey).\n\nClimate\n\nThe climate inside the Arctic Circle is generally cold, but the coastal areas of Norway have a generally mild climate as a result of the Gulf Stream, which makes the ports of northern Norway and northwest Russia ice-free all year long. In the interior, summers can be quite warm, while winters are extremely cold. For example, summer temperatures in Norilsk (Russia) will sometimes reach as high as 30 C, while the winter temperatures frequently fall below .\n\nSites along the Arctic Circle\n\nStarting at the prime meridian and heading eastwards, the Arctic Circle passes through:\nQuestion:\nWhich is the largest city within the Arctic Circle?\nAnswer:\nMurmansk\nPassage:\nWhat a Country!\nWhat a Country! is an American sitcom that aired in syndication from September 27, 1986 to May 23, 1987. It was based on the 1977-1979 British sitcom Mind Your Language. The series was intended as somewhat of a showcase for Yakov Smirnoff, whose catchphrase provided the show's title.\n\nSynopsis\n\nWhat a Country! is set in a class of recent immigrants to the United States who are trying to pass the citizenship test. Their teacher, Taylor Brown (played by Garrett M. Brown) is an American English language teacher, while the students include Nikolai (a Russian taxi driver), Laszlo (a retired Hungarian doctor), Ali (a Pakistani), Robert (the son of a deposed African king), Maria (a housekeeper working for a rich Beverly Hills family), Victor (a Hispanic in love with Maria), Yung Hee (a shy Japanese woman) and Sheikh El Hamid (an Arabian sheikh). Gail Strickland initially played the character of Principal Joan Courtney, though she was replaced by Don Knotts during the series' run. \n\nThe series aired a total of 26 episodes before being canceled.\n\nCast\n\n* Garrett M. Brown as Taylor Brown\n* Yakov Smirnoff as Nikolai Rostopovich\n* George Murdock as Laszlo Gabo\n* Vijay Amritraj as Ali Nadim\n* Harry Waters, Jr. as Robert Muboto\n* Ada Maris as Maria Conchita Lopez\n* Julian Reyes as Victor Ortega\n* Leila Hee Olsen as Yung Hi\n* Gail Strickland as Principal Joan Courtney (Episodes 1-10)\n* Don Knotts as Principal F.J. \"Bud\" McPherson (Episodes 11-26)\n\nEpisodes\nQuestion:\nWhat country is projected to become the world's largest oil producer in the year 2014?\nAnswer:\nThe United States of America\nPassage:\nNordic | Define Nordic at Dictionary.com\nNordic | Define Nordic at Dictionary.com\nNordic\nadjective\n1.\nof, relating to, or characteristic of a Germanic people of northern European origin, exemplified by the Scandinavians.\n2.\nhaving or suggesting the physical characteristics associated with these people, typically tall stature, blond hair, blue eyes, and elongated head.\n3.\n(sometimes lowercase) of or relating to skiing events involving ski jumping and cross-country skiing.\nCompare alpine (def 5).\na member of the Nordic people, especially a Scandinavian.\nOrigin of Nordic\n1895-1900; < French nordique, equivalent to nord north + -ique -ic\nRelated forms\n[nawr-dis-i-tee] /nɔrˈdɪs ɪ ti/ (Show IPA), noun\nanti-Nordic, adjective\nExamples from the Web for Nordic\nExpand\nContemporary Examples\nOne of the best pavilions, which got a lot of buzz, is the Danish and Nordic Pavilion.\n‘Forbrydelsen,’ ‘Borgen,’ ‘The Bridge’: The Rise of Nordic Noir TV Jace Lacob June 19, 2012\nHistorical Examples\nEven in eastern Turkestan there are still strong evidences of Nordic blood in the physiognomy of the people.\nThe Hyborian Age Robert E. Howard\nAttila and his Huns were the first to break through into Nordic lands as far as the plains of northern France.\nBritish Dictionary definitions for Nordic\nExpand\n(skiing) of or relating to competitions in cross-country racing and ski-jumping Compare alpine (sense 4)\n2.\n(of recreational walking) incorporating the use of poles that resemble ski poles to aid movement\nNordic\nadjective\n1.\nof, relating to, or belonging to a subdivision of the Caucasoid race typified by the tall blond blue-eyed long-headed inhabitants of N Britain, Scandinavia, N Germany, and the Netherlands\nWord Origin\nC19: from French nordique, from nordnorth\nCollins English Dictionary - Complete & Unabridged 2012 Digital Edition\n© William Collins Sons & Co. Ltd. 1979, 1986 © HarperCollins\nPublishers 1998, 2000, 2003, 2005, 2006, 2007, 2009, 2012\nWord Origin and History for Nordic\nExpand\nadj.\n1898, from French nordique (in J. Deniker's system of race classifications), literally \"of or pertaining to the north,\" from nord \"north\" (a loan-word from Old English; see north ). Perhaps influenced by German Nordisch. As a noun, from 1901. Strictly, the blond peoples who inhabit Scandinavia and the north of Britain. As a type of skiing competition, it is attested from 1954.\nOnline Etymology Dictionary, © 2010 Douglas Harper\nQuestion:\n\"The term \"\"Nordic\"\" means relating to what area?\"\nAnswer:\nScandinavian culture\nPassage:\nShirley Conran\nShirley Conran (born 21 September 1932) is a British novelist and journalist. \n\nLife and writings\n\nConran is a best-selling author, whose books include Lace and Superwoman.   She has been a columnist for Vanity Fair, women's editor of The Daily Mail and a feature writer for The Observer.\n\nLace spent 13 weeks on the New York Times Best Seller list,  reaching as high as No. 6,  and was adapted into a 1980s US miniseries.\n\nConran was educated at the University of Portsmouth. She was successfully treated for skin cancer and has suffered from ME.  She is the ex-wife of British designer, restaurateur, retailer and writer Sir Terence Conran and mother to Sebastian Conran and Jasper Conran, both of whom are designers. Her two later husbands included Kevin O'Sullivan, now the husband of Victoria Glendinning.  Conran has homes in France and London, and lived in Monaco for several years. \n\nShe is known for coining the phrases \"Life is too short to stuff a mushroom\"  and \"First things first, second things never\".\n\n;Founder of Maths Action\nAn independent, not for profit organisation with no political affiliations, Maths Action aims to improve maths performance in Britain. \n\nWorks\n\nFiction\n\n*Lace (Simon & Schuster, 1982) \n*Lace 2 (1985)\n*The Complete Story (omnibus, 1986)\n*Savages (1987, movie rights owned by Warner Brothers but never made)\n*Crimson (1992)\n*Tiger Eyes (1994)\n*The Revenge (aka Revenge of Mimi Quinn, 1998)\n*The Amazing Umbrella Shop (1990)\n\nNon-fiction\n\n*Superwoman (1975)\n*Superwoman 2 (1977)\n*Futurewoman: How to Survive Life After Thirty (1979)\n*Superwoman in Action (1979)\n*The Magic Garden (1983)\n*Down with Superwoman: For Everyone Who Hates Housework (1990)\n*Money Stuff (2014) \n\nOther\n\n*The Magic Garden was adapted as a computer program and published by Acornsoft for the BBC Micro as Shirley Conran's Magic Garden.\nQuestion:\nWhich author is the ex-wife of British designer, restaurateur, retailer and writer Sir Terence and the mother of designers Sebastian and Jasper?\nAnswer:\nShirley Conran\nPassage:\nTop 10 Largest Banks in the World 2015 by Market ...\nTop 10 Largest Banks in the World 2015 by Market Capitalization\nFinancial List / August 17, 2014\n2) JP Morgan Chase & Co ($229.90 billion)\nThis American multinational banking and financial services holding company has assets worth around $2.515. The company came into existence when Chase Manhattan Corporation merged with J P Morgan & Co. It is considered to be a universal bank. It is one of the big four banks of the US.\n1) Wells Fargo & Co ($261.72 billion)\nWells Fargo & Co is the largest bank in the world by market capitalization. Headquartered in San Francisco, California, this bank is the fourth largest bank in the US by assets. It is the second largest bank in deposits, debit cards and home mortgage servicing. In 2007, it was the only bank in the US to be rated AAA by S&P, though its rating has since been lowered to AA- in light of the financial crisis of 2007-12.\nThe above-mentioned banks are huge brands and are serving millions worldwide.\nQuestion:\nBy assets and market capitalization, what is the largest bank in the US?\nAnswer:\nMorganChase\n", "answers": ["The United States of America", "United States Of Amerca", "Us of a", "U.–S.–A.", "Americaland", "United States (U.S.A.)", "Amurika", "Unite states of america", "United States of America (redirect)", "The U S A", "Unietd States", "EE UU", "The U.S.A.", "U.-S.-A.", "Usa", "United Staets of America", "Unites States", "États-Unis d'Amérique", "Verenigde State", "U.–S.", "The United States of America.", "The U-S-A", "EEUU", "U. S. A.", "Nagkaisang mga Estado", "The U. S. of America", "The USA", "America (United States)", "The U. S. A.", "U S of America", "UNITED STATES", "Estados Unidos", "The U–S", "American United States", "US and A", "Unitd states", "The US of A", "EE.UU.", "U-S", "The U-S", "Etymology of the United States", "U.S.A.)", "EE. UU.", "United states of america", "US of america", "Verenigde State van Amerika", "Nited States", "United-States", "Unite States", "Estados Unidos de América", "UnitedStates", "Estaos Unios", "US of America", "The Usa", "United states of America", "Untied States of America", "The U S of America", "THE AMERICAN UNITED STATES", "The United-States", "U S A", "AmericA", "Estados Unidos de America", "United states", "The U.S. of America", "Amerka", "United–States", "U.s.a.", "United States of America", "United State of America", "United States (US)", "The U.S. of A", "America", "Amercia", "Stati Uniti d'America", "Los Estados Unidos de America", "United Stated", "U.S.", "United States (of America)", "United States", "States of America", "America-class", "Los Estados Unidos", "U,S,", "United States (country)", "Federal United States", "ISO 3166-1:US", "Untied States", "The U.–S.–A.", "VS America", "Amurica", "Etats-Unis d'Amerique", "US", "U.S. OF A", "USofA", "Etats-Unis", "U.S. of A", "United States of America (U.S.A.)", "Amarica", "The United States", "U-S-A", "United States/Introduction", "The Us", "Unitesd states", "The U S of A", "America class", "America magazine", "الولايات المتحدة الأمريكية", "The U. S. of A", "U S", "(USA)", "The United–States", "United States (U.S.)", "U.-S.", "United States of America (USA)", "'merica", "The US", "United States of America.", "UNited States", "The U.S.", "AMERICA", "United States of America/OldPage", "United+States", "The U S", "United Sates", "THE UNITED STATES OF AMERICA", "U–S–A", "United States Of America", "U.S. of America", "U–S", "Los Estados Unidos de América", "The U.-S.", "United sates", "The United States Of America", "America (country)", "United States of American", "United state of america", "The U.–S.", "Amurka", "U. S. of A", "The U. S.", "United States America", "US of A", "États-Unis", "USoA", "USA", "Estaos Uníos", "America, United States of", "U. S. of America", "U.S.American", "(US)", "The U–S–A", "U. S.", "U.S. America", "U.S. A", "Yankee land", "America (US)", "U.S", "America (United States of)", "US (country)", "UNITED STATES OF AMERICA", "U.S.A", "Estados unidos", "Americia", "The US of america", "Vereinigte Staaten", "US America", "These United States of America", "VS Amerika", "Name of the United States", "The united states of america", "Estatos Unitos", "America (USA)", "The U.-S.-A.", "United States of America/Introduction", "The US of America", "Americophile", "V.S. America", "U.S.A.", "U S of A", "V.S. Amerika", "United+States+of+America", "The Unites States of America"], "length": 3835, "dataset": "triviaqa", "language": "en", "all_classes": null, "_id": "c6270c6ae570ce9459e98f4c704e3d86d510a755f6ce5443"}

================================================
File: /byo_dataset/prompt_template_llama3_summarization.txt
================================================
<|begin_of_text|><|start_header_id|>user<|end_header_id|>

You are an assistant for summarization tasks. Use the following pieces of retrieved context in the section demarcated by "```" to summarize the context.

Context: {input} 

Summarize the entire context. Your summary should be detailed, long and should cover all important key aspects of the context.

<|eot_id|><|start_header_id|>assistant<|end_header_id|>


================================================
File: /analytics/sagemaker_metrics_plot.py
================================================
import logging
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

logging.basicConfig(format='[%(asctime)s] p%(process)s {%(filename)s:%(lineno)d} %(levelname)s - %(message)s', level=logging.INFO)
logger = logging.getLogger(__name__)

def plot_sm_utilization_metrics(endpoint_metrics_df : pd.DataFrame) -> sns.FacetGrid:
    '''
    This function reads a CSV file containing endpoint metrics data, processes the data,
    and generates a FacetGrid line plot to visualize utilization metrics for different 
    concurrency levels and instance types. The function returns the FacetGrid object.

    Parameters:
    endpoint_metrics_df (pd.DataFrame): Dataframe containing the endpoint metrics data.

    Returns:
    FacetGrid: The FacetGrid object containing the plotted data.

    Example Usage:
    ```
    sm_utilization_metrics_plot = plot_sm_utilization_metrics('sagemaker_endpoint_metrics.csv')
    sm_utilization_metrics_plot.savefig('sm_utilization_metrics_plot.png')
    ```
    '''
    # Load the data from CSV file

    logger.info("======================================")
    logger.info(f"loaded dataframe, shape is: {endpoint_metrics_df.shape}")
    logger.info("======================================")
    

    # Ensure Timestamp is in datetime format
    endpoint_metrics_df['Timestamp'] = pd.to_datetime(endpoint_metrics_df['Timestamp'])

    # Melt the DataFrame to long format
    utilization_metrics_melted_data = endpoint_metrics_df.melt(
        id_vars=['Timestamp', 'instance_type', 'concurrency'], 
        value_vars=['CPUUtilization', 'DiskUtilization', 'GPUMemoryUtilization', 'GPUUtilization', 'MemoryUtilization'],
        var_name='Metric', value_name='Value'
    )

    logger.info("======================================")
    logger.info(f"Melted dataframe, new shape is :  {utilization_metrics_melted_data.shape}")
    logger.info("======================================")

    # Define markers for the line plots
    markers = {"CPUUtilization": "o", "DiskUtilization": "s", "GPUMemoryUtilization": "X", "GPUUtilization": "^", "MemoryUtilization": 'v'}

    # Create the FacetGrid for line plot
    utilization_metrics_plot = sns.FacetGrid(
        utilization_metrics_melted_data, col='instance_type', row='concurrency', hue='Metric', 
        palette='muted', height=4, aspect=1.25, sharex=False
    )
    utilization_metrics_plot.map(sns.lineplot, 'Timestamp', 'Value', dashes=False)

    # Update markers
    for ax in utilization_metrics_plot.axes.flat:
        lines = ax.get_lines()
        for line, (metric, marker) in zip(lines, markers.items()):
            line.set_marker(marker)

    # Add legend
    utilization_metrics_plot.add_legend()

    # Create a subtitle
    with sns.plotting_context('paper', font_scale=1.3):
        utilization_metrics_plot.figure.suptitle("Utilization metrics for different concurrency levels and instance types")
        utilization_metrics_plot.set_titles(row_template="concurrency={row_name}", col_template="instance={col_name}", size=8)

    # Bold the concurrency titles
    for ax in utilization_metrics_plot.axes.flat:
        title_text = ax.get_title()
        if "concurrency" in title_text:
            ax.set_title(title_text, fontsize=10, fontweight='bold')

    # Set x and y labels for this chart
    utilization_metrics_plot.set_ylabels("Utilization (%)")
    utilization_metrics_plot.set_xlabels("Timestamp")
    #top below controls the spacing for title of the plot, hspace and wspace control the spacing between the grid
    utilization_metrics_plot.figure.subplots_adjust(top=.93, hspace=0.5, wspace=0.2)

    # Rotate x-axis labels for better readability
    for ax in utilization_metrics_plot.axes.flat:
        plt.setp(ax.get_xticklabels(), rotation=45, ha="right")
    logger.info(f'\nPlotting Complete, returning FacetGrid Object\n')
    return utilization_metrics_plot

================================================
File: /analytics/scratchpad.ipynb
================================================
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import logging\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='[%(asctime)s] p%(process)s {%(filename)s:%(lineno)d} %(levelname)s - %(message)s', level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_DIR: str = \"../results-*\"\n",
    "FIRST_N: int = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-09-23 20:35:14,362] p121634 {1289656933.py:2} INFO - looking for per inference files in ../results-*/per_inference/*.json\n",
      "[2024-09-23 20:35:14,365] p121634 {1289656933.py:4} INFO - found 1037 files, listing first 10\n",
      "['../results-llama3-8b-g5.12xl-tp=2-mc=max-djl-ec2/per_inference/1727121590.5035987.json', '../results-llama3-8b-g5.12xl-tp=2-mc=max-djl-ec2/per_inference/1727121633.7328534.json', '../results-llama3-8b-g5.12xl-tp=2-mc=max-djl-ec2/per_inference/1727121754.196286.json', '../results-llama3-8b-g5.12xl-tp=2-mc=max-djl-ec2/per_inference/1727121509.0425491.json', '../results-llama3-8b-g5.12xl-tp=2-mc=max-djl-ec2/per_inference/1727121685.8263414.json', '../results-llama3-8b-g5.12xl-tp=2-mc=max-djl-ec2/per_inference/1727121484.6407592.json', '../results-llama3-8b-g5.12xl-tp=2-mc=max-djl-ec2/per_inference/1727121362.5149496.json', '../results-llama3-8b-g5.12xl-tp=2-mc=max-djl-ec2/per_inference/1727121833.160436.json', '../results-llama3-8b-g5.12xl-tp=2-mc=max-djl-ec2/per_inference/1727121777.999922.json', '../results-llama3-8b-g5.12xl-tp=2-mc=max-djl-ec2/per_inference/1727121572.2959073.json']\n"
     ]
    }
   ],
   "source": [
    "data_path = os.path.join(RESULTS_DIR, \"per_inference\", \"*.json\")\n",
    "logger.info(f\"looking for per inference files in {data_path}\")\n",
    "file_list = glob.glob(data_path)\n",
    "logger.info(f\"found {len(file_list)} files, listing first {FIRST_N}\\n{file_list[:FIRST_N]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['results-llama3-8b-g5.12xl-tp=2-mc=max-triton-ec2',\n",
       " 'results-llama3-8b-g5.12xl-tp=2-mc=max-djl-ec2']"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_result_files_list = list(set([Path(f).parent.absolute().parent.name for f in file_list]))\n",
    "unique_result_files_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-09-23 20:35:14,491] p121634 {2288595646.py:4} INFO - sample data {\n",
      "  \"endpoint_name\": \"http://127.0.0.1:8080/invocations\",\n",
      "  \"prompt\": \"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nYou are an assistant for question-answering tasks. Use the following pieces of retrieved context in the section demarcated by \\\"```\\\" to answer the question. \\nThe context may contain multiple question answer pairs as an example. Only answer the final question provided in the question section below.\\nIf you dont know the answer just say that you dont know. Use three sentences maximum and keep the answer concise. \\n\\n```\\nPassage 1:\\nEricaceae\\nThe Ericaceae () are a family of flowering plants, commonly known as the heath or heather family, found most commonly in acidic and infertile growing conditions. The family is large, with c. 4250 known species spread across 124 genera, making it the 14th most species-rich family of flowering plants. The many well known and economically important members of the Ericaceae include the cranberry, blueberry, huckleberry, rhododendron (including azaleas), and various common heaths and heathers (Erica, Cassiope, Daboecia, and Calluna for example).\\n\\nDescription\\nThe Ericaceae contain a morphologically diverse range of taxa, including herbs, dwarf shrubs, shrubs, and trees. Their leaves are usually evergreen, alternate or whorled, simple and without stipules. Their flowers are hermaphrodite and show considerable variability. The petals are often fused (sympetalous) with shapes ranging from narrowly tubular to funnelform or widely urn-shaped. The corollas are usually radially symmetrical (actinomorphic) and urn-shaped, but many flowers of the genus Rhododendron are somewhat bilaterally symmetrical (zygomorphic). Anthers open by pores.\\n\\nTaxonomy\\nMichel Adanson used the term Vaccinia to describe a similar family, but Antoine Laurent de Jussieu first used the term Ericaceae. The name comes from the type genus Erica, which appears to be derived from the Greek word ere\\u00edk\\u0113 (\\u1f10\\u03c1\\u03b5\\u03af\\u03ba\\u03b7). The exact meaning is difficult to interpret, but some sources show it as meaning 'heather'. The name may have been used informally to refer to the plants before Linnaean times, and simply been formalised when Linnaeus described Erica in 1753, and then again when Jussieu described the Ericaceae in 1789.Historically, the Ericaceae included both subfamilies and tribes. In 1971, Stevens, who outlined the history from 1876 and in some instances 1839, recognised six subfamilies (Rhododendroideae, Ericoideae, Vaccinioideae, Pyroloideae, Monotropoideae, and Wittsteinioideae), and further subdivided four of the subfamilies into tribes, the Rhododendroideae having seven tribes (Bejarieae, Rhodoreae, Cladothamneae, Epigaeae, Phyllodoceae, and Diplarcheae). Within tribe Rhodoreae, five genera were described, Rhododendron L. (including Azalea L. pro parte), Therorhodion Small, Ledum L., Tsusiophyllum Max., Menziesia J. E. Smith, that were eventually transferred into Rhododendron, along with Diplarche from the monogeneric tribe Diplarcheae.In 2002, systematic research resulted in the inclusion of the formerly recognised families Empetraceae, Epacridaceae, Monotropaceae, Prionotaceae, and Pyrolaceae into the Ericaceae based on a combination of molecular, morphological, anatomical, and embryological data, analysed within a phylogenetic framework. The move significantly increased the morphological and geographical range found within the group. One possible classification of the resulting family includes 9 subfamilies, 126 genera, and about 4000 species:\\nEnkianthoideae Kron, Judd & Anderberg (one genus, 16 species)\\nPyroloideae Kosteltsky (4 genera, 40 species)\\nMonotropoideae Arnott (10 genera, 15 species)\\nArbutoideae Niedenzu (up to six genera, about 80 species)\\nCassiopoideae Kron & Judd (one genus, 12 species)\\nEricoideae Link (19 genera, 1790 species)\\nHarrimanelloideae Kron & Judd (one species)\\nEpacridoideae Arn. (=Styphelioideae Sweet) (35 genera, 545 species)\\nVaccinioideae Arnott (50 genera, 1580 species)\\n\\nGenera\\nSee the full list at List of Ericaceae genera.\\n\\nDistribution and ecology\\nThe Ericaceae have a nearly worldwide distribution. They are absent from continental Antarctica, parts of the high Arctic, central Greenland, northern and central Australia, and much of the lowland tropics and neotropics.The family is largely composed of plants that can tolerate acidic, infertile conditions. Like other stress-tolerant plants, many Ericaceae have mycorrhizal fungi to assist with extracting nutrients from infertile soils, as well as evergreen foliage to conserve absorbed nutrients. This trait is not found in the Clethraceae and Cyrillaceae, the two families most closely related to the Ericaceae. Most Ericaceae (excluding the Monotropoideae, and some Epacridoideae) form a distinctive accumulation of mycorrhizae, in which fungi grow in and around the roots and provide the plant with nutrients. The Pyroloideae are mixotrophic and gain sugars from the mycorrhizae, as well as nutrients.In many parts of the world, a \\\"heath\\\" or \\\"heathland\\\" is an environment characterised by an open dwarf-shrub community found on low-quality acidic soils, generally dominated by plants in the Ericaceae. A common example is Erica tetralix. This plant family is also typical of peat bogs and blanket bogs; examples include Rhododendron groenlandicum and Kalmia polifolia. In eastern North America, members of this family often grow in association with an oak canopy, in a habitat known as an oak-heath forest.In heathland, plants in the family Ericaceae serve as hostplants to the butterfly Plebejus argus.Some evidence suggests eutrophic rainwater can convert ericoid heaths with species such as Erica tetralix to grasslands. Nitrogen is particularly suspect in this regard, and may be causing measurable changes to the distribution and abundance of some ericaceous species.\\nPassage 2:\\nDeutzia silvestrii\\nDeutzia silvestrii is a species of Safflower in the family Hydrangeaceae. It is found in central China (\\u7ea2\\u82b1\\u6eb2\\u758f; h\\u00f3ng hu\\u0101 s\\u014du sh\\u016b).\\nPassage 3:\\nCassiope mertensiana\\nCassiope mertensiana is a species of flowering plant known by the common names western moss heather and white mountain heather.\\nThis heather is native to subalpine areas of western North America, from Alaska to the mountains of California. It is a small, branching shrub which forms patches along the ground and in rocky crevices.\\n\\nDescription\\nCassiope mertensiana has short, erect, snakelike stems that are covered in tiny leathery scalelike leaves only a few millimeters long. From between the layers of scale leaves emerge reddish  pedicels each bearing a petite, hanging, down-facing, bell-shaped flower. The bractlets are red and the contrasting flower is white.\\n\\nAlthough the shrub tends to grow in areas where there is a lot of accumulation of snow, adequate rain precipitation is needed for the continued growth of Cassiope Mertensiana. The shrub must be exposed to enough sunlight and warmer conditions for proper growth during the growing season.\\nPassage 4:\\nCassiope lycopodioides\\nCassiope lycopodioides, Haida Gwaii mountain-heather or clubmoss mountain heather, is a plant species native to North America.\\n\\nDistribution\\nIt is found in southern Alaska, British Columbia, and the US State of Washington.\\nIt is found on rocky slopes in arctic and alpine tundra at elevations up to 2000 m. In Washington, it is reported only from King County. The specific epithet \\\"lycopodioides\\\" refers to the plant's superficial resemblance to some species of clubmoss (Lycopodium sensu lato).\\n\\nSubspecies\\nCassiope lycopodioides subsp. cristapilosa, known only from the Haida Gwaii (formerly called the Queen Charlotte Islands), is recognized as a distinct taxon by some authorities but not others.\\n\\nDescription\\nCassiope lycopodioides is a perennial herb forming mats lying close to the ground. Leaves are narrow, up to 3 mm long, closely pressed against the stem. Flowers are white, bell-shaped, up to 20 mm across.\\nPassage 5:\\nDeutzia\\nDeutzia ( or ) is a genus of about 60 species of flowering plants in the family Hydrangeaceae, native to eastern and central Asia (from the Himalayas east to Japan and the Philippines), and Central America and also Europe. By far the highest species diversity is in China, where 50 species occur.\\nThe species are shrubs ranging from 1\\u20134 m (3 ft 3 in \\u2013 13 ft 1 in) in height. Most are deciduous, but a few subtropical species are evergreen. The leaves are opposite, simple, with a serrated margin. The flowers are produced in panicles or corymbs; they are white in most species, sometimes pink or reddish. The fruit is a dry capsule containing numerous small seeds. Identification of the species is very difficult, requiring often microscopic detail of the leaf hairs and seed capsule structure.\\nDeutzia is named after the 18th century Dutch patron of botany, Johan van der Deutz.\\n\\nSelected species\\n\\nCultivation and uses\\nThe deutzias are fairly new to gardens: the exception, D. scabra, was noticed in Japanese gardens by Engelbert Kaempfer (1712) and Carl Peter Thunberg (1784) but not actually seen in Europe till the 1830s; two-thirds of the species noted in the R.H.S. Dictionary were gathered in from the wild during the 20th century.Deutzias are commonly grown as ornamental plants for their white and pink flowers. Many cultivars and hybrids have been selected for garden use, including selections with double flowers. For example, Deutzia \\u00d7 lemoinei is a hybrid of D. gracilis and D. parviflora. The following cultivars and hybrids have gained the Royal Horticultural Society's Award of Garden Merit:-\\n\\nThe temperate deutzias are mostly hardy shrubs from far eastern regions where winters are dependably frozen; in milder climates, like much of England, the early-flowering species and hybrids are coaxed into premature bloom by mild spells, then spoilt by frost. Alice Coats remarks that deutzias have done better in Edinburgh, on the chilly east coast of Scotland, than in London. A solution in milder climates might be to site deutzia in the garden's most exposed, coldest microclimate, as is often done with early-flowering magnolias.\\nIdentification can be difficult, and in particular, many of the plants in cultivation sold as D. scabra are actually D. crenata (Huxley 1992). The selected hybrid white double \\\"Pride-of-Rochester\\\", already in cultivation in 1881, was originated by the Rochester, New York nurserymen Ellwanger and Barry.Deutzia scabra is used by joiners in Japan to polish wood.\\nPassage 6:\\nCassiope\\nCassiope is a genus of 9-12 small shrubby species in the family Ericaceae. It is the sole genus in the subfamily Cassiopoideae. They are native to the Arctic and north temperate montane regions. The genus is named after Cassiopeia of Greek mythology. Common names, shared with several other similar related genera, include heather and heath. They have scale-like leaves lying against the stems, and produce solitary bell-shaped flowers in late spring. Though hardy, flowers can be damaged by late frosts.\\nThey are cultivated in gardens, suitable sites being rock gardens, peat banks or glades in woodland areas.,\\nPassage 7:\\nHarrimanella\\nHarrimanella is a genus of flowering plant in the heath family Ericaceae, with a single species, Harrimanella hypnoides, also known as moss bell heather or moss heather.   It was originally named Cassiope hypnoides by Linnaeus (1737) in his Flora Lapponica, but Harrimanella hypnoides is now the accepted name at Integrated Taxonomic Information System. The species name hypnoides means 'like Hypnum ', which is a genus mosses.\\nThe plant is a cold hardy dicot perennial found growing on rock crevices in the Canadian arctic, Quebec, the Northeastern United States, Greenland, Iceland, the mountains of Norway, Sweden and Finland, Svalbard and arctic Russia, including the Ural mountains.Harrimanella hypnoides produces moss-like cushions, about 5 cm high, often of prostrate stems with ascending shoot tips. The leaves are scale-like, looking like those of a moss. The flowers are conspicuous, white and bell shaped with five fused petals and five sepals. They are borne singly on short reddish pedicels. The fruit is an erect capsule.\\nPassage 8:\\nDeutzia ningpoensis\\nDeutzia ningpoensis is a shrub in the family Hydrangeaceae.  The species is endemic to China. It grows to between 1 and 2.5 metres high and produces panicles of white flowers from May to July in its native range.\\n```\\n\\nQuestion: Which as more species Cassiope or Deutzia? \\n\\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>\",\n",
      "  \"question\": \"Which as more species Cassiope or Deutzia?\",\n",
      "  \"ground_truth\": \"Deutzia\",\n",
      "  \"payload_file\": \"payload_en_3000-3840.jsonl\",\n",
      "  \"do_sample\": true,\n",
      "  \"temperature\": 0.1,\n",
      "  \"top_p\": 0.92,\n",
      "  \"top_k\": 120,\n",
      "  \"max_new_tokens\": 100,\n",
      "  \"completion\": \"{\\\"generated_text\\\": \\\"\\\\n\\\\nAccording to the provided context, Deutzia has about 60 species, while Cassiope has 9-12 species. Therefore, Deutzia has more species.\\\"}\",\n",
      "  \"prompt_tokens\": 3010,\n",
      "  \"completion_tokens\": 44,\n",
      "  \"latency\": 1.6929611009982182,\n",
      "  \"time_to_first_token\": null,\n",
      "  \"time_per_output_token\": null,\n",
      "  \"time_to_last_token\": null,\n",
      "  \"uuid\": \"f8d4f8a95cf84a6d866513d8802bbbf9\",\n",
      "  \"experiment_name\": \"Meta-Llama-3-8B-Instruct\",\n",
      "  \"concurrency\": 2,\n",
      "  \"filename\": \"results-llama3-8b-g5.12xl-tp=2-mc=max-djl-ec2\"\n",
      "}\n",
      "[2024-09-23 20:35:14,499] p121634 {2288595646.py:6} INFO - shape of data from (1037, 26)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>endpoint_name</th>\n",
       "      <th>prompt</th>\n",
       "      <th>question</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>payload_file</th>\n",
       "      <th>do_sample</th>\n",
       "      <th>temperature</th>\n",
       "      <th>top_p</th>\n",
       "      <th>top_k</th>\n",
       "      <th>max_new_tokens</th>\n",
       "      <th>...</th>\n",
       "      <th>time_to_last_token</th>\n",
       "      <th>uuid</th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>concurrency</th>\n",
       "      <th>filename</th>\n",
       "      <th>bad_words</th>\n",
       "      <th>stop_words</th>\n",
       "      <th>pad_id</th>\n",
       "      <th>end_id</th>\n",
       "      <th>max_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://127.0.0.1:8080/invocations</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;user&lt;|end_...</td>\n",
       "      <td>Which as more species Cassiope or Deutzia?</td>\n",
       "      <td>Deutzia</td>\n",
       "      <td>payload_en_3000-3840.jsonl</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.92</td>\n",
       "      <td>120</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>f8d4f8a95cf84a6d866513d8802bbbf9</td>\n",
       "      <td>Meta-Llama-3-8B-Instruct</td>\n",
       "      <td>2</td>\n",
       "      <td>results-llama3-8b-g5.12xl-tp=2-mc=max-djl-ec2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://127.0.0.1:8080/invocations</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;user&lt;|end_...</td>\n",
       "      <td>Both WAGS Atlanta and WAGS are what?</td>\n",
       "      <td>American reality television series</td>\n",
       "      <td>payload_en_500-1000.jsonl</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.92</td>\n",
       "      <td>120</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>c77f4eeb09304c4fb927b8008be87886</td>\n",
       "      <td>Meta-Llama-3-8B-Instruct</td>\n",
       "      <td>4</td>\n",
       "      <td>results-llama3-8b-g5.12xl-tp=2-mc=max-djl-ec2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://127.0.0.1:8080/invocations</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;user&lt;|end_...</td>\n",
       "      <td>Passage:\\nUnits of Measurement - University of...</td>\n",
       "      <td>English inch,Inch (unit),International inch,De...</td>\n",
       "      <td>payload_en_2000-3000.jsonl</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.92</td>\n",
       "      <td>120</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>4cbfd69056854939a36bb34268f87b85</td>\n",
       "      <td>Meta-Llama-3-8B-Instruct</td>\n",
       "      <td>6</td>\n",
       "      <td>results-llama3-8b-g5.12xl-tp=2-mc=max-djl-ec2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://127.0.0.1:8080/invocations</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;user&lt;|end_...</td>\n",
       "      <td>Are Kakwa River and Bighead River located in t...</td>\n",
       "      <td>yes</td>\n",
       "      <td>payload_en_3000-3840.jsonl</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.92</td>\n",
       "      <td>120</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>a933e435434e4a90b80575cad2f0a3f1</td>\n",
       "      <td>Meta-Llama-3-8B-Instruct</td>\n",
       "      <td>1</td>\n",
       "      <td>results-llama3-8b-g5.12xl-tp=2-mc=max-djl-ec2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://127.0.0.1:8080/invocations</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;user&lt;|end_...</td>\n",
       "      <td>Passage:\\nTubman: Conductor of the Underground...</td>\n",
       "      <td>National Underground Railroad Network to Freed...</td>\n",
       "      <td>payload_en_3000-3840.jsonl</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.92</td>\n",
       "      <td>120</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>23c57b884e1d45dea30006d3132146fc</td>\n",
       "      <td>Meta-Llama-3-8B-Instruct</td>\n",
       "      <td>4</td>\n",
       "      <td>results-llama3-8b-g5.12xl-tp=2-mc=max-djl-ec2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       endpoint_name  \\\n",
       "0  http://127.0.0.1:8080/invocations   \n",
       "1  http://127.0.0.1:8080/invocations   \n",
       "2  http://127.0.0.1:8080/invocations   \n",
       "3  http://127.0.0.1:8080/invocations   \n",
       "4  http://127.0.0.1:8080/invocations   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  <|begin_of_text|><|start_header_id|>user<|end_...   \n",
       "1  <|begin_of_text|><|start_header_id|>user<|end_...   \n",
       "2  <|begin_of_text|><|start_header_id|>user<|end_...   \n",
       "3  <|begin_of_text|><|start_header_id|>user<|end_...   \n",
       "4  <|begin_of_text|><|start_header_id|>user<|end_...   \n",
       "\n",
       "                                            question  \\\n",
       "0         Which as more species Cassiope or Deutzia?   \n",
       "1               Both WAGS Atlanta and WAGS are what?   \n",
       "2  Passage:\\nUnits of Measurement - University of...   \n",
       "3  Are Kakwa River and Bighead River located in t...   \n",
       "4  Passage:\\nTubman: Conductor of the Underground...   \n",
       "\n",
       "                                        ground_truth  \\\n",
       "0                                            Deutzia   \n",
       "1                 American reality television series   \n",
       "2  English inch,Inch (unit),International inch,De...   \n",
       "3                                                yes   \n",
       "4  National Underground Railroad Network to Freed...   \n",
       "\n",
       "                 payload_file  do_sample  temperature  top_p  top_k  \\\n",
       "0  payload_en_3000-3840.jsonl       True          0.1   0.92    120   \n",
       "1   payload_en_500-1000.jsonl       True          0.1   0.92    120   \n",
       "2  payload_en_2000-3000.jsonl       True          0.1   0.92    120   \n",
       "3  payload_en_3000-3840.jsonl       True          0.1   0.92    120   \n",
       "4  payload_en_3000-3840.jsonl       True          0.1   0.92    120   \n",
       "\n",
       "   max_new_tokens  ... time_to_last_token                              uuid  \\\n",
       "0           100.0  ...               None  f8d4f8a95cf84a6d866513d8802bbbf9   \n",
       "1           100.0  ...               None  c77f4eeb09304c4fb927b8008be87886   \n",
       "2           100.0  ...               None  4cbfd69056854939a36bb34268f87b85   \n",
       "3           100.0  ...               None  a933e435434e4a90b80575cad2f0a3f1   \n",
       "4           100.0  ...               None  23c57b884e1d45dea30006d3132146fc   \n",
       "\n",
       "            experiment_name  concurrency  \\\n",
       "0  Meta-Llama-3-8B-Instruct            2   \n",
       "1  Meta-Llama-3-8B-Instruct            4   \n",
       "2  Meta-Llama-3-8B-Instruct            6   \n",
       "3  Meta-Llama-3-8B-Instruct            1   \n",
       "4  Meta-Llama-3-8B-Instruct            4   \n",
       "\n",
       "                                        filename bad_words stop_words pad_id  \\\n",
       "0  results-llama3-8b-g5.12xl-tp=2-mc=max-djl-ec2       NaN        NaN    NaN   \n",
       "1  results-llama3-8b-g5.12xl-tp=2-mc=max-djl-ec2       NaN        NaN    NaN   \n",
       "2  results-llama3-8b-g5.12xl-tp=2-mc=max-djl-ec2       NaN        NaN    NaN   \n",
       "3  results-llama3-8b-g5.12xl-tp=2-mc=max-djl-ec2       NaN        NaN    NaN   \n",
       "4  results-llama3-8b-g5.12xl-tp=2-mc=max-djl-ec2       NaN        NaN    NaN   \n",
       "\n",
       "  end_id  max_tokens  \n",
       "0    NaN         NaN  \n",
       "1    NaN         NaN  \n",
       "2    NaN         NaN  \n",
       "3    NaN         NaN  \n",
       "4    NaN         NaN  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the files into a dataframe\n",
    "content = [json.loads(Path(f).read_text()) | dict(filename=Path(f).parent.absolute().parent.name) \\\n",
    "           for f in file_list]\n",
    "logger.info(f\"sample data {json.dumps(content[0], indent=2)}\")\n",
    "df = pd.DataFrame(content)\n",
    "logger.info(f\"shape of data from {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze payload_en_3000-3840 for a couple of result folders\n",
    "\"\"\"\n",
    "\"payload_file\": \"payload_en_1-500.jsonl\",\n",
    "  \"do_sample\": true,\n",
    "  \"temperature\": 0.1,\n",
    "  \"top_p\": 0.92,\n",
    "  \"top_k\": 120,\n",
    "  \"max_new_tokens\": 100,\n",
    "  \"completion\": \"{\\\"generated_text\\\": \\\"\\\\n\\\\n```Stauntonia is a genus of flowering plants in the family Lardizabalaceae. It is named after George Staunton, who brought it to Britain from China in the 19th century.\\\\n\\\\nSpecies\\\\nSpecies accepted by the Plants of the World Online as of March 2023:\\\\nSinofranchetia\\\\nSinofranchetia is a genus of flowering plant in the Lardizabalaceae family. It contains a single species, Sinofr\\\"}\",\n",
    "  \"prompt_tokens\": 328,\n",
    "  \"completion_tokens\": 111,\n",
    "  \"latency\": 2.4156091760087293,\n",
    "  \"time_to_first_token\": null,\n",
    "  \"time_per_output_token\": null,\n",
    "  \"time_to_last_token\": null,\n",
    "  \"uuid\": \"5aca6360ee5244a68d2a951f0067d68b\",\n",
    "  \"experiment_name\": \"Meta-Llama-3-8B-Instruct\",\n",
    "  \"concurrency\": 4,\n",
    "  \"filename\": \"results-llama3-8b-g5.12xl-tp=2-mc=max-djl-ec2\"\n",
    "\"\"\"\n",
    "PAYLOAD_OF_INTEREST: str = \"payload_en_3000-3840.jsonl\" #payload_en_3000-3840.jsonl\"\n",
    "df1 = df[(df.payload_file == PAYLOAD_OF_INTEREST)]\n",
    "RESULT_FOLDER1_OF_INTEREST: str = \"results-llama3-8b-g5.12xl-tp=4-mc=max-djl-ec2\"\n",
    "# df1 = df[(df.payload_file == PAYLOAD_OF_INTEREST) & \\\n",
    "#          (df.filename == RESULT_FOLDER1_OF_INTEREST)]\n",
    "# logger.info(f\"shape of dataframe with data for {PAYLOAD_OF_INTEREST} and {RESULT_FOLDER1_OF_INTEREST} is {df1.shape}\")\n",
    "# df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>completion_tokens</th>\n",
       "      <th>latency</th>\n",
       "      <th>question</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>completion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>results-llama3-8b-g5.12xl-tp=2-mc=max-djl-ec2</td>\n",
       "      <td>44</td>\n",
       "      <td>1.692961</td>\n",
       "      <td>Which as more species Cassiope or Deutzia?</td>\n",
       "      <td>Deutzia</td>\n",
       "      <td>{\"generated_text\": \"\\n\\nAccording to the provi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>results-llama3-8b-g5.12xl-tp=2-mc=max-djl-ec2</td>\n",
       "      <td>24</td>\n",
       "      <td>1.271467</td>\n",
       "      <td>Are Kakwa River and Bighead River located in t...</td>\n",
       "      <td>yes</td>\n",
       "      <td>{\"generated_text\": \"\\n\\nYes, Kakwa River and B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>results-llama3-8b-g5.12xl-tp=2-mc=max-djl-ec2</td>\n",
       "      <td>117</td>\n",
       "      <td>4.177421</td>\n",
       "      <td>Passage:\\nTubman: Conductor of the Underground...</td>\n",
       "      <td>National Underground Railroad Network to Freed...</td>\n",
       "      <td>{\"generated_text\": \"\\n\\nThe answer to the ques...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>results-llama3-8b-g5.12xl-tp=2-mc=max-djl-ec2</td>\n",
       "      <td>19</td>\n",
       "      <td>1.376350</td>\n",
       "      <td>Passage:\\nGummo Marx\\nMilton \"Gummo\" Marx (Oct...</td>\n",
       "      <td>Karl Marx,Karl Heinrich Marx,K. H. Marx,Marx, ...</td>\n",
       "      <td>{\"generated_text\": \"\\n\\nI don't know the answe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>results-llama3-8b-g5.12xl-tp=2-mc=max-djl-ec2</td>\n",
       "      <td>14</td>\n",
       "      <td>1.123095</td>\n",
       "      <td>Hardley Flood is an area of lagoons that suppo...</td>\n",
       "      <td>duck</td>\n",
       "      <td>{\"generated_text\": \"\\n\\nI don't know.\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>results-llama3-8b-g5.12xl-tp=2-mc=max-triton-ec2</td>\n",
       "      <td>23</td>\n",
       "      <td>1.322193</td>\n",
       "      <td>Passage:\\nGuillemot\\nGuillemots is the common ...</td>\n",
       "      <td>Sea bird,Marine birds,Sea-bird,Marine bird,Sea...</td>\n",
       "      <td>I don't know the answer to this question. The ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>results-llama3-8b-g5.12xl-tp=2-mc=max-triton-ec2</td>\n",
       "      <td>6</td>\n",
       "      <td>1.132178</td>\n",
       "      <td>Which film has the director born earlier, Dos ...</td>\n",
       "      <td>Dos Basuras</td>\n",
       "      <td>I don't know.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>results-llama3-8b-g5.12xl-tp=2-mc=max-triton-ec2</td>\n",
       "      <td>20</td>\n",
       "      <td>1.279956</td>\n",
       "      <td>Are Euptelea and Muehlenbeckia both genuses?</td>\n",
       "      <td>yes</td>\n",
       "      <td>Yes, both Euptelea and Muehlenbeckia are gener...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>results-llama3-8b-g5.12xl-tp=2-mc=max-triton-ec2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.987512</td>\n",
       "      <td>Passage:\\nHoy (boat)\\nA hoy was a  small sloop...</td>\n",
       "      <td>Blustery,Eolic,Aeolian Action,Wind Cycle,Cyclo...</td>\n",
       "      <td>I don't know.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>results-llama3-8b-g5.12xl-tp=2-mc=max-triton-ec2</td>\n",
       "      <td>11</td>\n",
       "      <td>1.049198</td>\n",
       "      <td>Passage:\\nDanube Waltz River Cruise Videos - 2...</td>\n",
       "      <td>Budimpešta,Budapest,Veres Péter Gimnázium,Buda...</td>\n",
       "      <td>I don't know the answer to this question.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>367 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              filename  completion_tokens  \\\n",
       "0        results-llama3-8b-g5.12xl-tp=2-mc=max-djl-ec2                 44   \n",
       "3        results-llama3-8b-g5.12xl-tp=2-mc=max-djl-ec2                 24   \n",
       "4        results-llama3-8b-g5.12xl-tp=2-mc=max-djl-ec2                117   \n",
       "5        results-llama3-8b-g5.12xl-tp=2-mc=max-djl-ec2                 19   \n",
       "11       results-llama3-8b-g5.12xl-tp=2-mc=max-djl-ec2                 14   \n",
       "...                                                ...                ...   \n",
       "1019  results-llama3-8b-g5.12xl-tp=2-mc=max-triton-ec2                 23   \n",
       "1020  results-llama3-8b-g5.12xl-tp=2-mc=max-triton-ec2                  6   \n",
       "1023  results-llama3-8b-g5.12xl-tp=2-mc=max-triton-ec2                 20   \n",
       "1032  results-llama3-8b-g5.12xl-tp=2-mc=max-triton-ec2                  6   \n",
       "1035  results-llama3-8b-g5.12xl-tp=2-mc=max-triton-ec2                 11   \n",
       "\n",
       "       latency                                           question  \\\n",
       "0     1.692961         Which as more species Cassiope or Deutzia?   \n",
       "3     1.271467  Are Kakwa River and Bighead River located in t...   \n",
       "4     4.177421  Passage:\\nTubman: Conductor of the Underground...   \n",
       "5     1.376350  Passage:\\nGummo Marx\\nMilton \"Gummo\" Marx (Oct...   \n",
       "11    1.123095  Hardley Flood is an area of lagoons that suppo...   \n",
       "...        ...                                                ...   \n",
       "1019  1.322193  Passage:\\nGuillemot\\nGuillemots is the common ...   \n",
       "1020  1.132178  Which film has the director born earlier, Dos ...   \n",
       "1023  1.279956       Are Euptelea and Muehlenbeckia both genuses?   \n",
       "1032  0.987512  Passage:\\nHoy (boat)\\nA hoy was a  small sloop...   \n",
       "1035  1.049198  Passage:\\nDanube Waltz River Cruise Videos - 2...   \n",
       "\n",
       "                                           ground_truth  \\\n",
       "0                                               Deutzia   \n",
       "3                                                   yes   \n",
       "4     National Underground Railroad Network to Freed...   \n",
       "5     Karl Marx,Karl Heinrich Marx,K. H. Marx,Marx, ...   \n",
       "11                                                 duck   \n",
       "...                                                 ...   \n",
       "1019  Sea bird,Marine birds,Sea-bird,Marine bird,Sea...   \n",
       "1020                                        Dos Basuras   \n",
       "1023                                                yes   \n",
       "1032  Blustery,Eolic,Aeolian Action,Wind Cycle,Cyclo...   \n",
       "1035  Budimpešta,Budapest,Veres Péter Gimnázium,Buda...   \n",
       "\n",
       "                                             completion  \n",
       "0     {\"generated_text\": \"\\n\\nAccording to the provi...  \n",
       "3     {\"generated_text\": \"\\n\\nYes, Kakwa River and B...  \n",
       "4     {\"generated_text\": \"\\n\\nThe answer to the ques...  \n",
       "5     {\"generated_text\": \"\\n\\nI don't know the answe...  \n",
       "11              {\"generated_text\": \"\\n\\nI don't know.\"}  \n",
       "...                                                 ...  \n",
       "1019  I don't know the answer to this question. The ...  \n",
       "1020                                      I don't know.  \n",
       "1023  Yes, both Euptelea and Muehlenbeckia are gener...  \n",
       "1032                                      I don't know.  \n",
       "1035          I don't know the answer to this question.  \n",
       "\n",
       "[367 rows x 6 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df1[['filename', 'completion_tokens', 'latency', 'question', 'ground_truth', 'completion']]\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_121634/3548883129.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['completion'] = df2.completion.map(extract_answer)\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict\n",
    "def extract_answer(x):\n",
    "    if \"generated_text\" in x:\n",
    "        return json.loads(x).get('generated_text')\n",
    "    return x\n",
    "df2['completion'] = df2.completion.map(extract_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>completion_tokens</th>\n",
       "      <th>latency</th>\n",
       "      <th>question</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>completion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>results-llama3-8b-g5.12xl-tp=2-mc=max-djl-ec2</td>\n",
       "      <td>44</td>\n",
       "      <td>1.692961</td>\n",
       "      <td>Which as more species Cassiope or Deutzia?</td>\n",
       "      <td>Deutzia</td>\n",
       "      <td>\\n\\nAccording to the provided context, Deutzia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>results-llama3-8b-g5.12xl-tp=2-mc=max-djl-ec2</td>\n",
       "      <td>24</td>\n",
       "      <td>1.271467</td>\n",
       "      <td>Are Kakwa River and Bighead River located in t...</td>\n",
       "      <td>yes</td>\n",
       "      <td>\\n\\nYes, Kakwa River and Bighead River are bot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>results-llama3-8b-g5.12xl-tp=2-mc=max-djl-ec2</td>\n",
       "      <td>117</td>\n",
       "      <td>4.177421</td>\n",
       "      <td>Passage:\\nTubman: Conductor of the Underground...</td>\n",
       "      <td>National Underground Railroad Network to Freed...</td>\n",
       "      <td>\\n\\nThe answer to the question \"Who presents \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>results-llama3-8b-g5.12xl-tp=2-mc=max-djl-ec2</td>\n",
       "      <td>19</td>\n",
       "      <td>1.376350</td>\n",
       "      <td>Passage:\\nGummo Marx\\nMilton \"Gummo\" Marx (Oct...</td>\n",
       "      <td>Karl Marx,Karl Heinrich Marx,K. H. Marx,Marx, ...</td>\n",
       "      <td>\\n\\nI don't know the answer to this question.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>results-llama3-8b-g5.12xl-tp=2-mc=max-djl-ec2</td>\n",
       "      <td>14</td>\n",
       "      <td>1.123095</td>\n",
       "      <td>Hardley Flood is an area of lagoons that suppo...</td>\n",
       "      <td>duck</td>\n",
       "      <td>\\n\\nI don't know.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>results-llama3-8b-g5.12xl-tp=2-mc=max-triton-ec2</td>\n",
       "      <td>23</td>\n",
       "      <td>1.322193</td>\n",
       "      <td>Passage:\\nGuillemot\\nGuillemots is the common ...</td>\n",
       "      <td>Sea bird,Marine birds,Sea-bird,Marine bird,Sea...</td>\n",
       "      <td>I don't know the answer to this question. The ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>results-llama3-8b-g5.12xl-tp=2-mc=max-triton-ec2</td>\n",
       "      <td>6</td>\n",
       "      <td>1.132178</td>\n",
       "      <td>Which film has the director born earlier, Dos ...</td>\n",
       "      <td>Dos Basuras</td>\n",
       "      <td>I don't know.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>results-llama3-8b-g5.12xl-tp=2-mc=max-triton-ec2</td>\n",
       "      <td>20</td>\n",
       "      <td>1.279956</td>\n",
       "      <td>Are Euptelea and Muehlenbeckia both genuses?</td>\n",
       "      <td>yes</td>\n",
       "      <td>Yes, both Euptelea and Muehlenbeckia are gener...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>results-llama3-8b-g5.12xl-tp=2-mc=max-triton-ec2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.987512</td>\n",
       "      <td>Passage:\\nHoy (boat)\\nA hoy was a  small sloop...</td>\n",
       "      <td>Blustery,Eolic,Aeolian Action,Wind Cycle,Cyclo...</td>\n",
       "      <td>I don't know.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>results-llama3-8b-g5.12xl-tp=2-mc=max-triton-ec2</td>\n",
       "      <td>11</td>\n",
       "      <td>1.049198</td>\n",
       "      <td>Passage:\\nDanube Waltz River Cruise Videos - 2...</td>\n",
       "      <td>Budimpešta,Budapest,Veres Péter Gimnázium,Buda...</td>\n",
       "      <td>I don't know the answer to this question.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>367 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              filename  completion_tokens  \\\n",
       "0        results-llama3-8b-g5.12xl-tp=2-mc=max-djl-ec2                 44   \n",
       "3        results-llama3-8b-g5.12xl-tp=2-mc=max-djl-ec2                 24   \n",
       "4        results-llama3-8b-g5.12xl-tp=2-mc=max-djl-ec2                117   \n",
       "5        results-llama3-8b-g5.12xl-tp=2-mc=max-djl-ec2                 19   \n",
       "11       results-llama3-8b-g5.12xl-tp=2-mc=max-djl-ec2                 14   \n",
       "...                                                ...                ...   \n",
       "1019  results-llama3-8b-g5.12xl-tp=2-mc=max-triton-ec2                 23   \n",
       "1020  results-llama3-8b-g5.12xl-tp=2-mc=max-triton-ec2                  6   \n",
       "1023  results-llama3-8b-g5.12xl-tp=2-mc=max-triton-ec2                 20   \n",
       "1032  results-llama3-8b-g5.12xl-tp=2-mc=max-triton-ec2                  6   \n",
       "1035  results-llama3-8b-g5.12xl-tp=2-mc=max-triton-ec2                 11   \n",
       "\n",
       "       latency                                           question  \\\n",
       "0     1.692961         Which as more species Cassiope or Deutzia?   \n",
       "3     1.271467  Are Kakwa River and Bighead River located in t...   \n",
       "4     4.177421  Passage:\\nTubman: Conductor of the Underground...   \n",
       "5     1.376350  Passage:\\nGummo Marx\\nMilton \"Gummo\" Marx (Oct...   \n",
       "11    1.123095  Hardley Flood is an area of lagoons that suppo...   \n",
       "...        ...                                                ...   \n",
       "1019  1.322193  Passage:\\nGuillemot\\nGuillemots is the common ...   \n",
       "1020  1.132178  Which film has the director born earlier, Dos ...   \n",
       "1023  1.279956       Are Euptelea and Muehlenbeckia both genuses?   \n",
       "1032  0.987512  Passage:\\nHoy (boat)\\nA hoy was a  small sloop...   \n",
       "1035  1.049198  Passage:\\nDanube Waltz River Cruise Videos - 2...   \n",
       "\n",
       "                                           ground_truth  \\\n",
       "0                                               Deutzia   \n",
       "3                                                   yes   \n",
       "4     National Underground Railroad Network to Freed...   \n",
       "5     Karl Marx,Karl Heinrich Marx,K. H. Marx,Marx, ...   \n",
       "11                                                 duck   \n",
       "...                                                 ...   \n",
       "1019  Sea bird,Marine birds,Sea-bird,Marine bird,Sea...   \n",
       "1020                                        Dos Basuras   \n",
       "1023                                                yes   \n",
       "1032  Blustery,Eolic,Aeolian Action,Wind Cycle,Cyclo...   \n",
       "1035  Budimpešta,Budapest,Veres Péter Gimnázium,Buda...   \n",
       "\n",
       "                                             completion  \n",
       "0     \\n\\nAccording to the provided context, Deutzia...  \n",
       "3     \\n\\nYes, Kakwa River and Bighead River are bot...  \n",
       "4     \\n\\nThe answer to the question \"Who presents \"...  \n",
       "5         \\n\\nI don't know the answer to this question.  \n",
       "11                                    \\n\\nI don't know.  \n",
       "...                                                 ...  \n",
       "1019  I don't know the answer to this question. The ...  \n",
       "1020                                      I don't know.  \n",
       "1023  Yes, both Euptelea and Muehlenbeckia are gener...  \n",
       "1032                                      I don't know.  \n",
       "1035          I don't know the answer to this question.  \n",
       "\n",
       "[367 rows x 6 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = {}\n",
    "dont_know_type_responses = {}\n",
    "valid_responses = {}\n",
    "for f in unique_result_files_list:\n",
    "    dont_know_type_responses[f] = 0\n",
    "    valid_responses[f] = 0\n",
    "for r in df2.iterrows():\n",
    "    r = r[1]\n",
    "    if r['question'] not in comparison:\n",
    "        comparison[r['question']] = []\n",
    "    r = dict(r)    \n",
    "    comparison[r['question']].append(r)\n",
    "    if 'don\\'t know' in r['completion']:\n",
    "        dont_know_type_responses[r['filename']] += 1\n",
    "    else:\n",
    "        valid_responses[r['filename']] += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-09-23 20:35:14,571] p121634 {2041944104.py:1} INFO - dont_know_type_responses={'results-llama3-8b-g5.12xl-tp=2-mc=max-triton-ec2': 48, 'results-llama3-8b-g5.12xl-tp=2-mc=max-djl-ec2': 233}\n",
      "valid_responses={'results-llama3-8b-g5.12xl-tp=2-mc=max-triton-ec2': 16, 'results-llama3-8b-g5.12xl-tp=2-mc=max-djl-ec2': 70}\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"dont_know_type_responses={dont_know_type_responses}\\nvalid_responses={valid_responses}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "615563"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path(\"comparison.json\").write_text(json.dumps(comparison, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"filename\": \"results-llama3-8b-g5.12xl-tp=2-mc=max-djl-ec2\",\n",
      "    \"completion_tokens\": 44,\n",
      "    \"latency\": 1.6929611009982182,\n",
      "    \"question\": \"Which as more species Cassiope or Deutzia?\",\n",
      "    \"ground_truth\": \"Deutzia\",\n",
      "    \"completion\": \"\\n\\nAccording to the provided context, Deutzia has about 60 species, while Cassiope has 9-12 species. Therefore, Deutzia has more species.\"\n",
      "  },\n",
      "  {\n",
      "    \"filename\": \"results-llama3-8b-g5.12xl-tp=2-mc=max-djl-ec2\",\n",
      "    \"completion_tokens\": 48,\n",
      "    \"latency\": 4.967612214997644,\n",
      "    \"question\": \"Which as more species Cassiope or Deutzia?\",\n",
      "    \"ground_truth\": \"Deutzia\",\n",
      "    \"completion\": \"\\n\\nAccording to the provided context, Deutzia has about 60 species, while Cassiope has 9-12 species. Therefore, Deutzia has more species than Cassiope.\"\n",
      "  },\n",
      "  {\n",
      "    \"filename\": \"results-llama3-8b-g5.12xl-tp=2-mc=max-djl-ec2\",\n",
      "    \"completion_tokens\": 48,\n",
      "    \"latency\": 2.8179733110009693,\n",
      "    \"question\": \"Which as more species Cassiope or Deutzia?\",\n",
      "    \"ground_truth\": \"Deutzia\",\n",
      "    \"completion\": \"\\n\\nAccording to the provided context, Cassiope has 9-12 species, while Deutzia has about 60 species. Therefore, Deutzia has more species than Cassiope.\"\n",
      "  },\n",
      "  {\n",
      "    \"filename\": \"results-llama3-8b-g5.12xl-tp=2-mc=max-djl-ec2\",\n",
      "    \"completion_tokens\": 44,\n",
      "    \"latency\": 1.5979820789980295,\n",
      "    \"question\": \"Which as more species Cassiope or Deutzia?\",\n",
      "    \"ground_truth\": \"Deutzia\",\n",
      "    \"completion\": \"\\n\\nAccording to the provided context, Deutzia has about 60 species, while Cassiope has 9-12 species. Therefore, Deutzia has more species.\"\n",
      "  },\n",
      "  {\n",
      "    \"filename\": \"results-llama3-8b-g5.12xl-tp=2-mc=max-djl-ec2\",\n",
      "    \"completion_tokens\": 48,\n",
      "    \"latency\": 3.5731225259987696,\n",
      "    \"question\": \"Which as more species Cassiope or Deutzia?\",\n",
      "    \"ground_truth\": \"Deutzia\",\n",
      "    \"completion\": \"\\n\\nAccording to the provided context, Cassiope has 9-12 species, while Deutzia has about 60 species. Therefore, Deutzia has more species than Cassiope.\"\n",
      "  },\n",
      "  {\n",
      "    \"filename\": \"results-llama3-8b-g5.12xl-tp=2-mc=max-triton-ec2\",\n",
      "    \"completion_tokens\": 40,\n",
      "    \"latency\": 1.5886268419999396,\n",
      "    \"question\": \"Which as more species Cassiope or Deutzia?\",\n",
      "    \"ground_truth\": \"Deutzia\",\n",
      "    \"completion\": \"According to the provided context, Cassiope has 9-12 species, while Deutzia has about 60 species. Therefore, Deutzia has more species than Cassiope.\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "for k in comparison.keys():\n",
    "    print(json.dumps(comparison[k], indent=2))\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}


================================================
File: /analytics/pricing.yml
================================================
pricing:
  instance_based:
    # Instance Based Pricing: SageMaker, EKS, Bedrock Provisioned Throughput, Bring your own endpoints that are priced hourly
    # SageMaker Hourly Instance Pricing
    ml.m5.xlarge: 0.23
    ml.g5.xlarge: 1.4084
    ml.g5.2xlarge: 1.515
    ml.g5.12xlarge: 7.09
    ml.g5.24xlarge: 10.18
    ml.g5.48xlarge: 20.36
    ml.inf2.xlarge: 0.99
    ml.inf2.8xlarge: 2.36
    ml.inf2.24xlarge: 7.79
    ml.inf2.48xlarge: 15.58
    ml.trn1.32xlarge: 28.497
    ml.p4d.24xlarge: 37.688
    ml.p5.48xlarge: 113.068
    ml.p3.2xlarge: 3.825
    ml.g4dn.12xlarge: 4.89
    ml.g6.2xlarge: 1.222
    ml.g6.16xlarge: 4.246
    ml.g6.12xlarge: 5.752
    ml.g6.24xlarge: 8.344
    ml.g6.48xlarge: 16.688
    anthropic.claude-v3-sonnet-pt-nc: 88
    # corresponding hourly pricing for EC2 instances if your model is hosted on EC2
    # all EC2 pricing is based on public on-demand pricing information that can be 
    # viewed in this link: https://aws.amazon.com/ec2/pricing/on-demand/
    m5.16xlarge: 3.072
    c5.18xlarge: 3.06
    m7i.12xlarge: 2.419
    m7a.4xlarge: 0.9274
    m7a.16xlarge: 3.709
    m7a.24xlarge: 5.564
    m5.xlarge: 0.192
    g5.xlarge: 1.006
    g5.4xlarge: 1.624
    g5.2xlarge: 1.212
    g5.12xlarge: 5.672
    g5.24xlarge: 8.144
    g5.48xlarge: 16.288
    inf2.xlarge: 0.7582
    inf2.8xlarge: 1.96786
    inf2.24xlarge: 6.49063
    inf2.48xlarge: 12.98127
    trn1.32xlarge: 21.50
    p4d.24xlarge: 32.7726
    p4de.24xlarge: 40.965
    p5.48xlarge: 98.32
    p5e.48xlarge: 122.5
    p3.2xlarge: 3.06
    g4dn.12xlarge: 3.912
    g6.2xlarge: 0.9776
    g6.16xlarge: 3.3968
    g6.12xlarge: 4.6016
    g6.24xlarge: 6.6752
    g6.48xlarge: 13.3504
    g6e.2xlarge: 2.242
    g6e.4xlarge: 3.1294
    g6e.12xlarge: 10.493
    g6e.16xlarge: 7.577
    g6e.24xlarge: 15.066
    g6e.48xlarge: 30.131


  token_based:
    # Token Based Pricing: Bedrock
    anthropic.claude-3-haiku-20240307-v1:0:
      input-per-1k-tokens: 0.00025
      output-per-1k-tokens: 0.00125
    anthropic.claude-3-sonnet-20240229-v1:0:
      input-per-1k-tokens: 0.00300
      output-per-1k-tokens: 0.01500
    anthropic.claude-v2:1:
      input-per-1k-tokens: 0.008
      output-per-1k-tokens: 0.024
    anthropic.claude-instant-v1:
      input-per-1k-tokens: 0.0008
      output-per-1k-tokens: 0.0024
    anthropic.claude-v2:
      input-per-1k-tokens: 0.008
      output-per-1k-tokens: 0.024
    # Titan
    amazon.titan-text-lite-v1: 
      input-per-1k-tokens: 0.00015
      output-per-1k-tokens: 0.0002
    amazon.titan-text-express-v1: 
      input-per-1k-tokens: 0.0002
      output-per-1k-tokens: 0.0006
    # Mistral & Mixtral
    mistral.mistral-7b-instruct-v0:2:
      input-per-1k-tokens: 0.00015
      output-per-1k-tokens: 0.0002
    mistral.mixtral-8x7b-instruct-v0:1: 
      input-per-1k-tokens: 0.00045
      output-per-1k-tokens: 0.0007
    ## Llama
    meta.llama3-1-8b-instruct-v1:0:
      input-per-1k-tokens: 0.00022
      output-per-1k-tokens: 0.00022
    meta.llama3-1-70b-instruct-v1:0:
      input-per-1k-tokens: 0.00265
      output-per-1k-tokens: 0.0035
    meta.llama3-1-405b-instruct-v1:0:
      input-per-1k-tokens: 0.00532
      output-per-1k-tokens: 0.016
    meta.llama3-8b-instruct-v1:0:
      input-per-1k-tokens: 0.0003
      output-per-1k-tokens: 0.0006
    meta.llama3-70b-instruct-v1:0:
      input-per-1k-tokens: 0.00265
      output-per-1k-tokens: 0.0035
    meta.llama2-13b-chat-v1:
      input-per-1k-tokens: 0.00075
      output-per-1k-tokens: 0.00100      
    meta.llama2-70b-chat-v1: 
      input-per-1k-tokens: 0.00195
      output-per-1k-tokens: 0.00256
      
    #  ai21
    ai21.j2-mid-v1:
      input-per-1k-tokens: 0.0125
      output-per-1k-tokens: 0.0125
    ai21.j2-ultra-v1: 
      input-per-1k-tokens: 0.0188
      output-per-1k-tokens: 0.0188
    # Cohere
    cohere.command-text-v14: 
      input-per-1k-tokens: 0.0015
      output-per-1k-tokens: 0.0020
    cohere.command-light-text-v14: 
      input-per-1k-tokens: 0.0003
      output-per-1k-tokens: 0.0006
    cohere.command-r-plus-v1:0:
      input-per-1k-tokens: 0.0030
      output-per-1k-tokens: 0.0150


================================================
File: /analytics/sagemaker_cost_rpm_plot.py
================================================
import re
import logging
import pandas as pd
import seaborn as sns
from typing import List
import matplotlib.pyplot as plt
import plotly.graph_objects as go

# Configure logging
logging.basicConfig(format='[%(asctime)s] p%(process)s {%(filename)s:%(lineno)d} %(levelname)s - %(message)s', level=logging.INFO)
logger = logging.getLogger(__name__)


def _pre_process_df(summary_payload_df: pd.DataFrame) -> tuple[pd.DataFrame, List]:
    """
    Pre-processes the summary payload DataFrame to extract relevant data for plotting.

    Args:
        summary_payload_df (pd.DataFrame): Input DataFrame containing instance data.

    Returns:
        tuple: A tuple containing the processed DataFrame and a list of RPM values.
    """
    logger.info("======================================")
    logger.info(f"Loaded dataframe, shape is: {summary_payload_df.shape}")
    logger.info("======================================")

    rpm_values = []
    # Dynamically extract RPM values based on DataFrame columns
    for name in summary_payload_df.columns:
        print(name)
        match = re.search(r'(\d+)_rpm', name)
        if match:
            rpm_values.append(int(match.group(1)))

    logger.info("======================================")
    logger.info(f"RPM Values extracted: {rpm_values}")
    logger.info("======================================")

    rows = []
    # Extract and reformat data for each RPM value
    for index, row in summary_payload_df.iterrows():
        for value in rpm_values:
            column = f'instance_count_and_cost_{value}_rpm'
            count, cost = tuple(v.lstrip("('").rstrip("')") for v in row[column].split(", "))
            rows.append({'instance_type': row['instance_type'],
                         'instance_count': int(count),
                         'RPM': value,
                         'cost': float(cost),
                         'TPM': row['transactions_per_minute'],
                         'TP_Degree': row['tensor_parallel_degree']})

    plot_df = pd.DataFrame(rows)

    logger.info("======================================")
    logger.info(f"Completed pre-processing the data, new dataframe shape: {plot_df.shape}")
    logger.info("======================================")

    return plot_df, rpm_values


def plot_best_cost_instance_heatmap(summary_payload_df: pd.DataFrame,
                                    output_filename: str,
                                    model_id: str,
                                    subtitle: str,
                                    cost_weight: float,
                                    instance_count_weight: float) -> go.Figure:
    """
    Creates a heatmap plot to visualize the cost of running different instance types at various RPM values.

    Args:
        summary_payload_df (pd.DataFrame): Input DataFrame containing instance data.

    Returns:
        go.Figure: Plotly heatmap figure object.
    """

    logger.info(summary_payload_df.columns)
    plot_df, rpm_values = _pre_process_df(summary_payload_df)

    logger.info("======================================")
    logger.info(f"Processed dataframe, shape is: {plot_df.shape}")
    logger.info(f"RPM Values loaded are: {rpm_values}")
    logger.info("======================================")

    heatmap_data = plot_df.pivot(index="RPM", columns="instance_type", values="cost")
    heatmap_data.index = heatmap_data.index.astype(str)

    # Sorting instance types by cost in ascending order for RPM = 1
    sorted_columns = heatmap_data.loc['1'].sort_values().index
    heatmap_data = heatmap_data[sorted_columns]

    heatmap_data_instance_count = plot_df.pivot(index="RPM", 
                                                columns="instance_type",
                                                values="instance_count")
    heatmap_data_instance_count = heatmap_data_instance_count[sorted_columns]

    # Create hover text for the heatmap
    hover_text_combined = []
    for i in range(heatmap_data.shape[0]):
        row = []
        for j in range(heatmap_data.shape[1]):
            rpm = heatmap_data.index[i]
            instance_type = heatmap_data.columns[j]
            cost = heatmap_data.iloc[i, j]
            instance_count = heatmap_data_instance_count.iloc[i, j]
            hover_text = (
                f'Instance Type: {instance_type}<br>'
                f'Instance Count: {instance_count}<br>'
                f'Cost: ${cost}<br>'
                f'RPM: {rpm}'
            )
            row.append(hover_text)
        hover_text_combined.append(row)

    text_arr = heatmap_data.values.copy().astype(str)

    logger.info("======================================")
    logger.info("Adding annotations")
    logger.info("======================================")

    # Annotate the heatmap with additional information
    for i, (cost_row, instance_count_row) in enumerate(zip(heatmap_data.values,
                                                           heatmap_data_instance_count.values)):
        min_cost_idx = cost_row.argmin()
        min_inst_idx = instance_count_row.argmin()
        normalized_val = (cost_weight * (cost_row / cost_row.max())) +\
                         (instance_count_weight * (instance_count_row / instance_count_row.max()))
        normalized_idx = normalized_val.argmin()

        text_arr[i, min_cost_idx] = f"<b>{cost_row[min_cost_idx]:.2f}<br>(least cost)"
        text_arr[i, min_inst_idx] = f"<b>{cost_row[min_inst_idx]:.2f}<br>(fewest instances)"
        text_arr[i, normalized_idx] = f"<b>{cost_row[normalized_idx]:.2f}<br>(best choice)"

    # Create the heatmap
    fig = go.Figure(data=go.Heatmap(
        z=heatmap_data.values,
        x=heatmap_data.columns,
        y=heatmap_data.index,
        colorscale='Dense',
        colorbar=dict(title="Cost"),
        zmin=heatmap_data.values.min(),
        zmax=heatmap_data.values.max(),
        text=text_arr,
        texttemplate="$%{text}",
        hovertext=hover_text_combined,
        hovertemplate='%{hovertext}<extra></extra>'
    ))

    num_rows, num_cols = heatmap_data.shape
    dynamic_font_size = _calculate_dynamic_font_size(num_rows, num_cols)
    fig.update_traces(textfont=dict(size=dynamic_font_size))

    logger.info("======================================")
    logger.info("Updating layout for better visualization")
    logger.info("======================================")

    # Update layout for better visualization
    fig.update_layout(
        title=f"Serving costs for \"{model_id}\" for different requests/minute and instance options<br>{subtitle}<br>Hover your mouse over a cell for additional information.",
        xaxis_title="",
        yaxis_title="Requests/minute",
        autosize=True,
        width=1500,
        height=700, 
        font=dict(size=dynamic_font_size)
    )

    fig.update_traces(textfont_size=dynamic_font_size)
    
    fig.add_annotation(
       showarrow=False,
       xanchor='left',
       xref='paper', 
       x=0, 
       yref='paper',
       y=-0.15,
       text=f"Note: <b><i>best choice</i></b> based on {100*cost_weight}% weightage to cost and {100*instance_count_weight}% to number of instances needed. <b><i>least cost</i></b> and <b><i>fewest instances</i></b> called out only when different from <b><i>best choice</i></b>.",
       font=dict(size=max(dynamic_font_size - 2, 8)))

    # Save the figure as an HTML file
    fig.write_html(output_filename)

    logger.info("======================================")
    logger.info(f"Heatmap plotting completed, saved to {output_filename}")
    logger.info("======================================")

    return fig

def plot_tps_vs_cost(df: pd.DataFrame,
                     output_filename: str,
                     model_id: str,
                     subtitle: str) -> go.Figure:
    """
    Creates an interactive line chart to visualize the cost per second vs transactions per second
    for different instance types.

    Args:
        df (pd.DataFrame): Input DataFrame containing instance data.
        output_filename (str): Name of the file to save the plot.
        model_id (str): ID of the model being analyzed.
        subtitle (str): Subtitle for the plot.

    Returns:
        go.Figure: Plotly figure object.
    """
    # Calculate transactions per second for each instance type
    df['transactions_per_second'] = df['transactions_per_minute'] / 60
    
    # Calculate cost per second
    df['cost_per_second'] = df['transactions_per_second'] * df['cost_per_txn']

    # Create the plot
    fig = go.Figure()

    # Add line traces for each instance type
    for instance_type, group in df.groupby('instance_type'):
        # Sort the group by TPS to ensure proper line connection
        group = group.sort_values('transactions_per_second')
        
        fig.add_trace(go.Scatter(
            x=group['transactions_per_second'],
            y=group['cost_per_second'],
            mode='lines+markers',
            name=instance_type,
            line=dict(shape='linear', width=2),  # Ensure linear interpolation and set line width
            marker=dict(size=8),  # Marker size
            connectgaps=True,
            hoverinfo='text',
            hovertext=[f"Instance Type: {instance_type}<br>"
                       f"TPS: {tps:.2f}<br>"
                       f"Cost per Second: ${cost_per_sec:.4f}<br>"
                       f"Cost per Txn: ${cost_per_txn:.4f}<br>"
                       f"Transactions per Minute: {tpm:.0f}"
                       for tps, cost_per_sec, cost_per_txn, tpm in zip(group['transactions_per_second'], 
                                                                       group['cost_per_second'],
                                                                       group['cost_per_txn'],
                                                                       group['transactions_per_minute'])]
        ))

    # Customize the plot
    fig.update_layout(
        title=f"Cost per Second vs TPS for {model_id}<br>{subtitle}",
        xaxis_title="Transactions Per Second (TPS)",
        yaxis_title="Cost per Second ($)",
        legend_title="Instance Type",
        font=dict(size=14),
        hovermode="closest",
        hoverdistance=10,  # Increase hover "snapping" distance
    )

    # Update axes to show more gridlines
    fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='LightGrey')
    fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='LightGrey')

    # Save the plot as an HTML file
    fig.write_html(output_filename)
    logger.info(f"Interactive TPS vs Cost per Second plot saved as {output_filename}")

    return fig

def _calculate_dynamic_font_size(num_rows: int, num_cols: int):
    """
    Adjust the dynamic font size of the text in the heatmap based on the number of rows
    and columns
    """
    base_size: int = 14
    scale_factor = min(1000 / max(num_rows, num_cols), 1)
    # Ensure minimum font size of 10
    return max(int(base_size * scale_factor), 10)


================================================
File: /analytics/analytics.py
================================================
"""
Analyze data across multiple fmbench runs
"""
import re
import os
import sys
import math
import glob
import json
import yaml
import logging
import argparse
import pandas as pd
from pathlib import Path
from tomark import Tomark
from sagemaker_cost_rpm_plot import plot_best_cost_instance_heatmap, plot_tps_vs_cost

logging.basicConfig(format='[%(asctime)s] p%(process)s {%(filename)s:%(lineno)d} %(levelname)s - %(message)s', level=logging.INFO)
logger = logging.getLogger(__name__)


RPM_LIST_CSV="1,10,100,1000,10000"
# default values for latency and concurrency thresholds. To configure the summary table
# based on custom thresholds, add them as command line arguments
LATENCY_THRESHOLD: int = 2
CONCURRENCY_THRESHOLD: int = 1
ANALYTICS_RESULTS_DIR: str = os.path.join("analytics", "results")
os.makedirs(ANALYTICS_RESULTS_DIR, exist_ok=True)
PAYLOAD_FILE_OF_INTEREST: str = "payload_en_1000-2000.jsonl"
PRICING_FILE_PATH: str = os.path.join("analytics", "pricing.yml")
DEFAULT_COST_WEIGHT: float = 0.6

def cost_per_txn(row, pricing):
    txns_per_hour = row['transactions_per_minute'] * 60
    if pricing['pricing']['instance_based'].get(row['instance_type']) is not None:
        instance_cost_per_hour = pricing['pricing']['instance_based'][row['instance_type']]
        cost_per_txn = round(instance_cost_per_hour / txns_per_hour, 4)
    else:
        input_token_cost = pricing['pricing']['token_based'][row['instance_type']]['input-per-1k-tokens']
        output_token_cost = pricing['pricing']['token_based'][row['instance_type']]['output-per-1k-tokens']
        cost_per_txn = (row['prompt_token_count_mean']/1000) * input_token_cost + \
                       (row['completion_token_count_mean']/1000) * output_token_cost
        cost_per_txn = round(cost_per_txn, 4)
    return cost_per_txn


def cost_per_1k_tokens(row, pricing):
    txns_per_hour = row['transactions_per_minute'] * 60
    tokens_per_hour = (row['prompt_token_count_mean'] + row['completion_token_count_mean']) * txns_per_hour
    if pricing['pricing']['instance_based'].get(row['instance_type']) is not None:
        instance_cost_per_hour = pricing['pricing']['instance_based'][row['instance_type']]
        cost_per_1k_tokens = round(1000 * (instance_cost_per_hour / tokens_per_hour), 8)
    else:
        input_token_cost = pricing['pricing']['token_based'][row['instance_type']]['input-per-1k-tokens']
        output_token_cost = pricing['pricing']['token_based'][row['instance_type']]['output-per-1k-tokens']
        total_tokens = row['prompt_token_count_mean'] + row['completion_token_count_mean']

        cost_per_1k_tokens = (row['prompt_token_count_mean'] / total_tokens) * input_token_cost + \
                             (row['completion_token_count_mean'] / total_tokens) * output_token_cost
        cost_per_1k_tokens = round(cost_per_1k_tokens, 8)
    return cost_per_1k_tokens

def parse_yaml_config(file_path):
    """
    This function parses a yaml file in the results folder (that represents the configuration file that was used to benchmark)
    and extracts the tensor parallel degree, batch size, and the config file name.
    """
    config_file_properties: Optional[Dict] = None
    tensor_parallel_degree: Optional[str] = None
    batch_size: Optional[int] = None
    serving_properties: Optional[str] = None
    model_copies: Optional[str] = None
    image_uri: Optional[str] = None
    try:
        with open(file_path, 'r') as file:
            config = yaml.safe_load(file)
            logger.info(f"Loaded the configuration file: {config}")
        experiment_config = config.get('experiments', [])
        if isinstance(experiment_config, list) and len(experiment_config) == 1:
            serving_properties = experiment_config[0].get('serving.properties', None)
            image_uri = experiment_config[0].get('image_uri', None)
            if serving_properties:
                logger.info(f"serving_properties: {serving_properties}.")
                tp_match = re.search(r'option\.tensor_parallel_degree=(\d+)', serving_properties)
                if tp_match:
                    tensor_parallel_degree = str(tp_match.group(1))

                model_copies = experiment_config[0]['inference_spec'].get('model_copies', None)

                bs_match = re.search(r'option\.max_rolling_batch_size=(\d+)', serving_properties)
                if bs_match:
                    batch_size = int(bs_match.group(1))
            else:
                logger.error("No 'serving.properties' found in the experiment configuration.")
        else:
            logger.error(f"Experiment configuration is list or the number of experiments is not 1, num experiments={len(experiment_config)}")
        config_file_properties = dict(config_file=os.path.basename(file_path),
                                      image_uri=image_uri,
                                      tensor_parallel_degree=tensor_parallel_degree,
                                      batch_size=batch_size,
                                      model_copies=model_copies)
        
    except Exception as e:
        logger.error(f"Error parsing the config file {file_path}: {e}")
        config_file_properties = None
    logger.info(f"config_file_properties={config_file_properties}")
    return config_file_properties

# Determine how many instances would be required to run 100 requests/minute,
# 1000 requests/minute, 10000 requests/minute. The idea being that at the 
# low end of the total number of requests/minute smaller instances which provide
# good inference latency at low concurrencies would suffice (said another way, 
# the larger more expensive instances are an overkill at this stage) but as 
# the number of requests/minute increase there comes an inflexion point beyond
# which the number of smaller instances required would be so much that it 
# would be more economical to use fewer instances of the larger more expensive instances.
def cost_per_n_rpm(r, rpm, pricing):
    if pricing['pricing']['instance_based'].get(r['instance_type']):
        instance_count_needed = math.ceil(rpm / r['transactions_per_minute'])
        cost = round(instance_count_needed * pricing['pricing']['instance_based'][r['instance_type']], 2)
    else:
        input_token_cost = pricing['pricing']['token_based'][r['instance_type']]['input-per-1k-tokens']
        output_token_cost = pricing['pricing']['token_based'][r['instance_type']]['output-per-1k-tokens']
        total_tokens = r['prompt_token_count_mean'] + r['completion_token_count_mean']

        cost_per_txn = (r['prompt_token_count_mean']/1000) * input_token_cost + \
                             (r['completion_token_count_mean']/1000) * output_token_cost
        #txn_per_hour = r['transactions_per_minute'] * 60
        txn_per_hour = rpm * 60
        cost = round(cost_per_txn * txn_per_hour, 8)
        instance_count_needed = 1

    return (instance_count_needed, cost)



def main():
    parser = argparse.ArgumentParser(description='Analyze multiple FMBench runs')
    parser.add_argument('--results-dir',
                        type=str,
                        help=f'Root directory containing results-* folders',
                        required=True)

    parser.add_argument('--exclude-pattern',
                        type=str,
                        default=None,
                        help=f'Exclude result folders matching this pattern, default is None',
                        required=False)
                        
    parser.add_argument('--latency-threshold',
                        type=int,
                        default=LATENCY_THRESHOLD,
                        help=f'Latency threshold, runs with p95 above this are not useful, default={LATENCY_THRESHOLD}',
                        required=False)
    parser.add_argument('--concurrency-threshold', 
                        type=int, 
                        default=CONCURRENCY_THRESHOLD, 
                        help=f'Concurrency threshold, runs with the number of concurrent requests handled under this are not useful, default={CONCURRENCY_THRESHOLD}')
    parser.add_argument('--payload-file',
                        type=str,
                        default=PAYLOAD_FILE_OF_INTEREST,
                        help=f'Payload file representing payload of interest, default={PAYLOAD_FILE_OF_INTEREST}',
                        required=False)
    # the model id is a required field. This model_id must match the model_id in your results folders so it is 
    # used during creating the summary table
    parser.add_argument('--model-id',
                        type=str,
                        help=f'Model for which data is being analyzed, this is a required field',
                        required=True)
    parser.add_argument('--cost-weight',
                        type=float,
                        default=DEFAULT_COST_WEIGHT,
                        help=f"Weightage to assign to cost while choosing best instance type, "
                             f"instance count is assigned \"1 - cost weightage\" automatically, "
                             f"default={DEFAULT_COST_WEIGHT}",
                        required=False)
    parser.add_argument('--rpm-list',
                        type=str,
                        default=RPM_LIST_CSV,
                        help=f"comma separate list of requests/minute for which we need to get price performance, "
                             f"default={RPM_LIST_CSV}",
                        required=False)
    parser.add_argument('--results-dir-indirection-level',
                        type=int,
                        default=1,
                        help=f"How many levels inside the results directory are the actual results folder, "
                            f"default=1",
                        required=False)
    args = parser.parse_args()
    print(f"main, {args} = args")

    ANALYTICS_RESULTS_DIR: str = os.path.join("analytics", args.results_dir)
    os.makedirs(ANALYTICS_RESULTS_DIR, exist_ok=True)

    # load pricing info
    pricing =  yaml.safe_load(Path(PRICING_FILE_PATH).read_text())
    logger.info(f"pricing={json.dumps(pricing, indent=2)}")

    # all results file to be parsed
    if args.results_dir_indirection_level == 1:
        summary_file_pattern: str = os.path.join(args.results_dir, "*",
                                                 f"results-{args.model_id}-*",
                                                 "all_metrics_summary.csv")
    else:
        summary_file_pattern: str = os.path.join(args.results_dir,
                                                 f"results-{args.model_id}-*",
                                                 "all_metrics_summary.csv")
    all_metrics_summary_files = glob.glob(summary_file_pattern,
                                          recursive=True)
    if args.exclude_pattern is not None:
        all_metrics_summary_files = [f for f in all_metrics_summary_files if args.exclude_pattern not in f]
    files_found: int = len(all_metrics_summary_files)
    logger.info(f"found {files_found} files "
                f"{all_metrics_summary_files} ")
    if files_found == 0:
        logger.error(f"no file found using the following pattern={summary_file_pattern}, exiting")
        sys.exit(1)

    # config file that was used to create the benchmarks
    # in each results diredctory there is a .yml file which is the config file
    result_and_configfile_combinations = []
    for f in all_metrics_summary_files:
        d = str(Path(f).parents[0].absolute())
        config_files = glob.glob(os.path.join(d, '*.yml'))
        if len(config_files) == 0:
            logger.error(f"no config file found in {d}")            
        else:
            result_and_configfile_combinations.append((f, config_files[0]))
    combined_data = []

    logger.info(f"there are {len(result_and_configfile_combinations)} result and config file combinations")

    for result_file, config_file in result_and_configfile_combinations: 
        #zip(all_metrics_summary_files, possible_config_files):
        # Read result and configuration files
        logger.info(f"result_file={result_file},\nconfig_file={config_file}")
        result_df = pd.read_csv(result_file)
        config_info = parse_yaml_config(config_file)
        if config_info:
            config_df = pd.DataFrame([config_info])
            logger.info(f"config_df: {config_df}")
            # match the length of result_df to concat the config file vars to the corresponding 
            # results folder
            config_df_repeated = pd.concat([config_df] * len(result_df), ignore_index=True)
            combined_df = pd.concat([result_df, config_df_repeated], axis=1)
            combined_data.append(combined_df)
        else:
            logger.warning(f"No config data found for {config_file}, using result only.")
            combined_data.append(result_df)
    df = pd.concat(combined_data, ignore_index=True)
    logger.info(f"Final dataframe: {df}")

    # filter to keep only relevant data
    logger.info(f"df columns: {df.columns}")
    # filter for the p95 latency threshold and the concurrency threshold

    df_selected = df[(df.latency_p95 <= args.latency_threshold) & (df.concurrency >= args.concurrency_threshold) & (df.error_rate == 0)]
    logger.info(f"after filtering to keep rows with latency_p95 <= ",
                f"{args.latency_threshold}s, concurrency <=",
                f"{args.concurrency_threshold}",
                f"df shape {df_selected.shape}")


    # select row with highest concurrency level
    grouping_cols = ["experiment_name", "payload_file", "instance_type", "instance_count"]
    # adding selected metrics for when the concurrency is the highest and the completion tokens are given out, indicating valid responses
    df_selected = df_selected[df_selected.completion_token_count_mean.notna()]
    logger.info(f"df_selected: {df_selected.completion_token_count_mean}")
    df_summary_all = df_selected.loc[df_selected.groupby(grouping_cols)['concurrency'].transform(max) == df_selected['concurrency']]

    # find price per txn and price per token
    df_summary_all['cost_per_txn'] = df_summary_all.apply(lambda r: cost_per_txn(r, pricing), axis=1)
    df_summary_all['cost_per_1k_tokens'] = df_summary_all.apply(lambda r: cost_per_1k_tokens(r, pricing), axis=1)

    # extrapolate to price per n requests per minue
    rpm_list = [int(rpm) for rpm in args.rpm_list.split(",")]
    for rpm in rpm_list:
        col_name = f"instance_count_and_cost_{rpm}_rpm"
        df_summary_all[col_name] = df_summary_all.apply(lambda r: cost_per_n_rpm(r, rpm, pricing), axis=1)

    df_summary_all = df_summary_all.sort_values(by="cost_per_1k_tokens")    
    summary_file: str = os.path.join(ANALYTICS_RESULTS_DIR,
                                     f"{args.model_id}-summary-p95-latency={args.latency_threshold}s.csv")
    df_summary_all.to_csv(summary_file, index=False)
    logger.info(f"saved df_summary_all dataframe of shape={df_summary_all.shape} in {summary_file}")
    
    summary_file_payload_of_interest: str = os.path.join(ANALYTICS_RESULTS_DIR,
                                                         f"{args.model_id}-summary-{Path(args.payload_file).stem}-p95-latency={args.latency_threshold}s.csv")
    summary_file_payload_of_interest_raw_metrics: str = os.path.join(ANALYTICS_RESULTS_DIR,
                                                         f"{args.model_id}-summary-{Path(args.payload_file).stem}-p95-latency-concurrency={args.latency_threshold}s-raw.csv")                                       
    df_summary_payload_of_interest = df_summary_all[df_summary_all.payload_file == args.payload_file]
    df_summary_payload_of_interest = df_summary_payload_of_interest.sort_values(by="cost_per_1k_tokens")
    df_summary_payload_of_interest['transactions_per_second'] = df_summary_payload_of_interest.transactions_per_minute/60
    df_summary_payload_of_interest['transactions_per_second'] = df_summary_payload_of_interest['transactions_per_second'].astype(int)
    # place it next to transactions per minute
    cols = df_summary_payload_of_interest.columns.tolist() 
    index_to_insert = cols.index('transactions_per_minute') + 1  # Get the position after 'transactions_per_minute'
    cols.insert(index_to_insert, cols.pop(cols.index('transactions_per_second')))  # Insert 'transactions_per_second' after 'transactions_per_minute'
    df_summary_payload_of_interest = df_summary_payload_of_interest[cols]

    # create a csv file with all the raw metrics
    df_summary_payload_of_interest.to_csv(summary_file_payload_of_interest_raw_metrics, index=False)
    cols_to_remove = ['payload_file', 'instance_count', 'error_rate', 'prompt_token_count_mean', 'prompt_token_throughput', 'completion_token_count_mean', 'latency_p50',
                      'latency_p99', 'completion_token_throughput']
    # filter out the columns as needed and only give the relevant columns in the analysis markdown table
    df_summary_payload_of_interest_trimmed = df_summary_payload_of_interest.drop(columns=cols_to_remove)
    df_summary_payload_of_interest_trimmed_grouped = df_summary_payload_of_interest_trimmed.loc[df_summary_payload_of_interest_trimmed.groupby('instance_type')['concurrency'].idxmax()].reset_index()
    df_summary_payload_of_interest_trimmed_grouped.to_csv(summary_file_payload_of_interest, index=False)


    # cost RPM plot, the function saves the html to a file
    heatmap_fname: str = os.path.join(ANALYTICS_RESULTS_DIR,
                                      f"{args.model_id}-cost-rpm-heatmap-for-"
                                      f"{Path(args.payload_file).stem}-p95-latency={args.latency_threshold}s.html")
    df1 = pd.read_csv(summary_file_payload_of_interest)
    logger.info(f"df columns: {df1.columns}")
    # if an instance type has multiple entries then keep the one with the least cost per token
    shape_before = df1.shape
    df1 = df1.loc[df1.groupby('instance_type').cost_per_1k_tokens.idxmin()].reset_index(drop=True)
    shape_after = df1.shape
    if shape_before[0] != shape_after[0]:
        logger.warning(f"there were multiple entries for some instance types, kept ones with min per token cost, "
                       f"shape_before={shape_before}, shape_after={shape_after}")
    prompt_spec: str = args.payload_file.split(".")[0]
    subtitle: str = f"Prompt: {prompt_spec} tokens, latency p95 threshold: {args.latency_threshold}s"
    _ = plot_best_cost_instance_heatmap(df1,
                                    heatmap_fname,
                                    args.model_id,
                                    subtitle,
                                    args.cost_weight,
                                    1 - args.cost_weight)
    # save the line chart
    # TPS vs Cost line chart
    tps_vs_cost_fname: str = os.path.join(ANALYTICS_RESULTS_DIR,
                                        f"{args.model_id}-tps-vs-cost-for-"
                                        f"{Path(args.payload_file).stem}-p95-latency={args.latency_threshold}s.html")

    _ = plot_tps_vs_cost(df1,
                        tps_vs_cost_fname,
                        args.model_id,
                        subtitle)

    logger.info("all done")
if __name__ == "__main__":
    main()


================================================
File: /startup_scripts/ubuntu_arm_startup.txt
================================================
Content-Type: multipart/mixed; boundary="//"
MIME-Version: 1.0

--//
Content-Type: text/cloud-config; charset="us-ascii"
MIME-Version: 1.0
Content-Transfer-Encoding: 7bit
Content-Disposition: attachment; filename="cloud-config.txt"

#cloud-config
cloud_final_modules:
- [scripts-user, always]

--//
Content-Type: text/x-shellscript; charset="us-ascii"
MIME-Version: 1.0
Content-Transfer-Encoding: 7bit
Content-Disposition: attachment; filename="userdata.txt"

#!/bin/bash
cd /home/ubuntu

# Update packages and install Docker + Git using apt-get (Ubuntu style)
sudo apt-get update -y
sudo apt-get install -y docker.io git
sudo systemctl start docker
sudo systemctl enable docker

# Switch to 'ubuntu' and run the following commands
sudo -u ubuntu -i bash << 'EOF'
# Download and install the ARM64 (aarch64) Miniconda
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh -O /home/ubuntu/Miniconda3-latest-Linux-aarch64.sh
bash /home/ubuntu/Miniconda3-latest-Linux-aarch64.sh -b -p /home/ubuntu/miniconda3
rm /home/ubuntu/Miniconda3-latest-Linux-aarch64.sh

# Initialize conda for bash shell
/home/ubuntu/miniconda3/bin/conda init

# Create a new conda environment
/home/ubuntu/miniconda3/bin/conda create --name fmbench_python311 -y python=3.11 ipykernel

# Activate the environment and attempt to install fmbench
source /home/ubuntu/miniconda3/bin/activate fmbench_python311
pip install -U fmbench

# Add ubuntu user to the docker group and reload group memberships
sudo usermod -a -G docker $USER
newgrp docker

# Clone the vLLM project repository from GitHub
git clone https://github.com/vllm-project/vllm.git

# Change the directory to the cloned vLLM project
cd vllm

# Build a Docker image using the provided Dockerfile for CPU, with a shared memory size of 4GB
sudo docker build -f Dockerfile.arm -t vllm-cpu-env --shm-size=4g .

# Install Docker Compose plugin
DOCKER_CONFIG=${DOCKER_CONFIG:-$HOME/.docker}
mkdir -p $DOCKER_CONFIG/cli-plugins
sudo curl -L https://github.com/docker/compose/releases/latest/download/docker-compose-$(uname -s)-$(uname -m) \
     -o $DOCKER_CONFIG/cli-plugins/docker-compose
sudo chmod +x $DOCKER_CONFIG/cli-plugins/docker-compose
docker compose version

# Download content from S3 using the provided script
curl -s https://raw.githubusercontent.com/aws-samples/foundation-model-benchmarking-tool/main/copy_s3_content.sh | sh -s -- /tmp
echo "__HF_TOKEN__" > /tmp/fmbench-read/scripts/hf_token.txt

# Add the conda environment activation and directory navigation to .bashrc
echo 'source /home/ubuntu/miniconda3/bin/activate fmbench_python311' >> /home/ubuntu/.bashrc

source /home/ubuntu/.bashrc
touch /tmp/startup_complete.flag
EOF


================================================
File: /startup_scripts/neuron_al2_startup_triton.txt
================================================
#!/bin/bash
cd /home/ubuntu/

# Update package lists and install Docker and Git
sudo apt update
sudo apt install -y docker.io git

# Start the Docker service
sudo systemctl start docker

# Run the following commands as the ubuntu user
sudo -u ubuntu -i bash << 'EOF'
# Download and install Miniconda
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/Miniconda3-latest-Linux-x86_64.sh
bash ~/Miniconda3-latest-Linux-x86_64.sh -b -p ~/miniconda3
rm ~/Miniconda3-latest-Linux-x86_64.sh

# Initialize conda for bash shell
~/miniconda3/bin/conda init

# Create a new conda environment
~/miniconda3/bin/conda create --name fmbench_python311 -y python=3.11 ipykernel
# Activate the environment and install fmbench
source ~/miniconda3/bin/activate fmbench_python311
pip install -U fmbench

sudo usermod -a -G docker $USER
newgrp docker

# curl the docker file for triton
curl -o ./Dockerfile_triton https://raw.githubusercontent.com/aws-samples/foundation-model-benchmarking-tool/main/src/fmbench/scripts/triton/Dockerfile_triton

# curl the script that builds and pushes the triton image locally
curl -o build_and_push_triton.sh https://raw.githubusercontent.com/aws-samples/foundation-model-benchmarking-tool/main/src/fmbench/scripts/triton/build_and_push_triton.sh

# Make the triton build and push script executable, and run it
chmod +x build_and_push_triton.sh
./build_and_push_triton.sh

# Download content from S3 using the provided script
curl -s https://raw.githubusercontent.com/aws-samples/foundation-model-benchmarking-tool/main/copy_s3_content.sh | sh -s -- /tmp
echo "__HF_TOKEN__" > /tmp/fmbench-read/scripts/hf_token.txt

# Add the conda environment activation to .bashrc
echo 'source ~/miniconda3/bin/activate fmbench_python311' >> ~/.bashrc

source ~/.bashrc
touch /tmp/startup_complete.flag
EOF

================================================
File: /startup_scripts/cpu_al2023_startup.txt
================================================
Content-Type: multipart/mixed; boundary="//"
MIME-Version: 1.0

--//
Content-Type: text/cloud-config; charset="us-ascii"
MIME-Version: 1.0
Content-Transfer-Encoding: 7bit
Content-Disposition: attachment; filename="cloud-config.txt"

#cloud-config
cloud_final_modules:
- [scripts-user, always]

--//
Content-Type: text/x-shellscript; charset="us-ascii"
MIME-Version: 1.0
Content-Transfer-Encoding: 7bit
Content-Disposition: attachment; filename="userdata.txt"

#!/bin/bash
cd /home/ec2-user

# Update and install Docker and other dependencies as root
sudo yum update -y
sudo yum install docker git -y
sudo systemctl start docker
sudo systemctl enable docker

# Switch to ec2-user and run the following commands
sudo -u ec2-user -i bash << 'EOF'
# Download and install Miniconda
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O /home/ec2-user/Miniconda3-latest-Linux-x86_64.sh
bash /home/ec2-user/Miniconda3-latest-Linux-x86_64.sh -b -p /home/ec2-user/miniconda3
rm /home/ec2-user/Miniconda3-latest-Linux-x86_64.sh

# Initialize conda for bash shell
/home/ec2-user/miniconda3/bin/conda init

# Create a new conda environment
/home/ec2-user/miniconda3/bin/conda create --name fmbench_python311 -y python=3.11 ipykernel
# Activate the environment and install fmbench
source /home/ec2-user/miniconda3/bin/activate fmbench_python311
pip install -U fmbench

# Add ec2-user to the docker group and reload group memberships
sudo usermod -a -G docker $USER
newgrp docker

# Clone the vLLM project repository from GitHub
git clone https://github.com/vllm-project/vllm.git

# Change the directory to the cloned vLLM project
cd vllm

# Build a Docker image using the provided Dockerfile for CPU, with a shared memory size of 4GB
sudo docker build -f Dockerfile.cpu -t vllm-cpu-env --shm-size=4g .

DOCKER_CONFIG=${DOCKER_CONFIG:-$HOME/.docker}
mkdir -p $DOCKER_CONFIG/cli-plugins
sudo curl -L https://github.com/docker/compose/releases/latest/download/docker-compose-$(uname -s)-$(uname -m) -o $DOCKER_CONFIG/cli-plugins/docker-compose
sudo chmod +x $DOCKER_CONFIG/cli-plugins/docker-compose
docker compose version

# Download content from S3 using the provided script
curl -s https://raw.githubusercontent.com/aws-samples/foundation-model-benchmarking-tool/main/copy_s3_content.sh | sh -s -- /tmp
echo "__HF_TOKEN__" > /tmp/fmbench-read/scripts/hf_token.txt


# Add the conda environment activation and directory navigation to .bashrc
echo 'source /home/ec2-user/miniconda3/bin/activate fmbench_python311' >> /home/ec2-user/.bashrc


source /home/ec2-user/.bashrc
touch /tmp/startup_complete.flag
EOF


================================================
File: /startup_scripts/ubuntu_startup.txt
================================================
Content-Type: multipart/mixed; boundary="//"
MIME-Version: 1.0

--//
Content-Type: text/cloud-config; charset="us-ascii"
MIME-Version: 1.0
Content-Transfer-Encoding: 7bit
Content-Disposition: attachment; filename="cloud-config.txt"

#cloud-config
cloud_final_modules:
- [scripts-user, always]

--//
Content-Type: text/x-shellscript; charset="us-ascii"
MIME-Version: 1.0
Content-Transfer-Encoding: 7bit
Content-Disposition: attachment; filename="userdata.txt"

#!/bin/bash
cd /home/ubuntu/

# Update and install Docker as root
apt-get update
apt-get install --reinstall docker.io -y
apt-get install -y docker-compose
docker compose version

# Switch to ubuntu user and run the following commands
sudo -u ubuntu -i bash << 'EOF'
# Download and install Miniconda
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O /home/ubuntu/Miniconda3-latest-Linux-x86_64.sh
bash /home/ubuntu/Miniconda3-latest-Linux-x86_64.sh -b -p /home/ubuntu/miniconda3
rm /home/ubuntu/Miniconda3-latest-Linux-x86_64.sh

# Initialize conda for bash shell
/home/ubuntu/miniconda3/bin/conda init

# Create a new conda environment
/home/ubuntu/miniconda3/bin/conda create --name fmbench_python311 -y python=3.11 ipykernel
# Activate the environment and install fmbench
source /home/ubuntu/miniconda3/bin/activate fmbench_python311
pip install -U fmbench

sudo usermod -a -G docker $USER
newgrp docker

# Download content from S3 using the provided script
curl -s https://raw.githubusercontent.com/aws-samples/foundation-model-benchmarking-tool/main/copy_s3_content.sh | sh -s -- /tmp
echo "__HF_TOKEN__" > /tmp/fmbench-read/scripts/hf_token.txt

# Add the conda environment activation and directory navigation to .bashrc
echo 'source /home/ubuntu/miniconda3/bin/activate fmbench_python311' >> /home/ubuntu/.bashrc


neuron="__neuron__"

# Check if neuron_ls is successful and neuron flag is set to True
if neuron-ls && [ "$neuron" = "True" ]; then
    # Download the Dockerfile for Triton
    curl -o ./Dockerfile_triton https://raw.githubusercontent.com/aws-samples/foundation-model-benchmarking-tool/main/src/fmbench/scripts/triton/Dockerfile_triton

    # Download the script that builds and pushes the Triton image locally
    curl -o build_and_push_triton.sh https://raw.githubusercontent.com/aws-samples/foundation-model-benchmarking-tool/main/src/fmbench/scripts/triton/build_and_push_triton.sh

    # Make the build and push script executable
    chmod +x build_and_push_triton.sh

    # Run the build and push script
    ./build_and_push_triton.sh
fi


# install triton inference server, install only if running on a GPU instance
if nvidia-smi; then
    cd ~
    git clone https://github.com/triton-inference-server/tensorrtllm_backend.git --branch v0.12.0
    # Update the submodules
    cd tensorrtllm_backend
    # Install git-lfs if needed
    sudo apt --fix-broken install -y
    sudo apt-get update -y && sudo apt-get install git-lfs -y --no-install-recommends
    git lfs install
    git submodule update --init --recursive
fi

source /home/ubuntu/.bashrc
touch /tmp/startup_complete.flag

EOF


================================================
File: /globals.py
================================================
import os
import json
import boto3
import logging
import requests
import paramiko
from constants import *
from typing import Tuple
from utils import authorize_inbound_rules, create_key_pair
from botocore.exceptions import NoCredentialsError, ClientError
from utils import create_security_group, load_yaml_file, _get_ec2_hostname_and_username, get_region

# set a logger
logger = logging.getLogger(__name__)

config_data = {}

def get_iam_role() -> str:
    try:
        caller = boto3.client("sts").get_caller_identity()
        account_id = caller.get("Account")
        role_arn_from_env = os.environ.get("FMBENCH_ROLE_ARN")
        if role_arn_from_env:
            print(f"role_arn_from_env={role_arn_from_env}, using it to set arn_string")
            arn_string = role_arn_from_env
        else:
            print(
                f"role_arn_from_env={role_arn_from_env}, using current sts caller identity to set arn_string"
            )
            arn_string = caller.get("Arn")

            # if this is an assumed role then remove the assumed role related pieces
            # because we are also using this role for deploying the SageMaker endpoint
            # arn:aws:sts::015469603702:assumed-role/SSMDefaultRoleForOneClickPvreReporting/i-0c5bba16a8b3dac51
            # should be converted to arn:aws:iam::015469603702:role/SSMDefaultRoleForOneClickPvreReporting
            if ":assumed-role/" in arn_string:
                role_name = arn_string.split("/")[-2]
                arn_string = f"arn:aws:iam::{account_id}:instance-profile/{role_name}"
                print(
                    f"the sts role is an assumed role, setting arn_string to {arn_string}"
                )
            else:
                arn_string = caller.get("Arn")
        role_name = arn_string.split("/")[-1]
    except Exception as e:
        logger.error(f"Could not fetch the role name or arn_string: {e}")
        arn_string = None

    return arn_string


def create_iam_instance_profile_arn():

    iam_client = boto3.client("iam")
    role_name: str = "fmbench"

    instance_profile_arn: Optional[str] = None
    instance_profile_role_name: str = config_data["aws"].get(
        "iam_instance_profile_arn", "fmbench_orchestrator_role_new"
    )

    try:
        policy = {
            "Version": "2012-10-17",
            "Statement": [
                {
                    "Effect": "Allow",
                    "Action": [
                        "ecr:GetAuthorizationToken",
                        "ecr:BatchCheckLayerAvailability",
                        "ecr:GetDownloadUrlForLayer",
                        "ecr:BatchGetImage",
                        "ecr:ListImages",
                    ],
                    "Resource": "*",
                },
                {
                    "Effect": "Allow",
                    "Action": [
                        "ec2:RunInstances",
                        "ec2:DescribeInstances",
                        "ec2:CreateTags",
                        "ec2:StartInstances",
                        "ec2:StopInstances",
                        "ec2:RebootInstances",
                    ],
                    "Resource": [
                        "arn:aws:ec2:*:*:instance/*",
                        "arn:aws:ec2:*:*:volume/*",
                        "arn:aws:ec2:*:*:network-interface/*",
                        "arn:aws:ec2:*:*:key-pair/*",
                        "arn:aws:ec2:*:*:security-group/*",
                        "arn:aws:ec2:*:*:subnet/*",
                        "arn:aws:ec2:*:*:image/*",
                    ],
                },
                {
                    "Effect": "Allow",
                    "Action": [
                        "ec2:CreateSecurityGroup",
                        "ec2:AuthorizeSecurityGroupIngress",
                        "ec2:AuthorizeSecurityGroupEgress",
                        "ec2:DescribeSecurityGroups",
                    ],
                    "Resource": "*",
                },
                {
                    "Effect": "Allow",
                    "Action": ["ec2:CreateKeyPair", "ec2:DescribeKeyPairs"],
                    "Resource": "*",
                },
                {
                    "Effect": "Allow",
                    "Action": [
                        "ec2:CreateTags",
                        "ec2:DescribeInstances",
                        "ec2:TerminateInstances",
                        "ec2:DescribeInstanceStatus",
                        "ec2:DescribeAddresses",
                        "ec2:AssociateAddress",
                        "ec2:DisassociateAddress",
                        "ec2:DescribeRegions",
                        "ec2:DescribeImages",
                        "ec2:DescribeAvailabilityZones",
                    ],
                    "Resource": "*",
                },
                {
                    "Effect": "Allow",
                    "Action": "iam:PassRole",
                    "Resource": [f"arn:aws:iam::*:role/{role_name}*"],
                },
            ],
        }

        policy_response = iam_client.create_policy(
            PolicyName="CustomPolicy", PolicyDocument=json.dumps(policy)
        )

        # Create IAM role
        assume_role_policy_document = {
            "Version": "2012-10-17",
            "Statement": [
                {
                    "Effect": "Allow",
                    "Principal": {"Service": "ec2.amazonaws.com"},
                    "Action": "sts:AssumeRole",
                }
            ],
        }

        iam_client.create_role(
            RoleName=instance_profile_role_name,
            AssumeRolePolicyDocument=json.dumps(assume_role_policy_document),
        )

        iam_client.attach_role_policy(
            RoleName=instance_profile_role_name,
            PolicyArn=policy_response["Policy"]["Arn"],
        )

        # Attach managed policies to the role
        managed_policies = [
            "arn:aws:iam::aws:policy/AmazonSageMakerFullAccess",
            "arn:aws:iam::aws:policy/AmazonS3FullAccess",
            "arn:aws:iam::aws:policy/AWSCloudFormationReadOnlyAccess",
            "arn:aws:iam::aws:policy/AmazonBedrockFullAccess",
        ]

        for policy_arn in managed_policies:
            iam_client.attach_role_policy(
                RoleName=instance_profile_role_name, PolicyArn=policy_arn
            )

        # Create instance profile
        instance_profile_info = iam_client.create_instance_profile(
            InstanceProfileName="FMBenchOrchestratorInstanceProfile_new"
        )

        if instance_profile_info is not None:
            logger.info(f"Instance profile created: {instance_profile_info}")
            instance_profile_arn = instance_profile_info["InstanceProfile"].get("Arn")

        # Add role to instance profile
        iam_client.add_role_to_instance_profile(
            InstanceProfileName="FMBenchOrchestratorInstanceProfile_new",
            RoleName=instance_profile_role_name,
        )

        print("Instance profile created and role attached successfully.")
        return instance_profile_arn
    except ClientError as e:
        if e.response["Error"]["Code"] == "InvalidPermission.Duplicate":
            logger.info(f"Iam instance profile already exists. Skipping...")
        else:
            logger.error(f"Error creating the instance profile iam: {e}")


def upload_and_run_script(
    instance_id: str,
    private_key_path: str,
    user_data_script: str,
    region: str,
    startup_script: str,
) -> bool:
    """
    Runs the user data as a script in the case of which an instance is pre existing. This is because
    the user script of an instance can only be modified when it is stopped.
    """
    ec2_client = boto3.client("ec2", region_name=region)
    has_start_up_script_executed: bool = False
    try:
        # Get instance public IP
        public_hostname, username, instance_name = _get_ec2_hostname_and_username(
            instance_id, region, public_dns=True
        )
        logger.info(f"Uploading and running script on instance {instance_id}...")
        logger.info(
            f"hostname={public_hostname}, username={username}, instance_name={instance_name}"
        )
        # Create SSH client
        ssh = paramiko.SSHClient()
        ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())

        # Connect to the instance
        ssh.connect(
            hostname=public_hostname, username=username, key_filename=private_key_path
        )

        # Upload the script
        with ssh.open_sftp() as sftp:
            with sftp.file("/tmp/startup_script.sh", "w") as f:
                f.write(user_data_script)

        # Make the script executable and run it
        stdin, stdout, stderr = ssh.exec_command(
            "chmod +x /tmp/startup_script.sh && nohup sudo /tmp/startup_script.sh &"
        )

        # Print output
        # for line in stdout:
        #     logger.info(line.strip('\n'))
        # for line in stderr:
        #     logger.info(line.strip('\n'))
        ssh.close()
        logger.info(f"Script uploaded and executed on instance {instance_id}")
        has_start_up_script_executed = True
    except Exception as e:
        logger.error(
            f"Error uploading and running script on instance {instance_id}: {e}"
        )
    return has_start_up_script_executed


def get_sg_id(region: str) -> str:
    # Append the region to the group name
    GROUP_NAME = f"{config_data['security_group'].get('group_name')}-{region}"
    DESCRIPTION = config_data["security_group"].get("description", " ")
    VPC_ID = config_data["security_group"].get("vpc_id")

    try:
        # Create or get the security group with the region-specific name
        sg_id = create_security_group(region, GROUP_NAME, DESCRIPTION, VPC_ID)
        logger.info(f"Security group '{GROUP_NAME}' created or imported in {region}")

        if sg_id:
            # Add inbound rules if security group was created or imported successfully
            authorize_inbound_rules(sg_id, region)
            logger.info(f"Inbound rules added to security group '{GROUP_NAME}'")

        return sg_id

    except ClientError as e:
        logger.error(
            f"An error occurred while creating or getting the security group '{GROUP_NAME}': {e}"
        )
        raise  # Re-raise the exception for further handling if needed


def get_key_pair(region):
    # Create 'key_pair' directory if it doesn't exist
    key_pair_dir = "key_pair"
    if not os.path.exists(key_pair_dir):
        os.makedirs(key_pair_dir)

    # Generate the key pair name using the format: config_name-region
    key_pair_name_configured = config_data["key_pair_gen"]["key_pair_name"]

    # Generate the key pair name using the format: config_name-region
    key_pair_name = f"{key_pair_name_configured}_{region}"
    logger.info(f"key_pair_name_configured={key_pair_name_configured}, setting the key pair name as={key_pair_name}")
    private_key_fname = os.path.join(key_pair_dir, f"{key_pair_name}.pem")

    # Check if key pair generation is enabled
    if config_data["run_steps"]["key_pair_generation"]:
        # First, check if the key pair file already exists
        if os.path.exists(private_key_fname):
            try:
                # If the key pair file exists, read it
                with open(private_key_fname, "r") as file:
                    private_key = file.read()
                print(f"Using existing key pair from {private_key_fname}")
            except IOError as e:
                raise ValueError(
                    f"Error reading existing key pair file '{private_key_fname}': {e}"
                )
        else:
            # If the key pair file doesn't exist, create a new key pair
            try:
                delete_key_pair_if_present: bool = True
                private_key = create_key_pair(key_pair_name, region, delete_key_pair_if_present)
                # Save the key pair to the file
                with open(private_key_fname, "w") as key_file:
                    key_file.write(private_key)

                # Set file permissions to be readable only by the owner
                os.chmod(private_key_fname, 0o400)
                print(
                    f"Key pair '{key_pair_name}' created and saved as '{private_key_fname}'"
                )
            except Exception as e:
                # If key pair creation fails, raise an error
                raise ValueError(f"Failed to create key pair '{key_pair_name}': {e}")
    else:
        # If key pair generation is disabled, attempt to use an existing key
        try:
            with open(private_key_fname, "r") as file:
                private_key = file.read()
            print(f"Using pre-existing key pair from {private_key_fname}")
        except FileNotFoundError:
            raise ValueError(f"Key pair file not found at {private_key_fname}")
        except IOError as e:
            raise ValueError(f"Error reading key pair file '{private_key_fname}': {e}")
    return private_key_fname, key_pair_name


================================================
File: /post_startup_scripts/fmbench.txt
================================================
#cd /home/ubuntu/foundation-model-benchmarking-tool;
source activate fmbench_python311;
. ~/.bashrc;

if [[ "$CONDA_DEFAULT_ENV" == "fmbench_python311" ]]; then
    echo "The current environment is fmbench_python311. Running FMBench..."
    
    # Run fmbench and redirect output to a log file
    nohup fmbench --config-file {config_file} --local-mode {local_mode} --write-bucket {write_bucket} --tmp-dir /tmp > fmbench.log 2>&1 &
    FM_BENCH_PID=$!
    echo "FMBench is running with PID $FM_BENCH_PID. Logs are being written to fmbench.log."
    
    # Wait for the fmbench process to complete
    wait $FM_BENCH_PID
    echo "FMBench execution completed."

    # Check if any directory matching results-* exists
    if ls results-* 1> /dev/null 2>&1; then
        echo "Results directory found. Creating flag file in /tmp."
        # Create a flag file in /tmp
        touch /tmp/fmbench_completed.flag
    else
        echo "Results directory not found. No flag file created."
    fi
else
    echo "Error: The current environment is not fmbench_python311. Exiting."
    exit 1
fi


================================================
File: /main.py
================================================
import os
import sys
import time
import json
import wget
import yaml
import boto3
import base64
import urllib
import logging
import asyncio
import globals
import argparse
import paramiko
from utils import *
from constants import *
from pathlib import Path
from scp import SCPClient
from typing import Optional, List
from collections import defaultdict
from concurrent.futures import ThreadPoolExecutor
from botocore.exceptions import NoCredentialsError, ClientError
from globals import (
    create_iam_instance_profile_arn,
    get_region,
    get_iam_role,
    get_sg_id,
    get_key_pair,
    upload_and_run_script,
)

executor = ThreadPoolExecutor()

# Initialize global variables for this file
instance_id_list: List = []
fmbench_config_map: List = []
fmbench_post_startup_script_map: List = []
instance_data_map: Dict = {}

logging.basicConfig(
    level=logging.INFO,  # Set the log level to INFO
    # Define log message format
    format="[%(asctime)s] p%(process)s {%(filename)s:%(lineno)d} %(levelname)s - %(message)s",
    handlers=[
        logging.FileHandler("fmbench-orchestrator.log"),  # Log to a file
        logging.StreamHandler(),  # Also log to console
    ],
)


async def execute_fmbench(instance, post_install_script, remote_script_path):
    """
    Asynchronous wrapper for deploying an instance using synchronous functions.
    """
    # Check for the startup completion flag
    startup_complete = await asyncio.get_event_loop().run_in_executor(
        executor,
        wait_for_flag,
        instance,
        STARTUP_COMPLETE_FLAG_FPATH,
        CLOUD_INITLOG_PATH,
    )

    if startup_complete:
        if instance["upload_files"]:
            await upload_file_to_instance_async(
                instance["hostname"],
                instance["username"],
                instance["key_file_path"],
                file_paths=instance["upload_files"],
            )
        num_configs: int = len(instance["config_file"])
        for cfg_idx, config_file in enumerate(instance["config_file"]):
            cfg_idx += 1
            instance_name = instance["instance_name"]
            local_mode_param = POST_STARTUP_LOCAL_MODE_VAR
            write_bucket_param = POST_STARTUP_WRITE_BUCKET_VAR

            logger.info(
                f"going to run config {cfg_idx} of {num_configs} for instance {instance_name}"
            )
            # Handle configuration file (download/upload) and get the remote path
            remote_config_path = await handle_config_file_async(instance, config_file)
            # Format the script with the remote config file path
            # Change this later to be a better implementation, right now it is bad.

            # override defaults for post install script params if specified
            pssp = instance.get("post_startup_script_params")
            if pssp is not None:
                local_mode_param = pssp.get("local_mode", local_mode_param)
                write_bucket_param = pssp.get("write_bucket", write_bucket_param)

            # Convert `local_mode_param` to "yes" or "no" if it is a boolean
            if isinstance(local_mode_param, bool):
                local_mode_param = "yes" if local_mode_param else "no"

            formatted_script = (
                Path(post_install_script)
                .read_text()
                .format(
                    config_file=remote_config_path,
                    local_mode=local_mode_param,
                    write_bucket=write_bucket_param,
                )
            )

            

            # Upload and execute the script on the instance
            retries = 0
            max_retries = 2
            retry_sleep = 60
            while True:
                logger.info("Startup Script complete, executing fmbench now")
                script_output = await asyncio.get_event_loop().run_in_executor(
                    executor,
                    upload_and_execute_script_invoke_shell,
                    instance["hostname"],
                    instance["username"],
                    instance["key_file_path"],
                    formatted_script,
                    remote_script_path,
                )
                logger.info(f"Script Output from {instance['hostname']}:\n{script_output}")
                if script_output != "":
                    break
                else:
                    logger.error(f"post startup script not successfull after {retries}")
                    if retries < max_retries:
                        logger.error(f"post startup script retries={retries}, trying after a {retry_sleep}s sleep")
                    else:
                        logger.error(f"post startup script retries={retries}, not retrying any more, benchmarking "
                                    f"for instance={instance} will fail....")
                        break
                time.sleep(retry_sleep)
                retries += 1

            # Check for the fmbench completion flag
            fmbench_complete = await asyncio.get_event_loop().run_in_executor(
                executor,
                wait_for_flag,
                instance,
                FMBENCH_TEST_COMPLETE_FLAG_FPATH,
                FMBENCH_LOG_PATH,
                instance["fmbench_complete_timeout"],
                SCRIPT_CHECK_INTERVAL_IN_SECONDS,
            )

            logger.info("Going to get fmbench.log from the instance now")
            results_folder = os.path.join(
                RESULTS_DIR, globals.config_data["general"]["name"]
            )
            # Get Log even if fmbench_completes or not
            await asyncio.get_event_loop().run_in_executor(
                executor,
                get_fmbench_log,
                instance,
                results_folder,
                FMBENCH_LOG_REMOTE_PATH,
                cfg_idx,
            )

            if fmbench_complete:
                logger.info("Fmbench Run successful, Getting the folders now")
                await asyncio.get_event_loop().run_in_executor(
                    executor,
                    check_and_retrieve_results_folder,
                    instance,
                    results_folder,
                )
        if globals.config_data["run_steps"]["delete_ec2_instance"]:
            delete_ec2_instance(instance["instance_id"], instance["region"])
            instance_id_list.remove(instance["instance_id"])


async def multi_deploy_fmbench(instance_details, remote_script_path):
    tasks = []

    # Create a task for each instance
    for instance in instance_details:
        # Make this async as well?
        # Format the script with the specific config file
        logger.info(f"Instance Details are: {instance}")
        # Create an async task for this instance
        tasks.append(
            execute_fmbench(
                instance, instance["post_startup_script"], remote_script_path
            )
        )

    # Run all tasks concurrently
    await asyncio.gather(*tasks)


async def main():
    await multi_deploy_fmbench(instance_details, remote_script_path)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Run FMBench orchestrator with a specified config file."
    )
    parser.add_argument(
        "--config-file",
        type=str,
        help="Path to your Config File",
        required=False,
        default="configs/config.yml",
    )
    parser.add_argument(
        "--ami-mapping-file",
        type=str,
        help="Path to a config file containing the region->instance type->AMI apping",
        required=False,
        default="configs/ami_mapping.yml",
    )
    parser.add_argument(
        "--fmbench-config-file",
        type=str,
        help="Config file to use with fmbench, this is used if the orchestrator config file uses the \"{{config_file}}\" format for specifying the fmbench config file",
        required=False
    )
    parser.add_argument(
        "--infra-config-file",
        type=str,
        default=INFRA_YML_FPATH,
        help=f"Config file to use with AWS infrastructure, default={INFRA_YML_FPATH}",
        required=False
    )
    parser.add_argument(
        "--write-bucket",
        type=str,
        help="S3 bucket to store model files for benchmarking on SageMaker",
        required=False
    )

    args = parser.parse_args()
    logger.info(f"main, {args} = args")

    globals.config_data = load_yaml_file(args.config_file,
                                         args.ami_mapping_file,
                                         args.fmbench_config_file,
                                         args.infra_config_file,
                                         args.write_bucket)
    logger.info(f"Loaded Config {json.dumps(globals.config_data, indent=2)}")

    hf_token_fpath = globals.config_data["aws"].get("hf_token_fpath")
    hf_token: Optional[str] = None
    logger.info(f"Got Hugging Face Token file path from config. {hf_token_fpath}")
    logger.info("Attempting to open it")

    if Path(hf_token_fpath).is_file():
        hf_token = Path(hf_token_fpath).read_text().strip()
    else:
        logger.error(f"{hf_token_fpath} does not exist, cannot continue")
        sys.exit(1)

    logger.info(f"read hugging face token {hf_token} from file path")
    assert len(hf_token) > 4, "Hf_token is too small or invalid, please check"

    for i in globals.config_data["instances"]:
        logger.info(f"Instance list is as follows: {i}")

    logger.info(f"Deploying Ec2 Instances")
    if globals.config_data["run_steps"]["deploy_ec2_instance"]:
        try:
            iam_arn = get_iam_role()
        except Exception as e:
            logger.error(f"Cannot get IAM Role due to exception {e}")

        if not iam_arn:
            raise NoCredentialsError(
                """Unable to locate credentials,
                                        Please check if an IAM role is 
                                        attched to your instance."""
            )

        logger.info(f"iam arn: {iam_arn}")
        # WIP Parallelize This.
        num_instances: int = len(globals.config_data["instances"])
        for idx, instance in enumerate(globals.config_data["instances"]):
            idx += 1
            logger.info(
                f"going to create instance {idx} of {num_instances}, instance={instance}"
            )
            deploy: bool = instance.get("deploy", True)
            if deploy is False:
                logger.warning(
                    f"deploy={deploy} for instance={json.dumps(instance, indent=2)}, skipping it..."
                )
                continue
            region = instance.get("region", globals.config_data["aws"].get("region"))
            startup_script = instance["startup_script"]
            logger.info(f"Region Set for instance is: {region}")
            if globals.config_data["run_steps"]["security_group_creation"]:
                logger.info(
                    f"Creating Security Groups. getting them by name if they exist"
                )
                sg_id = get_sg_id(region)
            if region is not None:
                PRIVATE_KEY_FNAME, PRIVATE_KEY_NAME = get_key_pair(region)
            else:
                logger.error(
                    f"Region is not provided in the configuration file. Make sure the region exists. Region: {region}"
                )
            # command_to_run = instance["command_to_run"]
            with open(f"{startup_script}", "r") as file:
                user_data_script = file.read()
                # Replace the hf token in the bash script to pull the HF model
                user_data_script = user_data_script.replace("__HF_TOKEN__", hf_token)
                user_data_script = user_data_script.replace("__neuron__", "True")

            if instance.get("instance_id") is None:
                instance_type = instance["instance_type"]
                ami_id = instance["ami_id"]
                device_name = instance["device_name"]
                ebs_del_on_termination = instance["ebs_del_on_termination"]
                ebs_Iops = instance["ebs_Iops"]
                ebs_VolumeSize = instance["ebs_VolumeSize"]
                ebs_VolumeType = instance["ebs_VolumeType"]
                # Retrieve CapacityReservationId and CapacityReservationResourceGroupArn if they exist
                CapacityReservationId = instance.get("CapacityReservationId", None)
                CapacityReservationPreference = instance.get(
                    "CapacityReservationPreference", "none"
                )
                CapacityReservationResourceGroupArn = instance.get(
                    "CapacityReservationResourceGroupArn", None
                )

                if CapacityReservationId:
                    logger.info(
                        f"Capacity reservation id provided: {CapacityReservationId}"
                    )
                elif CapacityReservationResourceGroupArn:
                    logger.info(
                        f"Capacity reservation resource group ARN provided: {CapacityReservationResourceGroupArn}"
                    )
                else:
                    logger.info(
                        "No capacity reservation specified, using default preference"
                    )

                # Create an EC2 instance with the user data script
                instance_id = create_ec2_instance(
                    idx,
                    PRIVATE_KEY_NAME,
                    sg_id,
                    user_data_script,
                    ami_id,
                    instance_type,
                    iam_arn,
                    region,
                    device_name,
                    ebs_del_on_termination,
                    ebs_Iops,
                    ebs_VolumeSize,
                    ebs_VolumeType,
                    CapacityReservationPreference,
                    CapacityReservationId,
                    CapacityReservationResourceGroupArn,
                )
                instance_id_list.append(instance_id)
                instance_data_map[instance_id] = {
                    "fmbench_config": instance["fmbench_config"],
                    "post_startup_script": instance["post_startup_script"],
                    "post_startup_script_params": instance.get(
                        "post_startup_script_params"
                    ),
                    "fmbench_complete_timeout": instance["fmbench_complete_timeout"],
                    "region": instance.get("region", region),
                    "PRIVATE_KEY_FNAME": PRIVATE_KEY_FNAME,
                    "upload_files": instance.get("upload_files"),
                }
            else:
                instance_id = instance["instance_id"]
                # TODO: Check if host machine can open the private key provided, if it cant, raise exception
                PRIVATE_KEY_FNAME = instance["private_key_fname"]
                if not PRIVATE_KEY_FNAME:
                    logger.error(
                        "Private key not found, not adding instance to instance id list"
                    )
                if upload_and_run_script(
                    instance_id,
                    PRIVATE_KEY_FNAME,
                    user_data_script,
                    instance["region"],
                    instance["startup_script"],
                ):
                    logger.info(
                        f"Startup script uploaded and executed on instance {instance_id}"
                    )
                else:
                    logger.error(
                        f"Failed to upload and execute startup script on instance {instance_id}"
                    )
                if PRIVATE_KEY_FNAME:
                    instance_id_list.append(instance_id)
                    instance_data_map[instance_id] = {
                        "fmbench_config": instance["fmbench_config"],
                        "post_startup_script": instance["post_startup_script"],
                        "fmbench_complete_timeout": instance[
                            "fmbench_complete_timeout"
                        ],
                        "post_startup_script_params": instance.get(
                            "post_startup_script_params"
                        ),
                        "region": instance.get("region", region),
                        "PRIVATE_KEY_FNAME": PRIVATE_KEY_FNAME,
                        "upload_files": instance.get("upload_files"),
                    }

                logger.info(f"done creating instance {idx} of {num_instances}")

    sleep_time = 60
    logger.info(
        f"Going to Sleep for {sleep_time} seconds to make sure the instances are up"
    )
    time.sleep(sleep_time)

    instance_details = generate_instance_details(
        instance_id_list, instance_data_map
    )  # Call the async function
    asyncio.run(main())
    logger.info("all done")


================================================
File: /requirements.txt
================================================
scp==0.15.0
wget==3.2
boto3==1.35.21
PyYAML==6.0.2
paramiko==3.5.0
requests==2.32.3
pandas==2.2.3
plotly==5.24.1
seaborn==0.13.2
tomark==0.1.4
Jinja2==3.1.4


================================================
File: /docs/iam.md
================================================
# IAM role for FMBench orchestrator

Here are the permissions and trust policies that the IAM role assigned to the Amazon EC2 machines used by the FMBench orchestrator needs to have. This role is used both for the driver node i.e. the machine on which the orchestrator is installed and the individual EC2 VMs created by the driver node on which the FMBench benchmarking runs.

## Create the permission policy under IAM -> Policies 

Name it something like ```fmbench-orchestrator-permissions```

1. Permissions 

    ```{.bash}
    {
        "Version": "2012-10-17",
        "Statement": [
            {
                "Effect": "Allow",
                "Action": [
                    "ecr:GetAuthorizationToken",
                    "ecr:BatchCheckLayerAvailability",
                    "ecr:GetDownloadUrlForLayer",
                    "ecr:BatchGetImage",
                    "ecr:ListImages"
                ],
                "Resource": "*"
            },
            {
                "Effect": "Allow",
                "Action": [
                    "ec2:RunInstances",
                    "ec2:DescribeInstances",
                    "ec2:CreateTags",
                    "ec2:StartInstances",
                    "ec2:StopInstances",
                    "ec2:RebootInstances"
                ],
                "Resource": [
                    "arn:aws:ec2:*:*:instance/*",
                    "arn:aws:ec2:*:*:volume/*",
                    "arn:aws:ec2:*:*:network-interface/*",
                    "arn:aws:ec2:*:*:key-pair/*",
                    "arn:aws:ec2:*:*:security-group/*",
                    "arn:aws:ec2:*:*:subnet/*",
                    "arn:aws:ec2:*:*:image/*",
                    "arn:aws:ec2:*:*:capacity-reservation/*"
                ]
            },
            {
                "Effect": "Allow",
                "Action": [
                    "ec2:CreateSecurityGroup",
                    "ec2:AuthorizeSecurityGroupIngress",
                    "ec2:AuthorizeSecurityGroupEgress",
                    "ec2:DescribeSecurityGroups"
                ],
                "Resource": "*"
            },
            {
                "Effect": "Allow",
                "Action": [
                    "ec2:CreateKeyPair",
                    "ec2:DescribeKeyPairs",
                    "ec2:DeleteKeyPair"
                ],
                "Resource": "*"
            },
            {
                "Effect": "Allow",
                "Action": [
                    "ec2:CreateTags",
                    "ec2:DescribeInstances",
                    "ec2:TerminateInstances",
                    "ec2:DescribeInstanceStatus",
                    "ec2:DescribeAddresses",
                    "ec2:AssociateAddress",
                    "ec2:DisassociateAddress",
                    "ec2:DescribeRegions",
                    "ec2:DescribeImages",
                    "ec2:DescribeAvailabilityZones"
                ],
                "Resource": "*"
            },
            {
                "Effect": "Allow",
                "Action": "iam:PassRole",
                "Resource": [
                    "arn:aws:iam::*:role/fmbench*"
                ]
            }
        ]
    }
    ```

## Create the role itself under IAM-> Roles

Use the AWS Service/EC2 use case.  Name it ```fmbench-orchestrator``` and attach the permissions policy created above.  You will have the option to add a Trust policy (shown below), but this should be the default.
1. Trust policies

    ```{.bash}
    {
        "Version": "2012-10-17",
        "Statement": [
            {
                "Effect": "Allow",
                "Principal": {
                    "Service": "ec2.amazonaws.com"
                },
                "Action": "sts:AssumeRole"
            },
            {
                "Effect": "Allow",
                "Principal": {
                    "Service": "sagemaker.amazonaws.com"
                },
                "Action": "sts:AssumeRole"
            },
            {
                "Effect": "Allow",
                "Principal": {
                    "Service": "bedrock.amazonaws.com"
                },
                "Action": "sts:AssumeRole"
            }
        ]
    }
    ```


## Amazon Bedrock and Amazon SageMaker endpoint support

Add these policies to the IAM role you just created.

1. AmazonBedrockFullAccess
1. AmazonS3FullAccess
1. AmazonSageMakerFullAccess
1. AWSPriceListServiceFullAccess


================================================
File: /docs/config_guide.md
================================================

# `FMBench` orchestrator configuration guide

## Overview

The orchestrator uses multiple config files, these are:

- **config.yml**: this is the main configuration file and this is the one you would create/modify for individual runs. This contains parameters for EC2 instances to use for benchmarking and which `FMBench` config files to use. For an example, see [`ec2.yml](../configs/ec2.yml). This file contains parameters that you would typically need to change.

- **infra.yml**: this file contains infrastructure and orchestration related parameters, you would most likely never need to change contents of this file. For an example, see [`infra.yml`](../configs/infra.yml).

- **ami_mapping.yml**: this file contains the AMIs to be used for a given instance type i.e. a GPU, CPU or AWS Chips (Trainium, Inferentia) for a given region. Unless you are using a custom AMI you do not need to modify this file.

This configuration file is used to manage the deployment and orchestration of multiple EC2 instances for running `FMBench` benchmarks. The file defines various parameters, including AWS settings, run steps, security group settings, key pair management, and instance-specific configurations. This guide explains the purpose of each section and provides details on how to customize the file according to your requirements.

## Configuration files

### `infra.yml`

#### AWS Settings

This section contains the basic settings required to interact with AWS services.

- `region`: Unless you want to specify a region explicitly, this is always set to `{{region}}` which gets replaced with the current region of the EC2 VM on which the orchestrator is being run. The `region` parameter can also be specified with each instance in the `instances` section, if specified in the `instances` section then that value would override the value in this section. This allows for launching instances in a region different from the region in which the orchestrator is running.
- `hf_token_fpath`: Your Hugging Face token for accessing specific resources or APIs. Always set to `/tmp/hf_token.txt` unless you want to store the token in a different path.

#### Run Steps

Defines the various steps in the orchestration process. Set each step to `yes` or `no` based on whether you want that step to be executed.

- `security_group_creation`: Whether to create a new security group for the EC2 instances. Set to `yes` to create a new security group or `no` to use an existing one.
- `key_pair_generation`: Whether to generate a new key pair for accessing the EC2 instances. If set to `no`, ensure you have an existing key pair available.
- `deploy_ec2_instance`: Whether to deploy the EC2 instances as specified in the `instances` section.
- `delete_ec2_instance`: Whether to terminate the EC2 instances after completing the benchmarks.

#### Security Group

This section configures the security group settings for the EC2 instances. You would typically not need to change anything in this section from what is specified in the [default config file](configs/config.yml).

- `group_name`: Name of the security group to be created or used. If a group with this name already exists, it will be used.
- `description`: A brief description of the security group, such as "MultiDeploy EC2 Security Group."
- `vpc_id`: The VPC ID where the security group will be created. Leave this blank to use the default VPC.

#### Key Pair Management

Manages the SSH key pair used for accessing the EC2 instances. You would typically not need to change anything in this section from what is specified in the [default config file](configs/config.yml).

- `key_pair_name`: Name of the key pair to be created or used. If `key_pair_generation` is set to `no`, ensure this matches the name of an existing key pair.
- `key_pair_fpath`: The file path where the key pair file (`.pem`) will be stored locally. Update this path if you have an existing key pair.

### `config.yml`

#### Instances

Defines the EC2 instances to be launched for running the benchmarks. This section can contain multiple instance configurations.

- `instance_type`: The type of EC2 instance to be launched (e.g., `g5.2xlarge`). Choose based on your resource requirements.
- `deploy`: (_Optional_, default: `yes`) set to `yes` if you want to run benchmarking on this instance, `no` otherwise (comes in handy if you want to skip a particular instance from the run but do not want to remove it from the config file).
- `ami_id`: Set to one of `{{gpu}}`, `{{cpu}}`, or `{{neuron}}` depending upon instance type. The orchestrator code replaces it with the actual ami id based on the region and whether it is a `gpu`, `cpu` or `neuron` instance.
- `startup_script`: Path to the startup script that will be executed when the instance is launched. This script should be stored in the `startup_scripts` directory.
- `post_startup_script`: Path to a script that will be executed after the initial startup script. Use this for any additional configuration or benchmark execution commands.
- `fmbench_config`: URL or file path to the `FMBench` configuration file that will be used by the orchestrator. If specifying a config file from the `FMBench` GitHub repo you can simply say (for example) `fmbench:llama3.1/70b/config-ec2-llama3-1-70b-p4de.24xl-deploy-ec2-longbench.yml` which will be translated into `https://raw.githubusercontent.com/aws-samples/foundation-model-benchmarking-tool/refs/heads/main/src/fmbench/configs/llama3.1/70b/config-ec2-llama3-1-70b-p4de.24xl-deploy-ec2-longbench.yml` by the orchestrator code.

- `upload_files`: this is a list of `local` and `remote` entries where any file on the orchestrator machine can be uploaded to a remote path into the instance. This can be used for uploading a custom prompt, a custom tokenizer, a custom pricing file etc. In the example below we are uploading a custom dataset and a custom prompt template from the local (orchestrator) machine to the remote machine.
    ```
    upload_files:
    - local: byo_dataset/synthetic_data_large_prompts.jsonl
      remote: /tmp/fmbench-read/source_data
    - local: byo_dataset/prompt_template_llama3_summarization.txt
      remote: /tmp/fmbench-read/prompt_template/prompt_template_llama3_summarization.txt
    ```


#### Sample instance configuration

The following is an example configuration for deploying a `g6e.2xlarge` instance with GPU AMI (Ubuntu Deep Learning OSS) and startup scripts:

```yaml
instances:
- instance_type: g6e.2xlarge
  region: {{region}}
  ami_id: {{gpu}}
  device_name: /dev/sda1
  ebs_del_on_termination: True
  ebs_Iops: 16000
  ebs_VolumeSize: 250
  ebs_VolumeType: gp3
  startup_script: startup_scripts/ubuntu_startup.txt
  post_startup_script: post_startup_scripts/fmbench.txt
  # Timeout period in Seconds before a run is stopped
  fmbench_complete_timeout: 2400
  fmbench_config: 
  - fmbench:llama3/8b/config-ec2-llama3-8b-g6e-2xlarge.yml
  upload_files:
  - local: byo_dataset/custom.jsonl
    remote: /tmp
  - local: analytics/pricing.yml
    remote: /tmp
```



================================================
File: /configs/infra.yml
================================================
aws:
  # This is the path to the hf token file that contains your custom
  # hf token
  hf_token_fpath: /tmp/hf_token.txt
  # AWS region, this parameter is templatized, no need to change
  region: {{region}}
  
# steps to run the fmbench orchestration
# test. If all steps are set to yes, the security
# group will be greated, the keys will be generated at 
# instance creation, EC2 instances will be created, 
# the FMBench orchestration test will run and then at the 
# end the infrastructure (in this case EC2 instances) will
# be deleted.
# All results are stored in the local results directory at the end of the
# FMBench orchestration test.
run_steps:
  security_group_creation: yes
  key_pair_generation: yes
  deploy_ec2_instance: yes
  delete_ec2_instance: yes

security_group:
  group_name: fmbench_orchestrator_sg
  description: MultiDeploy EC2 Security Group
  # If VPC Is left empty, boto3 automatically gets the default VPC for your region
  # If your current region does not have an active default VPC set up, set it up manually
  # following the steps here: https://docs.aws.amazon.com/vpc/latest/userguide/work-with-default-vpc.html#create-default-vpc
  vpc_id:


key_pair_gen:
  #Need to change this name to something better?
  # This assumes that if key_pair_generation is false, you have the key pair stored in the root.
  # If so, change the file name to your KP name and the script will pick it up.
  key_pair_name: fmbench_orchestrator_key_pair



================================================
File: /configs/ec2_llama3.2-1b-cpu-byodataset.yml
================================================
# general configuration applicable to the entire app
general:
  name: llama3.2-1b-cpu

# Take the below as list of dict as there might be 2 instances with the same AMI
defaults: &cpu_settings
  region: {{region}}
  ami_id: {{cpu}}
  device_name: /dev/xvda
  ebs_del_on_termination: True
  ebs_Iops: 16000
  ebs_VolumeSize: 250
  ebs_VolumeType: gp3
  startup_script: startup_scripts/cpu_al2023_startup.txt
  post_startup_script: post_startup_scripts/fmbench.txt
  # Timeout period in Seconds before a run is stopped
  fmbench_complete_timeout: 3600

instances:

- instance_type: m7a.24xlarge
  <<: *cpu_settings  
  fmbench_config: 
  - fmbench:llama3.2/1b/config-llama3.2-1b-m7a-24xlarge-ec2-summarization.yml
  upload_files:
  - local: byo_dataset/synthetic_data_large_prompts.jsonl
    remote: /tmp/fmbench-read/source_data/
  - local: byo_dataset/prompt_template_llama3_summarization.txt
    remote: /tmp/fmbench-read/prompt_template/


================================================
File: /configs/llama3.1/8b/llama3.1-8b-g5.yml
================================================
# general configuration applicable to the entire app
general:
  name: llama3.1-8b-g5

defaults: &ec2_settings
  region: {{region}}
  ami_id: {{gpu}}
  device_name: /dev/sda1
  ebs_del_on_termination: True
  ebs_Iops: 16000
  ebs_VolumeSize: 250
  ebs_VolumeType: gp3
  startup_script: startup_scripts/ubuntu_startup.txt
  post_startup_script: post_startup_scripts/fmbench.txt
  # Timeout period in Seconds before a run is stopped
  fmbench_complete_timeout: 2400
  
instances:
- instance_type: g5.xlarge
  deploy: yes
  <<: *ec2_settings
  fmbench_config: 
  - fmbench:llama3.1/8b/config-llama3.1-8b-g5.xl-tp-1-mc-max-ec2-conc-1-2.yml

- instance_type: g5.2xlarge
  deploy: yes
  <<: *ec2_settings
  fmbench_config: 
  - fmbench:llama3.1/8b/config-llama3.1-8b-g5.2xl-tp-1-mc-max-ec2-conc-1-2.yml




================================================
File: /configs/llama3.1/8b/llama3.1-8b-g6e-p5-djl.yml
================================================
# general configuration applicable to the entire app
general:
  name: llama3.1-8b-g6e-p5-djl

defaults: &ec2_settings
  region: {{region}}
  ami_id: {{gpu}}
  device_name: /dev/sda1
  ebs_del_on_termination: True
  ebs_Iops: 16000
  ebs_VolumeSize: 250
  ebs_VolumeType: gp3
  startup_script: startup_scripts/ubuntu_startup.txt
  post_startup_script: post_startup_scripts/fmbench.txt
  # Timeout period in Seconds before a run is stopped
  fmbench_complete_timeout: 2400
  
instances:
- instance_type: g6e.2xlarge
  deploy: yes
  <<: *ec2_settings
  fmbench_config: 
  - fmbench:llama3.1/8b/config-llama3.1-8b-g6e.2xl-tp-1-mc-max-djl.yml

- instance_type: g6e.4xlarge
  deploy: yes
  <<: *ec2_settings
  fmbench_config: 
  - fmbench:llama3.1/8b/config-llama3.1-8b-g6e.4xl-tp-1-mc-max-djl.yml

- instance_type: g6e.12xlarge
  deploy: yes
  <<: *ec2_settings
  fmbench_config: 
  - fmbench:llama3.1/8b/config-llama3.1-8b-g6e.12xl-tp-2-mc-max-djl.yml
  - fmbench:llama3.1/8b/config-llama3.1-8b-g6e.12xl-tp-4-mc-max-djl.yml

- instance_type: g6e.24xlarge
  deploy: yes
  <<: *ec2_settings
  fmbench_config: 
  - fmbench:llama3.1/8b/config-llama3.1-8b-g6e.24xl-tp-2-mc-max-djl.yml
  - fmbench:llama3.1/8b/config-llama3.1-8b-g6e.24xl-tp-4-mc-max-djl.yml

- instance_type: g6e.48xlarge
  deploy: yes
  <<: *ec2_settings
  fmbench_config: 
  - fmbench:llama3.1/8b/config-llama3.1-8b-g6e.48xl-tp-2-mc-max-djl.yml
  - fmbench:llama3.1/8b/config-llama3.1-8b-g6e.48xl-tp-4-mc-max-djl.yml
  - fmbench:llama3.1/8b/config-llama3.1-8b-g6e.48xl-tp-8-mc-max-djl.yml

- instance_type: p5.48xlarge
  deploy: no
  <<: *ec2_settings
  fmbench_config: 
  - fmbench:llama3.1/8b/config-ec2-llama3-1-8b-p5-tp-2-mc-max.yml


================================================
File: /configs/llama3.1/70b/llama3.1-70b-p4de-summariztion.yml
================================================
# general configuration applicable to the entire app
general:
  name: llama3.1-70b-summarization

instances:
# This is for a capacity reservation type instance p4de.24xlarge
- instance_type: p4de.24xlarge
  deploy: yes
  region: us-west-2
  ami_id: {{ gpu }}
  device_name: /dev/sda1
  ebs_del_on_termination: True
  ebs_Iops: 16000
  ebs_VolumeSize: 400
  ebs_VolumeType: gp3
  #Defaults to none, You can use either Reservation Id ARN or both
  CapacityReservationPreference: 
  CapacityReservationId: cr-0aed3d7ec3ff92812
  CapacityReservationResourceGroupArn:
  startup_script: startup_scripts/ubuntu_startup.txt
  post_startup_script: post_startup_scripts/fmbench.txt
  # Timeout period in Seconds before a run is stopped
  fmbench_complete_timeout: 6000
  fmbench_config: 
  - fmbench:llama3.1/70b/config-ec2-llama3-1-70b-p4de.24xl-deploy-ec2-summarization.yml
  upload_files:
  - local: byo_dataset/synthetic_data_large_prompts.jsonl
    remote: /tmp/fmbench-read/source_data
  - local: byo_dataset/prompt_template_llama3_summarization.txt
    remote: /tmp/fmbench-read/prompt_template/prompt_template_llama3_summarization.txt



================================================
File: /configs/llama3.1/70b/llama3.1-70b-g5-g6-g6e-trn-inf-p4de.yml
================================================
# general configuration applicable to the entire app
general:
  name: llama3.1-70b

instances:
# This is for g6e type instances
- instance_type: g6e.24xlarge
  deploy: yes
  region: {{region}}
  ami_id: {{ gpu }}
  device_name: /dev/sda1
  ebs_del_on_termination: True
  ebs_Iops: 16000
  ebs_VolumeSize: 400
  ebs_VolumeType: gp3
  startup_script: startup_scripts/ubuntu_startup.txt
  post_startup_script: post_startup_scripts/fmbench.txt
  # Timeout period in Seconds before a run is stopped
  fmbench_complete_timeout: 6000
  fmbench_config: 
  - fmbench:llama3.1/70b/config-llama3-1-70b-g6e.24xl-deploy-ec2.yml

- instance_type: g6e.48xlarge
  deploy: yes
  region: {{region}}
  ami_id: {{ gpu }}
  device_name: /dev/sda1
  ebs_del_on_termination: True
  ebs_Iops: 16000
  ebs_VolumeSize: 400
  ebs_VolumeType: gp3
  startup_script: startup_scripts/ubuntu_startup.txt
  post_startup_script: post_startup_scripts/fmbench.txt
  # Timeout period in Seconds before a run is stopped
  fmbench_complete_timeout: 6000
  fmbench_config: 
  - fmbench:llama3.1/70b/config-llama3-1-70b-g6e.48xl-deploy-ec2.yml

# This is for the g6 instance. The only instance you can deploy a llama3.1 70b on a g6 is g6.48xl
- instance_type: g6.48xlarge
  deploy: yes
  region: {{region}}
  ami_id: {{ gpu }}
  device_name: /dev/sda1
  ebs_del_on_termination: True
  ebs_Iops: 16000
  ebs_VolumeSize: 400
  ebs_VolumeType: gp3
  startup_script: startup_scripts/ubuntu_startup.txt
  post_startup_script: post_startup_scripts/fmbench.txt
  # Timeout period in Seconds before a run is stopped
  fmbench_complete_timeout: 6000
  fmbench_config: 
  - fmbench:llama3.1/70b/config-llama3-1-70b-g6.48xl-deploy-ec2.yml

# This is for the g5 instance. The only instance you can deploy a llama3.1 70b on a g5 is g5.48xl
- instance_type: g5.48xlarge
  deploy: yes
  region: us-east-2
  ami_id: {{ gpu }}
  device_name: /dev/sda1
  ebs_del_on_termination: True
  ebs_Iops: 16000
  ebs_VolumeSize: 400
  ebs_VolumeType: gp3
  startup_script: startup_scripts/ubuntu_startup.txt
  post_startup_script: post_startup_scripts/fmbench.txt
  # Timeout period in Seconds before a run is stopped
  fmbench_complete_timeout: 6000
  fmbench_config: 
  - fmbench:llama3.1/70b/config-llama3-1-70b-g5.48xl-deploy-ec2.yml

# This is for a capacity reservation type instance p4de.24xlarge
- instance_type: p4de.24xlarge
  deploy: yes
  region: us-west-2
  ami_id: {{ gpu }}
  device_name: /dev/sda1
  ebs_del_on_termination: True
  ebs_Iops: 16000
  ebs_VolumeSize: 400
  ebs_VolumeType: gp3
  #Defaults to none, You can use either Reservation Id ARN or both
  CapacityReservationPreference: 
  CapacityReservationId: cr-0aed3d7ec3ff92812
  CapacityReservationResourceGroupArn:
  startup_script: startup_scripts/ubuntu_startup.txt
  post_startup_script: post_startup_scripts/fmbench.txt
  # Timeout period in Seconds before a run is stopped
  fmbench_complete_timeout: 6000
  fmbench_config: 
  - fmbench:llama3.1/70b/config-ec2-llama3-1-70b-p4de.24xl-deploy-ec2-longbench.yml

# This is for the trn1.32xlarge instance. This specific example is for triton + djl which gives the most optimal performance for llama3.1 70b on trn1.32xlarge
- instance_type: trn1.32xlarge
  deploy: yes
  region: {{region}} 
  ami_id: {{ neuron }}
  device_name: /dev/sda1
  ebs_del_on_termination: True
  ebs_Iops: 16000
  ebs_VolumeSize: 600 # additional storage required to load the model, docker image, etc
  ebs_VolumeType: gp3
  startup_script: startup_scripts/ubuntu_startup.txt
  post_startup_script: post_startup_scripts/fmbench.txt
  # Timeout period in Seconds before a run is stopped
  fmbench_complete_timeout: 6000
  fmbench_config: 
  - fmbench:llama3.1/70b/config-llama3-1-70b-trn1.32xl-deploy-ec2-triton.yml

# This is for the inf2.48xlarge instance. This specific example is for triton + djl which gives the most optimal performance for llama3.1 70b on inf2.48xlarge
- instance_type: inf2.48xlarge
  deploy: yes
  region: {{region}}
  ami_id: {{ neuron }}
  device_name: /dev/sda1
  ebs_del_on_termination: True
  ebs_Iops: 16000
  ebs_VolumeSize: 600 # additional storage required to load the model, docker image, etc
  ebs_VolumeType: gp3
  startup_script: startup_scripts/ubuntu_startup.txt
  post_startup_script: post_startup_scripts/fmbench.txt
  # Timeout period in Seconds before a run is stopped
  fmbench_complete_timeout: 6000
  fmbench_config: 
  - fmbench:llama3.1/70b/config-llama3-1-70b-inf2.48xl-triton-tp24.yml

# This is for the p5.48xlarge instance
- instance_type: p5.48xlarge
  deploy: no
  region: {{region}}
  ami_id: {{ gpu }}
  device_name: /dev/sda1
  ebs_del_on_termination: True
  ebs_Iops: 16000
  ebs_VolumeSize: 200 # additional storage required to load the model, docker image, etc
  ebs_VolumeType: gp3
  startup_script: startup_scripts/ubuntu_startup.txt
  post_startup_script: post_startup_scripts/fmbench.txt
  # Timeout period in Seconds before a run is stopped
  fmbench_complete_timeout: 6000
  fmbench_config: 
  - fmbench:llama3.1/70b/config-llama3-1-70b-p5-djl-lmi.yml


================================================
File: /configs/llama3.2/llama3.2-1b-cpu-intel-amd.yml
================================================
# general configuration applicable to the entire app
general:
  name: llama3.2-1b-cpu

# Take the below as list of dict as there might be 2 instances with the same AMI
defaults: &cpu_settings
  region: {{region}}
  ami_id: {{cpu}}
  device_name: /dev/xvda
  ebs_del_on_termination: True
  ebs_Iops: 16000
  ebs_VolumeSize: 250
  ebs_VolumeType: gp3
  startup_script: startup_scripts/cpu_al2023_startup.txt
  post_startup_script: post_startup_scripts/fmbench.txt
  # Timeout period in Seconds before a run is stopped
  fmbench_complete_timeout: 3600

instances:
- instance_type: m5.16xlarge
  <<: *cpu_settings
  fmbench_config: 
  - fmbench:llama3.2/1b/config-llama3.2-1b-m5-16xlarge-ec2.yml

- instance_type: m7a.16xlarge
  <<: *cpu_settings
  fmbench_config: 
  - fmbench:llama3.2/1b/config-llama3.2-1b-m7a-16xlarge-ec2.yml

- instance_type: m7a.24xlarge
  <<: *cpu_settings  
  fmbench_config: 
  - fmbench:llama3.2/1b/config-llama3.2-1b-m7a-24xlarge-ec2.yml

- instance_type: m7i.12xlarge
  <<: *cpu_settings
  deploy: no
  fmbench_config: 
  - fmbench:llama3.2/1b/config-llama3.2-1b-m7i-12xlarge-ec2.yml



================================================
File: /configs/ec2_custom_dataset.yml
================================================
# general configuration applicable to the entire app
general:
  name: llama3b-g6e-custom-dataset

#Instance follows the format below.
#   instance_id: {instance_id_here} if Instance_id, then you need to bring your own private key
#   private_key_fname: key_pair/fmbench_orchestrator_1-us-east-1
#                   OR
# - instance_type: {instance_name_here} 
#   region: {region_here}
#   ami_id: {ami_id_here}
#   device_name: /dev/sda1
#   ebs_del_on_termination: True | False
#   ebs_Iops: 16000
#   ebs_VolumeSize: {Volume_Size_Here}
#   ebs_VolumeType: {Volume_type_Here}
#   #Defaults to none, You can use either Reservation Id ARN or both  (The below 3 fields are optional)
#   CapacityReservationPreference: open | none 
#   CapacityReservationId: {The ID of the Capacity Reservation in which to run the instance.}
#   CapacityReservationResourceGroupArn: {The ARN of the Capacity Reservation resource group in which to run the instance.}

### REQUIRED WITH ABOVE:
#   startup_script: startup_scripts/gpu_ubuntu_startup.txt
#   post_startup_script: post_startup_scripts/fmbench.txt
#   fmbench_config: https://raw.githubusercontent.com/dheerajoruganty/multi-deploy-ec2/refs/heads/main/configs/config-ec2-llama3-8b.yml

### OPTIONAL:
#   fmbench_llm_tokenizer_fpath: fmbench_llm_utils/tokenizer.json
#   fmbench_llm_config_fpath: fmbench_llm_utils/config.json
#   fmbench_tokenizer_remote_dir: /tmp/fmbench-read/llama3_tokenizer/
#   # Timeout period in Seconds before a run is stopped
#   fmbench_complete_timeout: 1200

## US-EAST-1 Mapping:
# Neuron AMI : ami-05d498302130f9036
# DeepLearning AMI AL2 : ami-07f302d2a74e2b584
# Al2 AMI, CPU bench : ami-0e54eba7c51c234f6

# Take the below as list of dict as there might be 2 instances with the same AMI

instances:
- instance_type: g6e.2xlarge
  region: {{region}}
  ami_id: {{gpu}}
  device_name: /dev/sda1
  ebs_del_on_termination: True
  ebs_Iops: 16000
  ebs_VolumeSize: 250
  ebs_VolumeType: gp3
  startup_script: startup_scripts/ubuntu_startup.txt
  post_startup_script: post_startup_scripts/fmbench.txt
  # Timeout period in Seconds before a run is stopped
  fmbench_complete_timeout: 2400
  fmbench_config: 
  - fmbench:llama3/8b/config-ec2-llama3-8b-g6e-2xlarge.yml
  upload_files:
  - local: byo_dataset/custom.jsonl
    remote: /tmp/fmbench-read/source_data/
  - local: analytics/pricing.yml
    remote: /tmp/fmbench-read/configs/


================================================
File: /configs/ec2_byo_instance.yml
================================================
# general configuration applicable to the entire app
general:
  name: llama3b-g6e-byo-instance

aws:
  # This is the path to the hf token file that contains your custom
  # hf token
  hf_token_fpath: /tmp/hf_token.txt
  # AWS region, this parameter is templatized, no need to change
  region: {{region}}
  
# steps to run the fmbench orchestration
# test. If all steps are set to yes, the security
# group will be greated, the keys will be generated at 
# instance creation, EC2 instances will be created, 
# the FMBench orchestration test will run and then at the 
# end the infrastructure (in this case EC2 instances) will
# be deleted.
# All results are stored in the local results directory at the end of the
# FMBench orchestration test.
run_steps:
  security_group_creation: yes
  key_pair_generation: no
  deploy_ec2_instance: yes
  run_bash_script: yes
  delete_ec2_instance: yes

security_group:
  group_name: fmbench_orchestrator_sg
  description: MultiDeploy EC2 Security Group
  # If VPC Is left empty, boto3 automatically gets the default VPC for your region
  # If your current region does not have an active default VPC set up, set it up manually
  # following the steps here: https://docs.aws.amazon.com/vpc/latest/userguide/work-with-default-vpc.html#create-default-vpc
  vpc_id:


key_pair_gen:
  #Need to change this name to something better?
  # This assumes that if key_pair_generation is false, you have the key pair stored in the root.
  # If so, change the file name to your KP name and the script will pick it up.
  key_pair_name: H1-kp

#Instance follows the format below.
#   instance_id: {instance_id_here} if Instance_id, then you need to bring your own private key
#   private_key_fname: key_pair/fmbench_orchestrator_1-us-east-1
#                   OR
# - instance_type: {instance_name_here} 
#   region: {region_here}
#   ami_id: {ami_id_here}
#   device_name: /dev/sda1
#   ebs_del_on_termination: True | False
#   ebs_Iops: 16000
#   ebs_VolumeSize: {Volume_Size_Here}
#   ebs_VolumeType: {Volume_type_Here}
#   #Defaults to none, You can use either Reservation Id ARN or both  (The below 3 fields are optional)
#   CapacityReservationPreference: open | none 
#   CapacityReservationId: {The ID of the Capacity Reservation in which to run the instance.}
#   CapacityReservationResourceGroupArn: {The ARN of the Capacity Reservation resource group in which to run the instance.}

### REQUIRED WITH ABOVE:
#   startup_script: startup_scripts/gpu_ubuntu_startup.txt
#   post_startup_script: post_startup_scripts/fmbench.txt
#   fmbench_config: https://raw.githubusercontent.com/dheerajoruganty/multi-deploy-ec2/refs/heads/main/configs/config-ec2-llama3-8b.yml

### OPTIONAL:
#   fmbench_llm_tokenizer_fpath: fmbench_llm_utils/tokenizer.json
#   fmbench_llm_config_fpath: fmbench_llm_utils/config.json
#   fmbench_tokenizer_remote_dir: /tmp/fmbench-read/llama3_tokenizer/
#   # Timeout period in Seconds before a run is stopped
#   fmbench_complete_timeout: 1200

## US-EAST-1 Mapping:
# Neuron AMI : ami-05d498302130f9036
# DeepLearning AMI AL2 : ami-07f302d2a74e2b584
# Al2 AMI, CPU bench : ami-0e54eba7c51c234f6

# Take the below as list of dict as there might be 2 instances with the same AMI

instances:
- instance_id: i-your-instance-id
  private_key_fname: key_pair/H1-kp.pem
  region: {{region}}
  startup_script: startup_scripts/ubuntu_startup.txt
  post_startup_script: post_startup_scripts/fmbench.txt
  # Timeout period in Seconds before a run is stopped
  fmbench_complete_timeout: 2400
  fmbench_config: 
  - fmbench:llama3/8b/config-ec2-llama3-8b-g6e-2xlarge.yml


================================================
File: /configs/ami_mapping.yml
================================================
# This AMI-mapping configuration file contains AMI mapping information per gpu/neuron based instance
# for specific regions. These AMIs are mapped at the time of start up of instances that are used to 
# benchmark the models. The region is fetched from the configuration file.

# AMI-mapping for us-east-1
us-east-1:
  neuron: ami-05d498302130f9036
  gpu: ami-067bd563cecc90173
  cpu: ami-06b21ccaeff8cd686

# AMI-mapping for us-east-2
us-east-2:
  neuron: ami-0109f5338f9bfc64e
  gpu: ami-09748f93764b742d1
  cpu: ami-06b21ccaeff8cd686

# AMI-mapping for us-west-1
us-west-1:
  neuron: ami-092330f6c49fb8a0b
  gpu: ami-047dca3c2da215909
  cpu: ami-06b21ccaeff8cd686

# AMI-mapping for us-west-2
us-west-2:
  neuron: ami-084d4a2de05b27a18
  gpu: ami-0ed0fd5212e1c579b
  cpu: ami-046b5b8111c19b3ac


================================================
File: /configs/llama3/8b/llama3-8b-triton-g6e.yml
================================================
# general configuration applicable to the entire app
general:
  name: llama3-8b-g6e-triton

defaults: &ec2_settings
  region: {{region}}
  ami_id: {{gpu}}
  device_name: /dev/sda1
  ebs_del_on_termination: True
  ebs_Iops: 16000
  ebs_VolumeSize: 250
  ebs_VolumeType: gp3
  startup_script: startup_scripts/ubuntu_startup.txt
  post_startup_script: post_startup_scripts/fmbench.txt
  # Timeout period in Seconds before a run is stopped
  fmbench_complete_timeout: 2400

instances:
- instance_type: g6e.2xlarge
  deploy: yes
  <<: *ec2_settings
  fmbench_config: 
  - fmbench:llama3/8b/config-llama3-8b-g6e.2xl-tp-1-mc-max-triton-ec2.yml

- instance_type: g6e.4xlarge
  deploy: yes
  <<: *ec2_settings
  fmbench_config: 
  - fmbench:llama3/8b/config-llama3-8b-g6e.4xl-tp-1-mc-max-triton-ec2.yml

- instance_type: g6e.12xlarge
  deploy: yes
  <<: *ec2_settings
  fmbench_config: 
  - fmbench:llama3/8b/config-llama3-8b-g6e.12xl-tp-2-mc-max-triton-ec2.yml

- instance_type: g6e.24xlarge
  deploy: yes
  <<: *ec2_settings
  fmbench_config: 
  - fmbench:llama3/8b/config-llama3-8b-g6e.24xl-tp-2-mc-max-triton-ec2.yml

- instance_type: g6e.48xlarge
  deploy: yes
  <<: *ec2_settings
  fmbench_config: 
  - fmbench:llama3/8b/config-llama3-8b-g6e.48xl-tp-2-mc-max-triton-ec2.yml




================================================
File: /configs/llama3/8b/llam3-8b-cpu-intel.yml
================================================
# general configuration applicable to the entire app
general:
  name: llama3b-g6e-cpu-intel

# Take the below as list of dict as there might be 2 instances with the same AMI
defaults: &ec2_intel_settings
  region: {{region}}
  ami_id: {{cpu}}
  device_name: /dev/xvda
  ebs_del_on_termination: True
  ebs_Iops: 16000
  ebs_VolumeSize: 250
  ebs_VolumeType: gp3
  startup_script: startup_scripts/cpu_al2023_startup.txt
  post_startup_script: post_startup_scripts/fmbench.txt
  # Timeout period in Seconds before a run is stopped
  fmbench_complete_timeout: 2400

instances:
- instance_type: m7i.12xlarge
  <<: *ec2_intel_settings
  fmbench_config: 
  - fmbench:llama3/8b/config-ec2-llama3-8b-m7i-12xlarge.yml

- instance_type: m5.16xlarge
  <<: *ec2_intel_settings
  fmbench_config: 
  - fmbench:llama3/8b/config-ec2-llama3-8b-m5-16xlarge.yml


================================================
File: /configs/llama3/8b/llama3-8b-cpu-amd.yml
================================================
# general configuration applicable to the entire app
general:
  name: llama3b-g6e-cpu-amd

defaults: &ec2_amd_settings
  region: {{region}}
  ami_id: {{cpu}}
  device_name: /dev/xvda
  ebs_del_on_termination: True
  ebs_Iops: 16000
  ebs_VolumeSize: 250
  ebs_VolumeType: gp3
  startup_script: startup_scripts/cpu_al2023_startup.txt
  post_startup_script: post_startup_scripts/fmbench.txt
  # Timeout period in Seconds before a run is stopped
  fmbench_complete_timeout: 2400

instances:
- instance_type: m7a.24xlarge
  <<: *ec2_amd_settings
  fmbench_config: 
  - fmbench:llama3/8b/config-ec2-llama3-8b-m7a-24xlarge.yml

- instance_type: m7a.16xlarge
  <<: *ec2_amd_settings
  fmbench_config: 
  - fmbench:llama3/8b/config-ec2-llama3-8b-m7a-16xlarge.yml



================================================
File: /configs/llama3/8b/llama3-8b-djl-g6e.yml
================================================
# general configuration applicable to the entire app
general:
  name: llama3-8b-g6e-djl

defaults: &ec2_settings
  region: {{region}}
  ami_id: {{gpu}}
  device_name: /dev/sda1
  ebs_del_on_termination: True
  ebs_Iops: 16000
  ebs_VolumeSize: 250
  ebs_VolumeType: gp3
  startup_script: startup_scripts/ubuntu_startup.txt
  post_startup_script: post_startup_scripts/fmbench.txt
  # Timeout period in Seconds before a run is stopped
  fmbench_complete_timeout: 2400

instances:
- instance_type: g6e.2xlarge
  deploy: yes
  <<: *ec2_settings
  fmbench_config: 
  - fmbench:llama3/8b/config-ec2-llama3-8b-g6e-2xlarge.yml

- instance_type: g6e.4xlarge
  deploy: yes
  <<: *ec2_settings
  fmbench_config: 
  - fmbench:llama3/8b/config-llama3-8b-g6e.4xl-tp-1-mc-max-djl-ec2.yml

- instance_type: g6e.12xlarge
  deploy: yes
  <<: *ec2_settings
  fmbench_config: 
  - fmbench:llama3/8b/config-llama3-8b-g6e.12xl-tp-2-mc-max-djl-ec2.yml

- instance_type: g6e.24xlarge
  deploy: yes
  <<: *ec2_settings
  fmbench_config: 
  - fmbench:llama3/8b/config-llama3-8b-g6e.24xl-tp-2-mc-max-djl-ec2.yml

- instance_type: g6e.48xlarge
  deploy: yes
  <<: *ec2_settings
  fmbench_config: 
  - fmbench:llama3/8b/config-llama3-8b-g6e.48xl-tp-2-mc-max-djl-ec2.yml




================================================
File: /configs/bedrock/llama3.2-bedrock.yml
================================================
# general configuration applicable to the entire app
general:
  name: llama3.2-bedrock

aws:
  # This is the path to the hf token file that contains your custom
  # hf token
  hf_token_fpath: /tmp/hf_token.txt
  # AWS region, this parameter is templatized, no need to change
  region: {{region}}
  
# steps to run the fmbench orchestration
# test. If all steps are set to yes, the security
# group will be greated, the keys will be generated at 
# instance creation, EC2 instances will be created, 
# the FMBench orchestration test will run and then at the 
# end the infrastructure (in this case EC2 instances) will
# be deleted.
# All results are stored in the local results directory at the end of the
# FMBench orchestration test.
run_steps:
  security_group_creation: yes
  key_pair_generation: yes
  deploy_ec2_instance: yes
  run_bash_script: yes
  delete_ec2_instance: yes

security_group:
  group_name: fmbench_orchestrator_sg
  description: MultiDeploy EC2 Security Group
  # If VPC Is left empty, boto3 automatically gets the default VPC for your region
  # If your current region does not have an active default VPC set up, set it up manually
  # following the steps here: https://docs.aws.amazon.com/vpc/latest/userguide/work-with-default-vpc.html#create-default-vpc
  vpc_id:


key_pair_gen:
  #Need to change this name to something better?
  # This assumes that if key_pair_generation is false, you have the key pair stored in the root.
  # If so, change the file name to your KP name and the script will pick it up.
  key_pair_name: fmbench_orchestrator_key_pair

#Instance follows the format below.
#   instance_id: {instance_id_here} if Instance_id, then you need to bring your own private key
#   private_key_fname: key_pair/fmbench_orchestrator_1-us-east-1
#                   OR
# - instance_type: {instance_name_here} 
#   region: {region_here}
#   ami_id: {ami_id_here}
#   device_name: /dev/sda1
#   ebs_del_on_termination: True | False
#   ebs_Iops: 16000
#   ebs_VolumeSize: {Volume_Size_Here}
#   ebs_VolumeType: {Volume_type_Here}
#   #Defaults to none, You can use either Reservation Id ARN or both  (The below 3 fields are optional)
#   CapacityReservationPreference: open | none 
#   CapacityReservationId: {The ID of the Capacity Reservation in which to run the instance.}
#   CapacityReservationResourceGroupArn: {The ARN of the Capacity Reservation resource group in which to run the instance.}

### REQUIRED WITH ABOVE:
#   startup_script: startup_scripts/gpu_ubuntu_startup.txt
#   post_startup_script: post_startup_scripts/fmbench.txt
#   fmbench_config: https://raw.githubusercontent.com/dheerajoruganty/multi-deploy-ec2/refs/heads/main/configs/config-ec2-llama3-8b.yml

### OPTIONAL:
#   fmbench_llm_tokenizer_fpath: fmbench_llm_utils/tokenizer.json
#   fmbench_llm_config_fpath: fmbench_llm_utils/config.json
#   fmbench_tokenizer_remote_dir: /tmp/fmbench-read/llama3_tokenizer/
#   # Timeout period in Seconds before a run is stopped
#   fmbench_complete_timeout: 1200

## US-EAST-1 Mapping:
# Neuron AMI : ami-05d498302130f9036
# DeepLearning AMI AL2 : ami-07f302d2a74e2b584
# Al2 AMI, CPU bench : ami-0e54eba7c51c234f6

# Take the below as list of dict as there might be 2 instances with the same AMI

instances:
- instance_type: m7a.xlarge
  region: {{region}}
  ami_id: {{gpu}}
  device_name: /dev/sda1
  ebs_del_on_termination: True
  ebs_Iops: 16000
  ebs_VolumeSize: 250
  ebs_VolumeType: gp3
  startup_script: startup_scripts/bedrock/ubuntu_bedrock_startup.txt
  post_startup_script: post_startup_scripts/fmbench.txt
  # Timeout period in Seconds before a run is stopped
  fmbench_complete_timeout: 7200
  fmbench_config: 
  - fmbench:bedrock/config-llama-3-2-all-models.yml


================================================
File: /configs/bedrock/llama3.1-bedrock.yml
================================================
# general configuration applicable to the entire app
general:
  name: llama3.1-bedrock

aws:
  # This is the path to the hf token file that contains your custom
  # hf token
  hf_token_fpath: /tmp/hf_token.txt
  # AWS region, this parameter is templatized, no need to change
  region: {{region}}
  
# steps to run the fmbench orchestration
# test. If all steps are set to yes, the security
# group will be greated, the keys will be generated at 
# instance creation, EC2 instances will be created, 
# the FMBench orchestration test will run and then at the 
# end the infrastructure (in this case EC2 instances) will
# be deleted.
# All results are stored in the local results directory at the end of the
# FMBench orchestration test.
run_steps:
  security_group_creation: yes
  key_pair_generation: yes
  deploy_ec2_instance: yes
  run_bash_script: yes
  delete_ec2_instance: yes

security_group:
  group_name: fmbench_orchestrator_sg
  description: MultiDeploy EC2 Security Group
  # If VPC Is left empty, boto3 automatically gets the default VPC for your region
  # If your current region does not have an active default VPC set up, set it up manually
  # following the steps here: https://docs.aws.amazon.com/vpc/latest/userguide/work-with-default-vpc.html#create-default-vpc
  vpc_id:


key_pair_gen:
  #Need to change this name to something better?
  # This assumes that if key_pair_generation is false, you have the key pair stored in the root.
  # If so, change the file name to your KP name and the script will pick it up.
  key_pair_name: fmbench_orchestrator_key_pair

#Instance follows the format below.
#   instance_id: {instance_id_here} if Instance_id, then you need to bring your own private key
#   private_key_fname: key_pair/fmbench_orchestrator_1-us-east-1
#                   OR
# - instance_type: {instance_name_here} 
#   region: {region_here}
#   ami_id: {ami_id_here}
#   device_name: /dev/sda1
#   ebs_del_on_termination: True | False
#   ebs_Iops: 16000
#   ebs_VolumeSize: {Volume_Size_Here}
#   ebs_VolumeType: {Volume_type_Here}
#   #Defaults to none, You can use either Reservation Id ARN or both  (The below 3 fields are optional)
#   CapacityReservationPreference: open | none 
#   CapacityReservationId: {The ID of the Capacity Reservation in which to run the instance.}
#   CapacityReservationResourceGroupArn: {The ARN of the Capacity Reservation resource group in which to run the instance.}

### REQUIRED WITH ABOVE:
#   startup_script: startup_scripts/gpu_ubuntu_startup.txt
#   post_startup_script: post_startup_scripts/fmbench.txt
#   fmbench_config: https://raw.githubusercontent.com/dheerajoruganty/multi-deploy-ec2/refs/heads/main/configs/config-ec2-llama3-8b.yml

### OPTIONAL:
#   fmbench_llm_tokenizer_fpath: fmbench_llm_utils/tokenizer.json
#   fmbench_llm_config_fpath: fmbench_llm_utils/config.json
#   fmbench_tokenizer_remote_dir: /tmp/fmbench-read/llama3_tokenizer/
#   # Timeout period in Seconds before a run is stopped
#   fmbench_complete_timeout: 1200

## US-EAST-1 Mapping:
# Neuron AMI : ami-05d498302130f9036
# DeepLearning AMI AL2 : ami-07f302d2a74e2b584
# Al2 AMI, CPU bench : ami-0e54eba7c51c234f6

# Take the below as list of dict as there might be 2 instances with the same AMI

instances:
- instance_type: m7a.xlarge
  # Setting the region to 'us-west-2' for llama3.1 8b and 70b models on 
  # Bedrock
  region: us-west-2 
  ami_id: {{gpu}}
  device_name: /dev/sda1
  ebs_del_on_termination: True
  ebs_Iops: 16000
  ebs_VolumeSize: 250
  ebs_VolumeType: gp3
  startup_script: startup_scripts/bedrock/ubuntu_bedrock_startup.txt
  post_startup_script: post_startup_scripts/fmbench.txt
  # Timeout period in Seconds before a run is stopped
  fmbench_complete_timeout: 7200
  fmbench_config: 
  - fmbench:bedrock/config-bedrock-llama3-1.yml


================================================
File: /configs/sagemaker.yml
================================================
# general configuration applicable to the entire app
general:
  name: sagemaker
#Instance follows the format below.
#   instance_id: {instance_id_here} if Instance_id, then you need to bring your own private key
#   private_key_fname: key_pair/fmbench_orchestrator_1-us-east-1
#                   OR
# - instance_type: {instance_name_here} 
#   region: {region_here}
#   ami_id: {ami_id_here}
#   device_name: /dev/sda1
#   ebs_del_on_termination: True | False
#   ebs_Iops: 16000
#   ebs_VolumeSize: {Volume_Size_Here}
#   ebs_VolumeType: {Volume_type_Here}
#   #Defaults to none, You can use either Reservation Id ARN or both  (The below 3 fields are optional)
#   CapacityReservationPreference: open | none 
#   CapacityReservationId: {The ID of the Capacity Reservation in which to run the instance.}
#   CapacityReservationResourceGroupArn: {The ARN of the Capacity Reservation resource group in which to run the instance.}

### REQUIRED WITH ABOVE:
#   startup_script: startup_scripts/gpu_ubuntu_startup.txt
#   post_startup_script: post_startup_scripts/fmbench.txt
#   fmbench_config: https://raw.githubusercontent.com/dheerajoruganty/multi-deploy-ec2/refs/heads/main/configs/config-ec2-llama3-8b.yml

### OPTIONAL:
#   fmbench_llm_tokenizer_fpath: fmbench_llm_utils/tokenizer.json
#   fmbench_llm_config_fpath: fmbench_llm_utils/config.json
#   fmbench_tokenizer_remote_dir: /tmp/fmbench-read/llama3_tokenizer/
#   # Timeout period in Seconds before a run is stopped
#   fmbench_complete_timeout: 1200

## US-EAST-1 Mapping:
# Neuron AMI : ami-05d498302130f9036
# DeepLearning AMI AL2 : ami-07f302d2a74e2b584
# Al2 AMI, CPU bench : ami-0e54eba7c51c234f6

# Take the below as list of dict as there might be 2 instances with the same AMI

defaults: &ec2_settings
  region: {{region}}
  ami_id: {{gpu}}
  device_name: /dev/sda1
  ebs_del_on_termination: True
  ebs_Iops: 16000
  ebs_VolumeSize: 250
  ebs_VolumeType: gp3
  startup_script: startup_scripts/ubuntu_startup.txt
  post_startup_script: post_startup_scripts/fmbench.txt
  post_startup_script_params:
    write_bucket: {{write_bucket}}
  # Timeout period in Seconds before a run is stopped
  fmbench_complete_timeout: 10000

instances:
- instance_type: m7a.xlarge
  <<: *ec2_settings
  fmbench_config: 
  - {{config_file}}


================================================
File: /configs/ec2.yml
================================================
# general configuration applicable to the entire app
general:
  name: llama3b-g6e

#Instance follows the format below.
#   instance_id: {instance_id_here} if Instance_id, then you need to bring your own private key
#   private_key_fname: key_pair/fmbench_orchestrator_1-us-east-1
#                   OR
# - instance_type: {instance_name_here} 
#   region: {region_here}
#   ami_id: {ami_id_here}
#   device_name: /dev/sda1
#   ebs_del_on_termination: True | False
#   ebs_Iops: 16000
#   ebs_VolumeSize: {Volume_Size_Here}
#   ebs_VolumeType: {Volume_type_Here}
#   #Defaults to none, You can use either Reservation Id ARN or both  (The below 3 fields are optional)
#   CapacityReservationPreference: open | none 
#   CapacityReservationId: {The ID of the Capacity Reservation in which to run the instance.}
#   CapacityReservationResourceGroupArn: {The ARN of the Capacity Reservation resource group in which to run the instance.}

### REQUIRED WITH ABOVE:
#   startup_script: startup_scripts/gpu_ubuntu_startup.txt
#   post_startup_script: post_startup_scripts/fmbench.txt
#   fmbench_config: https://raw.githubusercontent.com/dheerajoruganty/multi-deploy-ec2/refs/heads/main/configs/config-ec2-llama3-8b.yml

### OPTIONAL:
#   fmbench_llm_tokenizer_fpath: fmbench_llm_utils/tokenizer.json
#   fmbench_llm_config_fpath: fmbench_llm_utils/config.json
#   fmbench_tokenizer_remote_dir: /tmp/fmbench-read/llama3_tokenizer/
#   # Timeout period in Seconds before a run is stopped
#   fmbench_complete_timeout: 1200

## US-EAST-1 Mapping:
# Neuron AMI : ami-05d498302130f9036
# DeepLearning AMI AL2 : ami-07f302d2a74e2b584
# Al2 AMI, CPU bench : ami-0e54eba7c51c234f6

# Take the below as list of dict as there might be 2 instances with the same AMI

defaults: &ec2_settings
  region: {{region}}
  ami_id: {{gpu}}
  device_name: /dev/sda1
  ebs_del_on_termination: True
  ebs_Iops: 16000
  ebs_VolumeSize: 250
  ebs_VolumeType: gp3
  startup_script: startup_scripts/ubuntu_startup.txt
  post_startup_script: post_startup_scripts/fmbench.txt
  # Timeout period in Seconds before a run is stopped
  fmbench_complete_timeout: 2400

instances:
- instance_type: g6e.2xlarge
  <<: *ec2_settings    
  fmbench_config: 
  - fmbench:llama3/8b/config-ec2-llama3-8b-g6e-2xlarge.yml

- instance_type: g6e.4xlarge
  <<: *ec2_settings
  fmbench_config: 
  - fmbench:llama3/8b/config-llama3-8b-g6e.4xl-tp-1-mc-max-djl-ec2.yml



================================================
File: /configs/bedrock.yml
================================================
# general configuration applicable to the entire app
general:
  name: bedrock

#Instance follows the format below.
#   instance_id: {instance_id_here} if Instance_id, then you need to bring your own private key
#   private_key_fname: key_pair/fmbench_orchestrator_1-us-east-1
#                   OR
# - instance_type: {instance_name_here} 
#   region: {region_here}
#   ami_id: {ami_id_here}
#   device_name: /dev/sda1
#   ebs_del_on_termination: True | False
#   ebs_Iops: 16000
#   ebs_VolumeSize: {Volume_Size_Here}
#   ebs_VolumeType: {Volume_type_Here}
#   #Defaults to none, You can use either Reservation Id ARN or both  (The below 3 fields are optional)
#   CapacityReservationPreference: open | none 
#   CapacityReservationId: {The ID of the Capacity Reservation in which to run the instance.}
#   CapacityReservationResourceGroupArn: {The ARN of the Capacity Reservation resource group in which to run the instance.}

### REQUIRED WITH ABOVE:
#   startup_script: startup_scripts/gpu_ubuntu_startup.txt
#   post_startup_script: post_startup_scripts/fmbench.txt
#   fmbench_config: https://raw.githubusercontent.com/dheerajoruganty/multi-deploy-ec2/refs/heads/main/configs/config-ec2-llama3-8b.yml

### OPTIONAL:
#   fmbench_llm_tokenizer_fpath: fmbench_llm_utils/tokenizer.json
#   fmbench_llm_config_fpath: fmbench_llm_utils/config.json
#   fmbench_tokenizer_remote_dir: /tmp/fmbench-read/llama3_tokenizer/
#   # Timeout period in Seconds before a run is stopped
#   fmbench_complete_timeout: 1200

## US-EAST-1 Mapping:
# Neuron AMI : ami-05d498302130f9036
# DeepLearning AMI AL2 : ami-07f302d2a74e2b584
# Al2 AMI, CPU bench : ami-0e54eba7c51c234f6

# Take the below as list of dict as there might be 2 instances with the same AMI

defaults: &ec2_settings
  region: {{region}}
  ami_id: {{gpu}}
  device_name: /dev/sda1
  ebs_del_on_termination: True
  ebs_Iops: 16000
  ebs_VolumeSize: 250
  ebs_VolumeType: gp3
  startup_script: startup_scripts/ubuntu_startup.txt
  post_startup_script: post_startup_scripts/fmbench.txt
  # Timeout period in Seconds before a run is stopped
  fmbench_complete_timeout: 7200

instances:
- instance_type: m7a.xlarge
  <<: *ec2_settings
  fmbench_config: 
  - {{config_file}}


================================================
File: /utils.py
================================================
import os
import re
import time
import json
import wget
import yaml
import boto3
import base64
import urllib
import shutil
import logging
import asyncio
import requests
import paramiko
from utils import *
from constants import *
from pathlib import Path
from scp import SCPClient
from jinja2 import Template
from collections import defaultdict
from typing import Optional, List, Tuple, Any
from concurrent.futures import ThreadPoolExecutor
from botocore.exceptions import NoCredentialsError, ClientError

# set a logger
logger = logging.getLogger(__name__)

executor = ThreadPoolExecutor()

def _get_latest_version(package_name: str) -> Optional[str]:
    url = f"https://pypi.org/pypi/{package_name}/json"
    response = requests.get(url)
    
    if response.status_code == 200:
        data = response.json()
        version = data["info"]["version"]
    else:
        logger.info(f"package '{package_name}' not found on PyPI.")
        version = None
    return version

def get_region() -> str:
    """
    This function fetches the current region where this orchestrator is running using the 
    EC2 region metadata API or the boto3 session if the region cannot be determined from
    the API.
    """
    try:
        session = boto3.session.Session()
        region_name = session.region_name
        if region_name is None:
            logger.info(
                f"boto3.session.Session().region_name is {region_name}, "
                f"going to use an metadata api to determine region name"
            )
            # THIS CODE ASSUMED WE ARE RUNNING ON EC2, for everything else
            # the boto3 session should be sufficient to retrieve region name
            resp = requests.put(
                "http://169.254.169.254/latest/api/token",
                headers={"X-aws-ec2-metadata-token-ttl-seconds": "21600"},
            )
            token = resp.text
            region_name = requests.get(
                "http://169.254.169.254/latest/meta-data/placement/region",
                headers={"X-aws-ec2-metadata-token": token},
            ).text
            logger.info(
                f"region_name={region_name}, also setting the AWS_DEFAULT_REGION env var"
            )
            os.environ["AWS_DEFAULT_REGION"] = region_name
        logger.info(f"region_name={region_name}")
    except Exception as e:
        logger.error(f"Could not fetch the region: {e}")
        region_name = None
    return region_name

def _normalize_yaml_param_spacing(template_content: str, variable_name: str) -> str:
    """
    Replaces all possible spacing combinations of '{{ gpu_ami}}' with '{{gpu_ami}}'.
    
    Parameters:
    - template_content (str): The content of the template with potential spacing around 'gpu_ami'.
    - param_name (str): The name of the parameter to fix spacing
    Returns:
    - str: The template content with normalized '{{gpu_ami}}' placeholders.
    """
    
    # Define the regex pattern to match '{{ gpu_ami}}' with any possible spacing
    pattern = r"\{\{\s*" + re.escape(variable_name) + r"\s*\}\}"
    
    # Replace all occurrences of the pattern with '{{gpu_ami}}'
    normalized_content = re.sub(pattern, f"{{{variable_name}}}", template_content)
    
    return normalized_content


def _get_rendered_yaml(config_file_path: str, context: Dict) -> str:
    logger.info(f"config_file_path={config_file_path}")
    # read the yml file as raw text
    template_content = Path(config_file_path).read_text()

    # Normalize the spacing, so {{ gpu }} and {{ gpu}} etc all get converted
    # to {{gpu}}
    for param in ['gpu', 'cpu', 'neuron']:
        template_content = _normalize_yaml_param_spacing(template_content, param)

    # context contains region, config file etc.
    # context = {'region': global_region, 'config_file': fmbench_config_file, 'write_bucket': write_bucket}

    # First rendering to substitute 'region' and 'config_file'
    # if the {{config_file}} placeholder does not exist in the config.yml
    # then the 'config_file' key in the 'context' dict does not do anything
    # if the {{config_file}} placeholder does indeed exist then it will get
    # replaced with the value in the context dict, if however the user did not
    # provide the value as a command line argument to the orchestrator then it
    # would get replaced by None and we would have no fmbench config file and the 
    # code would raise an exception that it cannot continue
    template = Template(template_content)
    rendered_yaml = template.render(context)
    return rendered_yaml

def load_yaml_file(config_file_path: str,
                   ami_mapping_file_path: str,
                   fmbench_config_file: Optional[str],
                   infra_config_file: str,
                   write_bucket: Optional[str]) -> Optional[Dict]:
    """
    Load and parse a YAML file using Jinja2 templating for region and AMI ID substitution.

    Args:
        file_path (str): The path to the YAML file to be read.

    Returns:
        Optional[Dict]: Parsed content of the YAML file as a dictionary with region and AMI mapping information
                        substituted, or None if an error occurs.
    """

    # mandatory files should be present
    for f in [config_file_path, ami_mapping_file_path, infra_config_file]:
        if Path(f).is_file() is False:
            logger.error(f"{f} not found, cannot continue")
            raise FileNotFoundError(f"file '{f}' does not exist.")
    
    # Get the global region where this orchestrator is running
    # Initial context with 'region'
    global_region = get_region()
    context = {'region': global_region, 'config_file': fmbench_config_file, 'write_bucket': write_bucket}

    rendered_yaml = _get_rendered_yaml(config_file_path, context)
    # yaml to json
    config_data = yaml.safe_load(rendered_yaml)

    rendered_yaml = _get_rendered_yaml(infra_config_file, context)
    # yaml to json
    infra_config_data = yaml.safe_load(rendered_yaml)

    # merge the two configs
    config_data = config_data | infra_config_data

    # Fetch the AMI mapping file
    ami_mapping =  yaml.safe_load(Path(ami_mapping_file_path).read_text())

    # at this time any instance of ami_id: ami-something would remain as is
    # but any instance ami_id: gpu have been converted to ami_id: {gpu: None}
    # so we will iterate through the instance to replace ami_id with region specific
    # ami_id values from the ami_mapping we have. We have to do this because jinja2 does not
    # support nested variables and all other options added unnecessary complexity
    for i, instance in enumerate(config_data['instances']):
        if instance.get('region') is None:
            config_data['instances'][i]['region'] = global_region
            region = global_region
        else:
            region = instance['region']
        ami_id = instance['ami_id']

        if isinstance(ami_id, dict):
            # name of the first key, could be gpu, cpu, neuron or others in future
            ami_key = next(iter(ami_id))
            ami_id_from_config = None
            if ami_mapping.get(region):
                ami_id_from_config = ami_mapping[region].get(ami_key)
                if ami_id_from_config is None:
                    logger.error(f"instance {i+1}, instance_type={instance['instance_type']}, no ami found for {region} type {ami_key}")
                    raise Exception(f"instance {i+1}, instance_type={instance['instance_type']}, no ami found for {region} type {ami_key}")
            else:
                logger.error(f"no info found for region {region} in {ami_mapping_file_path}, cannot continue")
                raise Exception(f"instance {i+1}, instance_type={instance['instance_type']}, no info found in region {region} in {ami_mapping_file_path}, cannot continue")
            logger.info(f"instance {i+1}, instance_type={instance['instance_type']}, ami_key={ami_key}, region={region}, ami_id_from_config={ami_id_from_config}")
            # set the ami id
            config_data['instances'][i]['ami_id'] = ami_id_from_config
        elif isinstance(ami_id, str):
            logger.info(f"instance {i+1}, instance_type={instance['instance_type']}, region={region}, ami_id={ami_id}")
        else:
            raise Exception(f"instance {i+1}, instance_type={instance['instance_type']}, "
                            f"no info found for ami_id {ami_id}, region {region} in {ami_mapping_file_path}, cannot continue")

        # see if we need to unfurl the fmbench config file url
        fmbench_config_paths = instance['fmbench_config']
        if isinstance(fmbench_config_paths, list):
            for j in range(len(fmbench_config_paths)):
                if fmbench_config_paths[j] is None or fmbench_config_paths[j] == 'None':
                    raise Exception(f"instance {i+1}, instance_type={instance['instance_type']}, "
                                    f"no fmbench_config file provided, cannot continue")

                if fmbench_config_paths[j].startswith(FMBENCH_CFG_PREFIX):
                    fmbench_config_paths[j] = fmbench_config_paths[j].replace(FMBENCH_CFG_PREFIX, FMBENCH_CFG_GH_PREFIX)
            config_data['instances'][i]['fmbench_config'] = fmbench_config_paths

    return config_data


def _get_security_group_id_by_name(region: str, group_name: str, vpc_id: int) -> str:
    """
    Retrieve the security group ID based on its name and VPC ID.

    Args:
        sg_name (str): The name of the security group.
        vpc_id (str): The ID of the VPC where the security group is located.
        region (str): The AWS region.

    Returns:
        str: The security group ID if found, None otherwise.
    """
    try:
        ec2_client = boto3.client("ec2", region_name=region)
        security_group_id: Optional[str] = None
        response = ec2_client.describe_security_groups(
            Filters=[
                {"Name": "group-name", "Values": [group_name]},
            ]
        )
        # If security group exists, return the ID
        if response["SecurityGroups"]:
            security_group_id = response["SecurityGroups"][0]["GroupId"]
        else:
            logger.error(f"Security group '{group_name}' not found in VPC '{vpc_id}'.")
    except Exception as e:
        logger.INFO(f"Error retrieving security group: {e}")
        security_group_id = None
    return security_group_id


def create_security_group(
    region: str, group_name: str, description: str, vpc_id: Optional[str] = None
):
    """
    Create an EC2 security group.

    Args:
        group_name (str): Name of the security group.
        description (str): Description of the security group.
        vpc_id (str, optional): ID of the VPC in which to create the security group. If None, it will be created in the default VPC.
        region (str): AWS region where the security group will be created.

    Returns:
        str: ID of the created security group.
    """
    try:
        # Initialize the EC2 client
        ec2_client = boto3.client("ec2", region_name=region)
        security_group_id: Optional[str] = None
        # Define parameters for creating the security group
        params: Dict = {
            "GroupName": group_name,
            "Description": description,
        }
        # Only add the VpcId parameter if vpc_id is not None
        if vpc_id is not None:
            params["VpcId"] = vpc_id

        # Create the security group
        response = ec2_client.create_security_group(**params)
        if response is not None:
            security_group_id = response["GroupId"]
            logger.info(f"Security Group Created: {security_group_id}")
        else:
            logger.error(f"Security group is not created.")
    except ClientError as e:
        # Check if the error is due to the group already existing
        if e.response["Error"]["Code"] == "InvalidGroup.Duplicate":
            print(
                f"Security Group '{group_name}' already exists. Fetching existing security group ID."
            )
            return _get_security_group_id_by_name(region, group_name, vpc_id)
        else:
            print(f"Error creating security group: {e}")
            security_group_id = None
    return security_group_id


def authorize_inbound_rules(security_group_id: str, region: str):
    """
    Authorize inbound rules to a security group.

    Args:
        security_group_id (str): ID of the security group.
        region (str): AWS region where the security group is located.
    """
    try:
        # Initialize the EC2 client
        ec2_client = boto3.client("ec2", region_name=region)
        # Authorize inbound rules
        ec2_client.authorize_security_group_ingress(
            GroupId=security_group_id,
            IpPermissions=[
                {
                    "IpProtocol": "tcp",
                    "FromPort": 22,
                    "ToPort": 22,
                    "IpRanges": [{"CidrIp": "0.0.0.0/0"}],  # Allow SSH from anywhere
                },
                {
                    "IpProtocol": "tcp",
                    "FromPort": 80,
                    "ToPort": 80,
                    "IpRanges": [{"CidrIp": "0.0.0.0/0"}],  # Allow HTTP from anywhere
                },
            ],
        )
        logger.info(f"Inbound rules added to Security Group {security_group_id}")
    except ClientError as e:
        if e.response["Error"]["Code"] == "InvalidPermission.Duplicate":
            logger.info(
                f"Inbound rule already exists for Security Group {security_group_id}. Skipping..."
            )
        else:
            logger.error(f"Error authorizing inbound rules: {e}")


def create_key_pair(key_name: str, region: str, delete_key_pair_if_present: bool) -> str:
    """
    Create a new key pair for EC2 instances.

    Args:
        key_name (str): The name of the key pair.
        region (str): AWS region where the key pair will be created.

    Returns:
        str: The private key material in PEM format.
    """
    try:
        # Initialize the EC2 client
        ec2_client = boto3.client("ec2", region_name=region)
        # check if key pair exists
        kp_exists: bool = False
        kp_list_response = ec2_client.describe_key_pairs(KeyNames=[])
        for kp in kp_list_response['KeyPairs']:
            if kp['KeyName'] == key_name:
                kp_exists = True
                break
        if kp_exists is True:
            if delete_key_pair_if_present is True:
                logger.info(f"key pair {key_name} does exist, going to delete it now")
                ec2_client.delete_key_pair(KeyName=key_name)
            else:
                logger.error(f"key pair {key_name} already exists but delete_key_pair_if_present={delete_key_pair_if_present}, cannot continue")
        else:
            logger.info(f"key pair {key_name} does not exist, going to create it now")
        key_material: Optional[str] = None
        # Create a key pair
        response = ec2_client.create_key_pair(KeyName=key_name)
        if response.get("KeyMaterial") is not None:
            # Extract the private key from the response
            key_material = response["KeyMaterial"]
            logger.info(f"Key {key_name} is created")
        else:
            logger.error(f"Could not create key pair: {key_name}")
    except ClientError as e:
        logger.info(f"Error creating key pair: {e}")
        key_material = None
    return key_material


def create_ec2_instance(
    idx: int,
    key_name: str,
    security_group_id: str,
    user_data_script: str,
    ami: str,
    instance_type: str,
    iam_arn: str,
    region: str,
    device_name=DEFAULT_DEVICE_NAME,
    ebs_del_on_termination=True,
    ebs_Iops=EBS_IOPS,
    ebs_VolumeSize=EBS_VOLUME_SIZE,
    ebs_VolumeType=EBS_VOLUME_TYPE,
    CapacityReservationPreference=None,
    CapacityReservationId=None,
    CapacityReservationResourceGroupArn=None,
):
    """
    Create an EC2 instance with a startup script (user data) in the specified region.

    Args:
        idx (int): Index or identifier for the instance.
        key_name (str): The name of the key pair to associate with the instance.
        security_group_id (str): The ID of the security group to associate with the instance.
        user_data_script (str): The script to run on startup.
        ami (str): The ID of the AMI to use for the instance.
        instance_type (str): The type of instance to launch.
        iam_arn (str): The ARN of the IAM role to associate with the instance.
        region (str): The AWS region to launch the instance in.
        device_name (str): The device name for the EBS volume.
        ebs_del_on_termination (bool): Whether to delete the EBS volume on instance termination.
        ebs_Iops (int): The number of I/O operations per second for the EBS volume.
        ebs_VolumeSize (int): The size of the EBS volume in GiB.
        ebs_VolumeType (str): The type of EBS volume.
        CapacityReservationPreference (str): The capacity reservation preference.
        CapacityReservationTarget (dict): The capacity reservation target specifications.

    Returns:
        str: The ID of the created instance.
    """
    ec2_resource = boto3.resource("ec2", region_name=region)
    instance_id: Optional[str] = None
    try:
        instance_name: str = f"FMBench-{instance_type}-{idx}"
        
        # Prepare the CapacityReservationSpecification
        capacity_reservation_spec = {}
        if CapacityReservationId:
            capacity_reservation_spec["CapacityReservationTarget"] = {"CapacityReservationId": CapacityReservationId}
        elif CapacityReservationResourceGroupArn:
            capacity_reservation_spec["CapacityReservationTarget"] = {"CapacityReservationResourceGroupArn": CapacityReservationResourceGroupArn}
        elif CapacityReservationPreference:
            capacity_reservation_spec["CapacityReservationPreference"] = CapacityReservationPreference

        # Create a new EC2 instance with user data
        instances = ec2_resource.create_instances(
            BlockDeviceMappings=[
                {
                    "DeviceName": device_name,
                    "Ebs": {
                        "DeleteOnTermination": ebs_del_on_termination,
                        "Iops": ebs_Iops,
                        "VolumeSize": ebs_VolumeSize,
                        "VolumeType": ebs_VolumeType,
                    },
                },
            ],
            ImageId=ami,
            InstanceType=instance_type,  # Instance type
            KeyName=key_name,  # Name of the key pair
            SecurityGroupIds=[security_group_id],  # Security group ID
            UserData=user_data_script,  # The user data script to run on startup
            MinCount=MIN_INSTANCE_COUNT,  # Minimum number of instances to launch
            MaxCount=MAX_INSTANCE_COUNT,  # Maximum number of instances to launch
            IamInstanceProfile={  # IAM role to associate with the instance
                "Arn": iam_arn
            },
            CapacityReservationSpecification=capacity_reservation_spec,
            TagSpecifications=[
                {
                    "ResourceType": "instance",
                    "Tags": [{"Key": "Name", "Value": instance_name},
                             {"Key": "fmbench-version", "Value": _get_latest_version(FMBENCH_PACKAGE_NAME)}],
                }
            ],
        )

        if instances:
            instance_id = instances[0].id
            logger.info(f"EC2 Instance '{instance_id}', '{instance_name}' created successfully with user data.")
        else:
            logger.error("Instances could not be created")
    except Exception as e:
        logger.error(f"Error creating EC2 instance: {e}")
        instance_id=None
    return instance_id


def delete_ec2_instance(instance_id: str, region: str) -> bool:
    """
    Deletes an EC2 instance given its instance ID.

    Args:
        instance_id (str): The ID of the instance to delete.
        region (str): The AWS region where the instance is located.

    Returns:
        bool: True if the instance was deleted successfully, False otherwise.
    """
    try:
        ec2_client = boto3.client("ec2", region_name=region)
        has_instance_terminated: Optional[bool] = None
        # Terminate the EC2 instance
        response = ec2_client.terminate_instances(InstanceIds=[instance_id])
        if response is not None:
            logger.info(f"Instance {instance_id} has been terminated.")
            has_instance_terminated = True
        else:
            logger.error(f"Instance {instance_id}  could not be terminated")
            has_instance_terminated = False
    except Exception as e:
        logger.info(f"Error deleting instance {instance_id}: {e}")
        has_instance_terminated = False
    return has_instance_terminated


def _determine_username(ami_id: str, region: str):
    """
    Determine the appropriate username based on the AMI ID or name.

    Args:
        ami_id (str): The ID of the AMI used to launch the EC2 instance.

    Returns:
        str: The username for the EC2 instance.
    """
    try:
        ec2_client = boto3.client("ec2", region)
        # Describe the AMI to get its name
        response = ec2_client.describe_images(ImageIds=[ami_id])
        ec2_username: Optional[str] = None
        if response is not None:
            ami_name = response["Images"][0][
                "Name"
            ].lower()  # Convert AMI name to lowercase
        else:
            logger.error(f"Could not describe the ec2 image")
            return
        # Match the AMI name to determine the username
        for key in AMI_USERNAME_MAP:
            if key in ami_name:
                return AMI_USERNAME_MAP[key]

        # Default username if no match is found
        ec2_username = DEFAULT_EC2_USERNAME
    except Exception as e:
        logger.info(f"Error fetching AMI details: {e}")
        ec2_username = DEFAULT_EC2_USERNAME
    return ec2_username


def _get_ec2_hostname_and_username(
    instance_id: str, region: str, public_dns=True
) -> Tuple:
    """
    Retrieve the public or private DNS name (hostname) and username of an EC2 instance.
    Args:
        instance_id (str): The ID of the EC2 instance.
        region (str): The AWS region where the instance is located.
        public_dns (bool): If True, returns the public DNS; if False, returns the private DNS.

    Returns:
        tuple: A tuple containing the hostname (public or private DNS) and username.
    """
    try:
        hostname, username, instance_name = None, None, None
        ec2_client = boto3.client("ec2", region_name=region)
        # Describe the instance
        response = ec2_client.describe_instances(InstanceIds=[instance_id])
        if response is not None:
            # Extract instance information
            instance = response["Reservations"][0]["Instances"][0]
            ami_id = instance.get(
                "ImageId"
            )  # Get the AMI ID used to launch the instance
            # Check if the public DNS or private DNS is required
            if public_dns:
                hostname = instance.get("PublicDnsName")
            else:
                hostname = instance.get("PrivateDnsName")
            # instance name
            tags = response["Reservations"][0]["Instances"][0]["Tags"]
            logger.info(f"tags={tags}")
            instance_names = [t["Value"] for t in tags if t["Key"] == "Name"]
            if not instance_names:
                instance_name = "FMBench-" + instance.get('InstanceType') + "-" + instance_id
            else:
                instance_name = instance_names[0]
        # Determine the username based on the AMI ID
        username = _determine_username(ami_id, region)
    except Exception as e:
        logger.info(f"Error fetching instance details (hostname and username): {e}")
    return hostname, username, instance_name


# Function to check for 'results-*' folders in the root directory of an EC2 instance
def _check_for_results_folder(
    hostname: str, instance_name: str, username: str, key_file_path: str
) -> List:
    """
    Checks if any folder matching the pattern exists in the root directory.

    Args:
        hostname (str): The public IP or DNS of the EC2 instance.
        username (str): The SSH username (e.g., 'ec2-user').
        key_file_path (str): The path to the PEM key file.
        folder_pattern (str): The pattern to match folders (default is '/results-*').

    Returns:
        list: List of matching folder names, or an empty list if none found.
    """
    try:
        # Initialize the result folders within fmbench
        fmbench_result_folders: Optional[List] = None
        # Initialize the SSH client
        ssh_client = paramiko.SSHClient()
        ssh_client.set_missing_host_key_policy(paramiko.AutoAddPolicy())

        # Load the private key
        private_key = paramiko.RSAKey.from_private_key_file(key_file_path)

        # Connect to the instance
        ssh_client.connect(hostname, username=username, pkey=private_key)
        logger.info(
            f"_check_for_results_folder, instance_name={instance_name}, connected to {hostname} as {username}"
        )

        # Execute the command to check for folders matching the pattern
        command = f"ls -d {FMBENCH_RESULTS_FOLDER_PATTERN}"
        stdin, stdout, stderr = ssh_client.exec_command(command)
        output = stdout.read().decode().strip()
        error = stderr.read().decode().strip()
        logger.info(
            f"_check_for_results_folder, instance_name={instance_name}, output={output}, error={error}"
        )
        # Close the connection
        ssh_client.close()
        if error:
            # No folder found or other errors
            logger.info(
                f"_check_for_results_folder, instance_name={instance_name}, No matching folders found on {hostname}: {error}"
            )
            fmbench_result_folders = None
        else:
            # Split the output by newline to get folder names
            fmbench_result_folders = output.split("\n") if output else None
            logger.info(
                f"_check_for_results_folder, instance_name={instance_name}, fmbench_result_folders={fmbench_result_folders}"
            )
    except Exception as e:
        logger.info(f"Error connecting via SSH to {hostname}: {e}")
        fmbench_result_folders = None
    return fmbench_result_folders


# Function to retrieve folders from the EC2 instance
def _get_folder_from_instance(
    hostname: str,
    username: str,
    key_file_path: str,
    remote_folder: str,
    local_folder: str,
) -> bool:
    """
    Retrieves a folder from the EC2 instance to the local machine using SCP.

    Args:
        hostname (str): The public IP or DNS of the EC2 instance.
        username (str): The SSH username (e.g., 'ec2-user').
        key_file_path (str): The path to the PEM key file.
        remote_folder (str): The path of the folder on the EC2 instance to retrieve.
        local_folder (str): The local path where the folder should be saved.

    Returns:
        bool: True if the folder was retrieved successfully, False otherwise.
    """
    try:
        folder_retrieved: bool = False
        # Initialize the SSH client
        ssh_client = paramiko.SSHClient()
        ssh_client.set_missing_host_key_policy(paramiko.AutoAddPolicy())

        # Load the private key
        private_key = paramiko.RSAKey.from_private_key_file(key_file_path)

        # Connect to the instance
        ssh_client.connect(hostname, username=username, pkey=private_key)

        # Use SCP to copy the folder
        with SCPClient(ssh_client.get_transport()) as scp:
            scp.get(remote_folder, local_path=local_folder, recursive=True)
        logger.info(
            f"Folder '{remote_folder}' retrieved successfully to '{local_folder}'."
        )
        # Close the connection
        ssh_client.close()
        folder_retrieved = True
    except Exception as e:
        logger.error(f"Error retrieving folder from {hostname} via SCP: {e}")
        folder_retrieved = False
    return folder_retrieved


# Main function to check and retrieve 'results-*' folders from multiple instances
def check_and_retrieve_results_folder(instance: Dict, local_folder_base: str):
    """
    Checks for 'results-*' folders on a single EC2 instance and retrieves them if found.

    Args:
        instance (dict): Dictionary containing instance details (hostname, username, instance_id).
        local_folder_base (str): The local base path where the folders should be saved.

    Returns:
        None
    """
    try:
        hostname = instance["hostname"]
        instance_name = instance["instance_name"]
        username = instance["username"]
        key_file_path = instance["key_file_path"]
        instance_id = instance["instance_id"]
        logger.info(f"check_and_retrieve_results_folder, {instance['instance_name']}")
        # Check for 'results-*' folders in the specified directory
        results_folders = _check_for_results_folder(
            hostname, instance_name, username, key_file_path
        )
        logger.info(
            f"check_and_retrieve_results_folder, {instance_name}, result folders {results_folders}"
        )
        # If any folders are found, retrieve them
        for folder in results_folders:
            if folder:  # Check if folder name is not empty
                # Create a local folder path for this instance
                local_folder = os.path.join(local_folder_base, instance_name)
                logger.info(
                    f"Retrieving folder '{folder}' from {instance_name} to '{local_folder}'..."
                )
                _get_folder_from_instance(
                    hostname, username, key_file_path, folder, local_folder
                )
                logger.info(
                    f"check_and_retrieve_results_folder, {instance_name}, folder={folder} downloaded"
                )

    except Exception as e:
        logger.error(
            f"Error occured while attempting to check and retrieve results from the instances: {e}"
        )

def get_fmbench_log(instance: Dict, local_folder_base: str, log_file_path: str, iter_count: int):
    """
    Checks for 'fmbench.log' file on a single EC2 instance and retrieves them if found.

    Args:
        instance (dict): Dictionary containing instance details (hostname, username, instance_id, key_file_path).
        local_folder_base (str): The local base path where the folders should be saved.
        log_file_path (str): The remote path to the log file.

    Returns:
        None
    """
    hostname = instance["hostname"]
    username = instance["username"]
    key_file_path = instance["key_file_path"]
    instance_name = instance["instance_name"]
    log_file_path = log_file_path.format(username=username)
    # Define local folder to store the log file
    local_folder = os.path.join(local_folder_base, instance_name)
    local_log_file = os.path.join(local_folder, f'fmbench_{iter_count}.log')

    try:
        # Clear out the local folder if it exists, then recreate it
        if Path(local_folder).is_dir() and iter_count == 1:
            logger.info(f"going to delete {local_folder}, iter_count={iter_count}")
            shutil.rmtree(local_folder)
        os.makedirs(local_folder, exist_ok=True)

        # Setup SSH and SFTP connection using Paramiko
        key = paramiko.RSAKey.from_private_key_file(key_file_path)
        ssh_client = paramiko.SSHClient()
        ssh_client.set_missing_host_key_policy(paramiko.AutoAddPolicy())
        ssh_client.connect(hostname=hostname, username=username, pkey=key)

        # Use SFTP to download the log file
        sftp = ssh_client.open_sftp()
        sftp.get(log_file_path, local_log_file)
        logger.info(f"Downloaded '{log_file_path}' to '{local_log_file}'")

        # Close connections
        sftp.close()
        ssh_client.close()

    except Exception as e:
        logger.error(f"Error occurred while retrieving the log file from {instance_name}: {e}")


def generate_instance_details(instance_id_list, instance_data_map):
    """
    Generates a list of instance details dictionaries containing hostname, username, and key file path.

    Args:
        instance_id_list (list): List of EC2 instance IDs.
        instance_data_map (dict) : Dict of all neccessary fields

    Returns:
        list: A list of dictionaries containing hostname, username, and key file path for each instance.
    """
    instance_details = []

    for instance_id in instance_id_list:

        # If a config entry is found, get the config path
        # Directly access the instance_data_map using the instance_id
        config_entry = instance_data_map.get(instance_id, None)

        # If no config entry is found, raise an exception
        if not config_entry:
            raise ValueError(f"Configuration not found for instance ID: {instance_id}")

        # Check if all required fields are present, raise a ValueError if any are missing
        required_fields = [
            "fmbench_config",
            "post_startup_script",
            "fmbench_complete_timeout",
            "region",
            "PRIVATE_KEY_FNAME",
        ]

        missing_fields = [
            field
            for field in required_fields
            if field not in config_entry or config_entry[field] is None
        ]

        if missing_fields:
            raise ValueError(
                f"Missing configuration fields for instance ID {instance_id}: {', '.join(missing_fields)}"
            )

        # Extract all the necessary configuration values from the config entry
        fmbench_config = config_entry["fmbench_config"]
        post_startup_script = config_entry["post_startup_script"]
        upload_files = config_entry.get("upload_files")
        post_startup_script_params = config_entry.get("post_startup_script_params")
        fmbench_complete_timeout = config_entry["fmbench_complete_timeout"]
        region = config_entry["region"]
        PRIVATE_KEY_FNAME = config_entry["PRIVATE_KEY_FNAME"]


        # Get the public hostname and username for each instance
        public_hostname, username, instance_name = _get_ec2_hostname_and_username(
            instance_id, region, public_dns=True
        )

        # Append the instance details to the list if hostname and username are found
        if public_hostname and username:
            instance_details.append(
                {
                    "instance_id": instance_id,
                    "instance_name": instance_name,
                    "hostname": public_hostname,
                    "username": username,
                    "key_file_path": (
                        f"{PRIVATE_KEY_FNAME}.pem"
                        if not PRIVATE_KEY_FNAME.endswith(".pem")
                        else PRIVATE_KEY_FNAME
                    ),
                    "config_file": fmbench_config,
                    "post_startup_script": post_startup_script,
                    "post_startup_script_params" : post_startup_script_params,
                    "upload_files": upload_files,
                    "fmbench_complete_timeout": fmbench_complete_timeout,
                    "region": config_entry.get("region", "us-east-1"),
                }
            )
        else:
            logger.error(
                f"Failed to retrieve hostname and username for instance {instance_id}"
            )
    return instance_details


def run_command_on_instances(
    instance_details: List, key_file_path: str, command: str
) -> Dict:
    """
    Executes a command on multiple EC2 instances using the instance_details list.

    Args:
        instance_details (list): List of dictionaries containing instance details (hostname, username, key_file_path).
        command (str): The command to execute on each instance.
        key_file_path (str): Path to the pem key file

    Returns:
        dict: A dictionary containing the results of command execution for each instance.
              The key is the instance's hostname, and the value is a dictionary with 'stdout', 'stderr', and 'exit_status'.
    """
    results: Dict = {}

    for instance in instance_details:
        hostname, username, instance_name = (
            instance["hostname"],
            instance["username"],
            instance["instance_name"],
        )
        logger.info(f"Running command on {instance_name}, {hostname} as {username}...")
        try:
            with paramiko.SSHClient() as ssh_client:
                ssh_client.set_missing_host_key_policy(paramiko.AutoAddPolicy())
                private_key = paramiko.RSAKey.from_private_key_file(key_file_path)
                ssh_client.connect(hostname, username=username, pkey=private_key)
                logger.info(f"Connected to {hostname} as {username}")
                stdin, stdout, stderr = ssh_client.exec_command(command)
                # Wait for the command to complete
                exit_status = stdout.channel.recv_exit_status()
                results[hostname] = {
                    "stdout": stdout.read().decode(),
                    "stderr": stderr.read().decode(),
                    "exit_status": exit_status,
                }
        except Exception as e:
            logger.error(f"Error connecting to {hostname} or executing command: {e}")
            results[hostname] = {"stdout": "", "stderr": str(e), "exit_status": -1}
    return results


def upload_and_execute_script_invoke_shell(
    hostname: str,
    username: str,
    key_file_path: str,
    script_content: str,
    remote_script_path,
) -> str:
    """
    Uploads a bash script to the EC2 instance and executes it via an interactive SSH shell.

    Args:
        hostname (str): The public IP or DNS of the EC2 instance.
        username (str): The SSH username (e.g., 'ubuntu').
        key_file_path (str): The path to the PEM key file.
        script_content (str): The content of the bash script to upload.
        remote_script_path (str): The remote path where the script should be saved on the instance.

    Returns:
        str: The output of the executed script.
    """
    # Initialize the output
    output: str = ""
    try:
        with paramiko.SSHClient() as ssh_client:
            ssh_client.set_missing_host_key_policy(paramiko.AutoAddPolicy())
            private_key = paramiko.RSAKey.from_private_key_file(key_file_path)
            ssh_client.connect(hostname, username=username, pkey=private_key)
            logger.info(f"Connected to {hostname} as {username}")
            remote_script_path = remote_script_path.format(username=username)
            try:
                with ssh_client.open_sftp() as sftp:
                    with sftp.file(remote_script_path, "w") as remote_file:
                        remote_file.write(script_content)
                    logger.info(f"Script successfully uploaded to {remote_script_path}")
            except Exception as e:
                logger.error(f"Failed to upload script to {remote_script_path}: {e}")


            with ssh_client.invoke_shell() as shell:
                time.sleep(1)  # Give the shell some time to initialize

                logger.info("Going to check if FMBench complete Flag exists in this instance, if it does, remove it")
                # Check if fmbench flag exists, if it does, remove it:
                shell.send("if [ -f /tmp/fmbench_completed.flag ]; then rm /tmp/fmbench_completed.flag; fi\n")
                
                time.sleep(1)

                shell.send(f"chmod +x {remote_script_path}\n")
                time.sleep(1)  # Wait for the command to complete

                shell.send(
                    f"nohup bash {remote_script_path} > $HOME/run_fmbench_nohup.log 2>&1 & disown\n"
                )
                time.sleep(1)  # Wait for the command to complete

                while shell.recv_ready():
                    output += shell.recv(1024).decode("utf-8")
                    time.sleep(2)  # Allow time for the command output to be captured
                # Close the shell and connection
                shell.close()
                ssh_client.close()
    except Exception as e:
        logger.error(f"Error connecting via SSH to {hostname}: {e}")
        output = ""
    return output


# Asynchronous function to download a configuration file if it is a URL
async def download_config_async(url, download_dir=DOWNLOAD_DIR_FOR_CFG_FILES):
    """Asynchronously downloads the configuration file from a URL."""
    os.makedirs(download_dir, exist_ok=True)
    local_path = os.path.join(download_dir, os.path.basename(url))
    if os.path.exists(local_path):
        logger.info(
            f"{local_path} already existed, deleting it first before downloading again"
        )
        os.remove(local_path)
    # Run the blocking download operation in a separate thread
    await asyncio.get_event_loop().run_in_executor(
        executor, wget.download, url, local_path
    )
    return local_path


async def upload_file_to_instance_async(
    hostname, username, key_file_path, file_paths
):
    """Asynchronously uploads multiple files to the EC2 instance."""
    
    def upload_files():
        # Initialize the SSH client
        ssh_client = paramiko.SSHClient()
        ssh_client.set_missing_host_key_policy(paramiko.AutoAddPolicy())

        # Load the private key
        private_key = paramiko.RSAKey.from_private_key_file(key_file_path)

        # Connect to the instance
        ssh_client.connect(hostname, username=username, pkey=private_key)
        logger.info(f"Connected to {hostname} as {username}")

        # Upload the files
        with SCPClient(ssh_client.get_transport()) as scp:
            for file_path in file_paths:
                local_path = file_path['local']
                remote_path = file_path['remote']
                scp.put(local_path, remote_path)
                logger.info(f"Uploaded {local_path} to {hostname}:{remote_path}")

        # Close the SSH connection
        ssh_client.close()

    # Run the blocking operation in a separate thread
    await asyncio.to_thread(upload_files)

# Asynchronous function to handle the configuration file
async def handle_config_file_async(instance, config_file):
    """Handles downloading and uploading of the config file based on the config type (URL or local path)."""
    
    config_path = config_file
    file_paths = []
    
    # Check if the config path is a URL
    if urllib.parse.urlparse(config_path).scheme in ("http", "https"):
        logger.info(f"Config is a URL. Downloading from {config_path}...")
        local_config_path = await download_config_async(config_path)
    else:
        # It's a local file path, use it directly
        local_config_path = config_path

    # Define the remote path for the configuration file on the EC2 instance
    remote_config_path = f"/home/{instance['username']}/{os.path.basename(local_config_path)}"
    logger.info(f"remote_config_path is: {remote_config_path}...")

    # Append the local and remote paths to the list of files to upload
    file_paths.append({'local': local_config_path, 'remote': remote_config_path})

    # Upload the configuration file to the EC2 instance
    await upload_file_to_instance_async(
        instance["hostname"],
        instance["username"],
        instance["key_file_path"],
        file_paths  # Now passing the list of dictionaries with local and remote paths
    )

    return remote_config_path


def _check_completion_flag(
    hostname, username, key_file_path, flag_file_path=STARTUP_COMPLETE_FLAG_FPATH
):
    """
    Checks if the startup flag file exists on the EC2 instance.

    Args:
        hostname (str): The public IP or DNS of the EC2 instance.
        username (str): The SSH username (e.g., 'ubuntu').
        key_file_path (str): The path to the PEM key file.
        flag_file_path (str): The path to the startup flag file on the instance. Default is '/tmp/startup_complete.flag'.

    Returns:
        bool: True if the flag file exists, False otherwise.
    """
    try:
        # Initialize the SSH client
        ssh_client = paramiko.SSHClient()
        ssh_client.set_missing_host_key_policy(paramiko.AutoAddPolicy())

        # Load the private key
        private_key = paramiko.RSAKey.from_private_key_file(key_file_path)

        # Connect to the instance
        ssh_client.connect(hostname, username=username, pkey=private_key)

        # Check if the flag file exists
        stdin, stdout, stderr = ssh_client.exec_command(
            f"test -f {flag_file_path} && echo 'File exists'"
        )
        output = stdout.read().decode().strip()
        error = stderr.read().decode().strip()

        # Close the connection
        ssh_client.close()

        # Return True if the file exists, otherwise False
        return output == "File exists"

    except Exception as e:
        logger.info(f"Error connecting via SSH to {hostname}: {e}")
        return False


def wait_for_flag(
    instance,
    flag_file_path,
    log_file_path,
    max_wait_time=MAX_WAIT_TIME_FOR_STARTUP_SCRIPT_IN_SECONDS,
    check_interval=SCRIPT_CHECK_INTERVAL_IN_SECONDS,
) -> bool:
    """
    Waits for the startup flag file on the EC2 instance, and returns the script if the flag file is found.

    Args:
        instance (dict): The dictionary containing instance details (hostname, username, key_file_path).
        formatted_script (str): The bash script content to be executed.
        remote_script_path (str): The remote path where the script should be saved on the instance.
        max_wait_time (int): Maximum wait time in seconds (default: 600 seconds or 10 minutes).
        check_interval (int): Interval time in seconds between checks (default: 30 seconds).
    """
    end_time = time.time() + max_wait_time
    startup_complete: bool = False
    logger.info(
        f"going to wait {max_wait_time}s for the startup script for {instance['instance_name']} to complete"
    )
    logger.info(
        "-----------------------------------------------------------------------------------------------"
    )
    logger.info(
        f"you can open another terminal and see the startup logs from this machine using the following command"
    )
    logger.info(
        f"ssh -i {instance['key_file_path']} {instance['username']}@{instance['hostname']} 'tail -f {log_file_path}'"
    )
    logger.info(
        "-----------------------------------------------------------------------------------------------"
    )
    while time.time() < end_time:
        completed = _check_completion_flag(
            hostname=instance["hostname"],
            username=instance["username"],
            key_file_path=instance["key_file_path"],
            flag_file_path=flag_file_path,
        )
        if completed is True:
            logger.info(f"{flag_file_path} flag file found!!")
            break
        else:
            time_remaining = end_time - time.time()
            logger.warning(
                f"Waiting for {flag_file_path}, instance_name={instance['instance_name']}..., seconds until timeout={int(time_remaining)}s"
            )
            time.sleep(check_interval)
    logger.error(
        f"max_wait_time={max_wait_time} expired and the script for {instance['hostname']} has still not completed, exiting, "
    )
    return completed


# Function to upload folders to the EC2 instance
def _put_folder_to_instance(
    hostname: str,
    username: str,
    key_file_path: str,
    local_folder: str,
    remote_folder: str,
) -> bool:
    """
    Uploads a folder from the local machine to the EC2 instance using SCP.

    Args:
        hostname (str): The public IP or DNS of the EC2 instance.
        username (str): The SSH username (e.g., 'ec2-user').
        key_file_path (str): The path to the PEM key file.
        local_folder (str): The local path of the folder to upload.
        remote_folder (str): The path on the EC2 instance where the folder should be saved.

    Returns:
        bool: True if the folder was uploaded successfully, False otherwise.
    """
    try:
        folder_uploaded: bool = False
        # Initialize the SSH client
        ssh_client = paramiko.SSHClient()
        ssh_client.set_missing_host_key_policy(paramiko.AutoAddPolicy())

        # Load the private key
        private_key = paramiko.RSAKey.from_private_key_file(key_file_path)

        # Connect to the instance
        ssh_client.connect(hostname, username=username, pkey=private_key)

        # Use SCP to copy the folder
        with SCPClient(ssh_client.get_transport()) as scp:
            scp.put(local_folder, remote_path=remote_folder, recursive=True)
        logger.info(
            f"Folder '{local_folder}' uploaded successfully to '{remote_folder}'."
        )
        # Close the connection
        ssh_client.close()
        folder_uploaded = True
    except Exception as e:
        logger.error(f"Error uploading folder to {hostname} via SCP: {e}")
        folder_uploaded = False
    return folder_uploaded


================================================
File: /README.md
================================================
# FMBench Orchestrator

![fmbench_architecture](docs/img/Fmbench-Orchestrator-Architecture-v1.png)

## Overview

The **FMBench Orchestrator** is a tool designed to automate the deployment and management of `FMBench` for benchmarking on Amazon EC2, Amazon SageMaker and Amazon Bedrock. In case of benchmarking on EC2, we could benchmark on multiple instances simultaneously, and these instances can be of different instance types (so you could run `g6e`, `p4de` and a `trn1` instances via the same config file), in different AWS regions and also test multiple `FMBench` config files. This orchestrator automates the creation of Security Groups, Key Pairs, EC2 instances, runs `FMBench` for a specific config, retrieves the results, and shuts down the instances after completion. Thus it **simplifies the benchmarking process (no more manual creation of SageMaker Notebooks, EC2 instances and cleanup, downloading results folder) and ensures a streamlined and scalable workflow**.

```
+---------------------------+
| Initialization            |
| (Configure & Setup)       |
+---------------------------+
          ↓
+---------------------------+
| Instance Creation         |
| (Launch EC2 Instances)    |
+---------------------------+
          ↓
+---------------------------+
| FMBENCH Execution         |
| (Run Benchmark Script)    |
+---------------------------+
          ↓
+---------------------------+
| Results Collection        |
| (Download from instances) |
+---------------------------+
          ↓
+---------------------------+
| Instance Termination      |
| (Terminate Instances)     |
+---------------------------+
```

## Prerequisites

- **IAM ROLE**: You need an active AWS account having an **IAM Role** necessary permissions to create, manage, and terminate EC2 instances. See [this](docs/iam.md) link for the permissions and trust policies that this IAM role needs to have. Call this IAM role as `fmbench-orchestrator`.

    
- **Service quota**: Your AWS account needs to have appropriately set service quota limits to be able to start the Amazon EC2 instances that you may want to use for benchmarking. This may require you to submit service quota increase requests, use [this link](https://docs.aws.amazon.com/servicequotas/latest/userguide/request-quota-increase.html) for submitting a service quota increase requests. This would usually mean increasing the CPU limits for your accounts, getting quota for certain instance types etc.

- **EC2 Instance**: It is recommended to run the orchestrator on an EC2 instance, attaching the IAM Role with permissions, preferably located in the same AWS region where you plan to launch the multiple EC2 instances (although launching instances across regions is supported as well).

    - Use `Ubuntu` as the instance OS, specifically the `ubuntu/images/hvm-ssd-gp3/ubuntu-noble-24.04-amd64-server-20240927` AMI.
    - Use `t3.xlarge` as the instance type with preferably at least 100GB of disk space.
    - Associate the `fmbench-orchestrator` IAM role with this instance.

## Installation

1. **Install `conda`**

    ```{.bash}
    wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
    bash Miniconda3-latest-Linux-x86_64.sh -b  # Run the Miniconda installer in batch mode (no manual intervention)
    rm -f Miniconda3-latest-Linux-x86_64.sh    # Remove the installer script after installation
    eval "$(/home/$USER/miniconda3/bin/conda shell.bash hook)" # Initialize conda for bash shell
    conda init  # Initialize conda, adding it to the shell
    ```

1. **Clone the Repository**

    ```bash
    git clone https://github.com/awslabs/fmbench-orchestrator.git
    cd fmbench-orchestrator
    ```

### Conda Environment Setup

1. **Create a Conda Environment with Python 3.11**:

    ```bash
    conda create --name fmbench-orchestrator-py311 python=3.11 -y
    ```

1. **Activate the Environment**:

    ```bash
    conda activate fmbench-orchestrator-py311
    ```

1. **Install Required Packages**:

    ```bash
    pip install -r requirements.txt
    ```

1. **Hugging Face token**:

   Most models and tokenizers are downloaded from Hugging Face, to enable this place your Hugging Face token in `/tmp/hf_token.txt`.

   ```bash
   # replace with your Hugging Face token
   hf_token=your-hugging-face-token
   echo $hf_token > /tmp/hf_token.txt
   ```

### Steps to run the orchestrator:

You can either use an existing config file included in this repo, such as [`configs/ec2.yml`](configs/ec2.yml) or create your own using the files provided in the [`configs`](configs) directory as a template. Make sure you are in the `fmbench-orchestrator-py311` conda environment. The following command runs benchmarking for the `Llama3-8b` model on an `g6e.2xlarge` and `g6e.4xlarge` instance types.

The following command runs benchmarking on an EC2 instance, see [Benchmark for SageMaker](#benchmark-for-sagemaker) for benchmarking on SageMaker and [Benchmark for Bedrock](#benchmark-for-bedrock) for benchmarking on Bedrock.

```bash
python main.py --config-file configs/ec2.yml
```

Here is a description of all the command line parameters that are supported by the orchestrator:

- **--config-file** - _required_, path to the orchestrator configuration file.
- **--ami-mapping-file** - _optional_, _default=ami_mapping.yml_, path to a config file containing the region->instance type->AMI mapping
- **--fmbench-config-file** - _optional_, config file to use with `FMBench`, this is used if the orchestrator config file uses the "{{config_file}}" format for specifying the `FMBench` config file. If you are benchmarking on SageMaker or Bedrock then parameter does need to be specified.
- **--infra-config-file** - _optional_, _default=infra.yml_, config file to use with AWS infrastructure
- **--write-bucket** - _optional_, _default=placeholder_, *this parameter is only needed when benchmarking on SageMaker*, Amazon S3 bucket to store model files for benchmarking on SageMaker

Once the run is completed you can see the `FMBench` results folder downloaded in the `results` directory under the orchestrator, the `fmbench.log` file is also downloaded from the EC2 instances and placed alongside the results folder.

To analyze the results i.e. compare and contrast the price performance of different EC2 instance types that were a part of the run by running an analytics script. The example below shows how to use the `analytcs.py` script to analyze results obtained from running the orchestrator with the [`llama3-8b-g6e-triton.yml`](configs/llama3/8b/llama3-8b-triton-g6e.yml) config file.

```{.bashrc}
python analytics/analytics.py --results-dir results/llama3-8b-g6e-triton --model-id llama3-8b --payload-file payload_en_3000-3840.jsonl --latency-threshold 2
```

Running the scripts above creates a `results` folder under `analytics` which contains summaries of the results and a heatmap that helps understand which instance type gives the best price performance at the desired scale (transactions/minute) while maintaining the inference latency below a desired threshold.

## How do I ...

See [configuration guide](docs/config_guide.md) for details on the orchestrator config file.

### Benchmark for EC2

Take an existing config file from the [`configs`](configs/) folder, create a copy and edit it as needed. You would typically only need to modify the `instances` section of the config file to either modify the instance type and config file or add additional types. For example the following command line benchmarks the `Llama3.1-8b` models on `g6e` EC2 instance types.

```bash
python main.py --config-file configs/ec2.yml
```

## Benchmark for SageMaker

You can benchmark any model(s) on Amazon SageMaker by simply pointing the orchestrator to the desired `FMBench` SageMaker config file. The orchestrator will create an EC2 instance and use that for running `FMBench` benchmarking for SageMaker. For example the following command line benchmarks the `Llama3.1-8b` models on `ml.g5` instance types on SageMaker.

```bash
# provide the name of an S3 bucket in which you want
# SageMaker to store the model files (for models downloaded
# from Hugging Face)
write_bucket=your-bucket-name
python main.py --config-file configs/sagemaker.yml --fmbench-config-file fmbench:llama3.1/8b/config-llama3.1-8b-g5.2xl-g5.4xl-sm.yml --write-bucket $write_bucket
```

## Benchmark for Bedrock

You can benchmark any model(s) on Amazon Bedrock by simply pointing the orchestrator to the desired `FMBench` SageMaker config file. The orchestrator will create an EC2 instance and use that for running `FMBench` benchmarking for Bedrock.  For example the following command line benchmarks the `Llama3.1` models on Bedrock.

```bash
python main.py --config-file configs/bedrock.yml --fmbench-config-file fmbench:bedrock/config-bedrock-llama3-1.yml
```

### Use an existing `FMBench` config file but modify it slightly for my requirements

1. Download an `FMBench` config file from the [`FMBench repo`](https://github.com/aws-samples/foundation-model-benchmarking-tool/tree/main/src/fmbench/configs) and place it in the [`configs/fmbench`](./configs/fmbench/) folder.
1. Modify the downloaded config as needed.
1. Update the `instance -> fmench_config` section for the instance that needs to use this file to point to the updated config file in `fmbench/configs` so for example if the updated config file was `config-ec2-llama3-8b-g6e-2xlarge-custom.yml` then the following parameter:

    ```{.bashrc}
    fmbench_config: 
    - fmbench:llama3/8b/config-ec2-llama3-8b-g6e-2xlarge.yml
    ```
      would be changed to:

    ```{.bashrc}
    fmbench_config: 
    - configs/fmbench/config-ec2-llama3-8b-g6e-2xlarge-custom.yml
    ```

    The orchestrator would now upload the custom config on the EC2 instance being used for benchmarking.

### Provide a custom prompt/custom tokenizer for my benchmarking test

The `instances` section has an `upload_files` section for each instance where we can provide a list of `local` files and `remote` directory paths to place any custom file on an EC2 instance. This could be a `tokenizer.json` file, a custom prompt file, or a custom dataset. The example below shows how to upload a custom `pricing.yml` and a custom dataset to an EC2 instance.

```{.bashrc}
instances:
- instance_type: g6e.2xlarge
  <<: *ec2_settings
  fmbench_config: 
  - fmbench:llama3/8b/config-ec2-llama3-8b-g6e-2xlarge.yml
  upload_files:
   - local: byo_dataset/custom.jsonl
     remote: /tmp/fmbench-read/source_data/
   - local: analytics/pricing.yml
     remote: /tmp/fmbench-read/configs/
```

See [`ec2_llama3.2-1b-cpu-byodataset.yml`](configs/ec2_llama3.2-1b-cpu-byodataset.yml) for an example config file. This file refers to the [`synthetic_data_large_prompts`](byo_dataset/synthetic_data_large_prompts.jsonl) and a custom prompt file [`prompt_template_llama3_summarization.txt`](byo_dataset/prompt_template_llama3_summarization.txt) for a summarization task. You can edit the dataset file and the prompt template as per your requirements.

### Benchmark multiple config files on the same EC2 instance

Often times we want to benchmark different combinations of parameters on the same EC2 instance, for example we may want to test tensor parallelism degree of 2, 4 and 8 for say `Llama3.1-8b` model on the same EC2 machine say `g6e.48xlarge`. Can do that easily with the orchestrator by specifying a list of config files rather than just a single config file as shown in the following example:

   ```{.bashrc}
  fmbench_config: 
  - fmbench:llama3.1/8b/config-llama3.1-8b-g6e.48xl-tp-2-mc-max-djl.yml
  - fmbench:llama3.1/8b/config-llama3.1-8b-g6e.48xl-tp-4-mc-max-djl.yml
  - fmbench:llama3.1/8b/config-llama3.1-8b-g6e.48xl-tp-8-mc-max-djl.yml
  ```
The orchestrator would in this case first run benchmarking for the first file in the list, and then on the same EC2 instance run benchmarking for the second file and so on and so forth. The results folders and `fmbench.log` files for each of the runs is downloaded at the end when all config files for that instance have been processed.

## Contributing
Contributions are welcome! Please fork the repository and submit a pull request with your changes. For major changes, please open an issue first to discuss what you would like to change.


## Security

See [CONTRIBUTING](CONTRIBUTING.md#security-issue-notifications) for more information.

## License

This project is licensed under the MIT-0 License - see the [LICENSE](LICENSE) file for details.




